{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Policy Gradients\n",
    "The goal in policy gradient algorithms is to maximize the expected returns of a policy $\\pi_\\theta$ with parameters $\\theta$. Letting $\\tau=((s_0, a_0, r_0), \\ldots, (s_T, a_T, r_T) )$ denote a trajectory and $R(\\tau)$ the return of $\\tau$, this objective can be written as\n",
    "$$\\max_{\\theta} \\mathbb E_{\\tau \\sim \\pi_{\\theta}}[R(\\tau)].$$\n",
    "\n",
    "Using the REINFORCE trick, we can compute the policy gradient (the gradient of expected policy returns) as\n",
    "$$\\sum_{t=0}^T \\mathbb E_{s_t, a_t \\sim \\pi(\\tau)} \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t \\vert s_t) R(\\tau).$$\n",
    "\n",
    "We can then estimate this with a very simple scheme.\n",
    "We first sample a trajectory $\\tau = ((s_t, a_t, r_t))_{t=0}^\\infty$ from our current policy, compute the discounted return of the trajectory as $R$, then take a stochastic estimate of the policy gradient as \n",
    "\n",
    "$$\\sum_{t=0}^T \\mathbb \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t \\vert s_t) R(\\tau).$$\n",
    "We can then repeat sample more trajectories to average the estimate over multiple samples.\n",
    "In practice, we will often use _discounted_ returns $\\tilde R(\\tau) = \\sum_{t=0}^T \\gamma^t r_t$ where $\\gamma$ is the discount factor and our policy gradient estimate will simply replace the undiscounted returns with $\\tilde R(\\tau)$.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#@title imports\n",
    "# As usual, a bit of setup\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "import deeprl.infrastructure.pytorch_util as ptu\n",
    "\n",
    "from deeprl.infrastructure.rl_trainer import RL_Trainer\n",
    "from deeprl.infrastructure.trainers import PG_Trainer\n",
    "from deeprl.infrastructure.trainers import BC_Trainer\n",
    "\n",
    "from deeprl.agents.pg_agent import PGAgent\n",
    "from deeprl.policies.MLP_policy import MLPPolicyPG\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def remove_folder(path):\n",
    "    # check if folder exists\n",
    "    if os.path.exists(path): \n",
    "        print(\"Clearing old results at {}\".format(path))\n",
    "        # remove if exists\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        print(\"Folder {} does not exist yet. No old results to delete\".format(path))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pg_base_args_dict = dict(\n",
    "    env_name = 'Hopper-v2', #@param ['Ant-v2', 'Humanoid-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2']\n",
    "    exp_name = 'test_pg', #@param\n",
    "    save_params = False, #@param {type: \"boolean\"}\n",
    "    \n",
    "    ep_len = 200, #@param {type: \"integer\"}\n",
    "    discount = 0.95, #@param {type: \"number\"}\n",
    "\n",
    "    reward_to_go = True, #@param {type: \"boolean\"}\n",
    "    nn_baseline = False, #@param {type: \"boolean\"}\n",
    "    dont_standardize_advantages = True, #@param {type: \"boolean\"}\n",
    "\n",
    "    # Training\n",
    "    num_agent_train_steps_per_iter = 1, #@param {type: \"integer\"})\n",
    "    n_iter = 100, #@param {type: \"integer\"})\n",
    "\n",
    "    # batches & buffers\n",
    "    batch_size = 1000, #@param {type: \"integer\"})\n",
    "    eval_batch_size = 1000, #@param {type: \"integer\"}\n",
    "    train_batch_size = 1000, #@param {type: \"integer\"}\n",
    "    max_replay_buffer_size = 1000000, #@param {type: \"integer\"}\n",
    "\n",
    "    #@markdown network\n",
    "    n_layers = 2, #@param {type: \"integer\"}\n",
    "    size = 64, #@param {type: \"integer\"}\n",
    "    learning_rate = 5e-3, #@param {type: \"number\"}\n",
    "\n",
    "    #@markdown logging\n",
    "    video_log_freq = -1, #@param {type: \"integer\"}\n",
    "    scalar_log_freq = 1, #@param {type: \"integer\"}\n",
    "\n",
    "    #@markdown gpu & run-time settings\n",
    "    no_gpu = False, #@param {type: \"boolean\"}\n",
    "    which_gpu = 0, #@param {type: \"integer\"}\n",
    "    seed = 2, #@param {type: \"integer\"}\n",
    "    logdir = 'test',\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing policy gradients\n",
    "We will first compute a very naive policy gradient calculation by taking the whole discounted return of a trajectory. Fill out the method <code>_discounted_return</code> in <code>pg_agent.py</code>. Your error should be 1e-6 or lower."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### Test return computation\n",
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'CartPole'\n",
    "pg_args['env_name'] = '{}-v0'.format(env_str)\n",
    "pgtrainer = PG_Trainer(pg_args)\n",
    "pgagent = pgtrainer.rl_trainer.agent\n",
    "\n",
    "T = 10\n",
    "np.random.seed(0)\n",
    "rewards = np.random.normal(size=T)\n",
    "discounted_returns = pgagent._discounted_return(rewards)\n",
    "\n",
    "expected_return = 6.49674307\n",
    "return_error = rel_error(discounted_returns, expected_return)\n",
    "print(\"Error in return estimate is\", return_error)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "########################\n",
      "logging outputs to  test\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "CartPole-v0\n",
      "Error in return estimate is 1.3988385848769778e-10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll consider a return estimate with lower variance by taking the discounted reward-to-go at each timestep instead of the entire discounted return. More precisely, instead of taking $\\sum_{t'=0}^T \\gamma^{t'} r_{t'}$ as the return estimate for all timesteps $t$, we will instead use $\\sum_{t'=t}^T \\gamma^{t' - t} r_{t'}$ for the return estimate at timestep $t$. Fill out the method <code>_discounted_cumsum</code> in <code>pg_agent.py</code>.   Your error should be 1e-6 or lower."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "### Test reward to go computations\n",
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'CartPole'\n",
    "pg_args['env_name'] = '{}-v0'.format(env_str)\n",
    "pgtrainer = PG_Trainer(pg_args)\n",
    "pgagent = pgtrainer.rl_trainer.agent\n",
    "\n",
    "T = 10\n",
    "np.random.seed(0)\n",
    "rewards = np.random.normal(size=T)\n",
    "discounted_cumsum = pgagent._discounted_cumsum(rewards)\n",
    "expected_cumsum = np.array([6.49674307, 4.98177971, 4.82276053, 4.04633952, 1.90046981, 0.03464402,\n",
    " 1.06518095, 0.12115003, 0.28684973, 0.4105985])\n",
    "\n",
    "return_error = rel_error(discounted_cumsum, expected_cumsum)\n",
    "print(\"Error in return estimate is\", return_error)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "########################\n",
      "logging outputs to  test\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "CartPole-v0\n",
      "Error in return estimate is 1.0143655677664199e-08\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we'll use our return estimates to compute a policy gradient. Fill out the surrogate loss computation in the <code>update</code> method in MLPPolicyPG class in <code>policies/MLP_policy.py</code>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Test policy gradient (check gradients match what we expect)\n",
    "torch.manual_seed(0)\n",
    "ac_dim = 2\n",
    "ob_dim = 3\n",
    "batch_size = 5\n",
    "\n",
    "policy = MLPPolicyPG(\n",
    "            ac_dim=ac_dim,\n",
    "            ob_dim=ob_dim,\n",
    "            n_layers=1,\n",
    "            size=2,\n",
    "            learning_rate=0.25)\n",
    "\n",
    "np.random.seed(0)\n",
    "obs = np.random.normal(size=(batch_size, ob_dim))\n",
    "acts = np.random.normal(size=(batch_size, ac_dim))\n",
    "advs = 1000 * np.random.normal(size=(batch_size,))\n",
    "\n",
    "first_weight_before = np.array(ptu.to_numpy(next(policy.mean_net.parameters())))\n",
    "print(\"Weight before update\", first_weight_before)\n",
    "\n",
    "for i in range(5):\n",
    "    loss = policy.update(obs, acts, advs)['Training Loss']\n",
    "\n",
    "print(loss)\n",
    "expected_loss = -6142.9116\n",
    "loss_error = rel_error(loss, expected_loss)\n",
    "print(\"Loss Error\", loss_error, \"should be on the order of 1e-6 or lower\")\n",
    "\n",
    "first_weight_after = ptu.to_numpy(next(policy.mean_net.parameters()))\n",
    "print('Weight after update', first_weight_after)\n",
    "\n",
    "weight_change = first_weight_after - first_weight_before\n",
    "print(\"Change in weights\", weight_change)\n",
    "\n",
    "expected_change = np.array([[ 1.035012, 1.0455959, 0.11085394],\n",
    "                            [-1.1532364, -0.5915445, 0.557522]])\n",
    "updated_weight_error = rel_error(weight_change, expected_change)\n",
    "print(\"Weight Update Error\", updated_weight_error, \"should be on the order of 1e-6 or lower\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can compare the two return estimators on a simple environment and compare how well they do. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'CartPole'\n",
    "pg_args['env_name'] = '{}-v0'.format(env_str)\n",
    "pg_args['reward_to_go'] = False\n",
    "pg_args['n_iter'] = 100\n",
    "\n",
    "# Delete all previous logs\n",
    "remove_folder('logs/policy_gradient/{}/full_returns/'.format(env_str))\n",
    "\n",
    "for seed in range(3):\n",
    "    print(\"Running policy gradient experiment with seed\", seed)\n",
    "    pg_args['seed'] = seed\n",
    "    pg_args['logdir'] = 'logs/policy_gradient/{}/full_returns/seed{}'.format(env_str, seed)\n",
    "    pgtrainer = PG_Trainer(pg_args)\n",
    "    pgtrainer.run_training_loop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'CartPole'\n",
    "pg_args['env_name'] = '{}-v0'.format(env_str)\n",
    "pg_args['reward_to_go'] = True\n",
    "pg_args['n_iter'] = 100\n",
    "\n",
    "# Delete all previous logs\n",
    "remove_folder('logs/policy_gradient/{}/return_to_go/'.format(env_str))\n",
    "\n",
    "for seed in range(3):\n",
    "    print(\"Running policy gradient experiment with seed\", seed)\n",
    "    pg_args['seed'] = seed\n",
    "    pg_args['logdir'] = 'logs/policy_gradient/{}/return_to_go/seed{}'.format(env_str, seed)\n",
    "    pgtrainer = PG_Trainer(pg_args)\n",
    "    pgtrainer.run_training_loop()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We should see the reward to go estimator outperforming the full returns estimator, with some runs reaching the maximum reward of 200. There will likely however be high variance between runs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Visualize Policy Gradient results on CartPole\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/policy_gradient/CartPole"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also compare our estimators on a more complex task, though you will probably see that they don't perform well (not getting much above 200 returns). Note that on this more complex task, we use a much larger batch size to reduce variance in the policy gradients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'Hopper'\n",
    "pg_args['env_name'] = '{}-v2'.format(env_str)\n",
    "pg_args['learning_rate'] = 0.01\n",
    "pg_args['reward_to_go'] = False\n",
    "pg_args['batch_size'] = 10000\n",
    "pg_args['train_batch_size'] = 10000\n",
    "pg_args['n_iter'] = 100\n",
    "\n",
    "# Delete all previous logs\n",
    "remove_folder('logs/policy_gradient/{}/full_returns/'.format(env_str))\n",
    "\n",
    "for seed in range(3):\n",
    "    print(\"Running policy gradient experiment with seed\", seed)\n",
    "    pg_args['seed'] = seed\n",
    "    pg_args['logdir'] = 'logs/policy_gradient/{}/full_returns/seed{}'.format(env_str, seed)\n",
    "    pgtrainer = PG_Trainer(pg_args)\n",
    "    pgtrainer.run_training_loop()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 119.14203643798828\n",
      "Eval_StdReturn : 22.49319839477539\n",
      "Eval_MaxReturn : 151.5212860107422\n",
      "Eval_MinReturn : 50.666725158691406\n",
      "Eval_AverageEpLen : 66.0625\n",
      "Train_AverageReturn : 114.07244110107422\n",
      "Train_StdReturn : 24.500097274780273\n",
      "Train_MaxReturn : 182.06915283203125\n",
      "Train_MinReturn : 46.825748443603516\n",
      "Train_AverageEpLen : 63.58860759493671\n",
      "Train_EnvstepsSoFar : 501828\n",
      "TimeSinceStart : 291.1553752422333\n",
      "Training Loss : 130.89877319335938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10052 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 121.04612731933594\n",
      "Eval_StdReturn : 23.297969818115234\n",
      "Eval_MaxReturn : 147.4799041748047\n",
      "Eval_MinReturn : 49.36442947387695\n",
      "Eval_AverageEpLen : 66.75\n",
      "Train_AverageReturn : 122.50398254394531\n",
      "Train_StdReturn : 21.046571731567383\n",
      "Train_MaxReturn : 190.8625946044922\n",
      "Train_MinReturn : 47.51467514038086\n",
      "Train_AverageEpLen : 67.46308724832215\n",
      "Train_EnvstepsSoFar : 511880\n",
      "TimeSinceStart : 297.1748003959656\n",
      "Training Loss : 132.6505584716797\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10058 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 135.49046325683594\n",
      "Eval_StdReturn : 22.069786071777344\n",
      "Eval_MaxReturn : 184.22994995117188\n",
      "Eval_MinReturn : 103.97203063964844\n",
      "Eval_AverageEpLen : 73.28571428571429\n",
      "Train_AverageReturn : 120.8250961303711\n",
      "Train_StdReturn : 24.24456214904785\n",
      "Train_MaxReturn : 191.3162841796875\n",
      "Train_MinReturn : 49.29986572265625\n",
      "Train_AverageEpLen : 66.6092715231788\n",
      "Train_EnvstepsSoFar : 521938\n",
      "TimeSinceStart : 303.3667633533478\n",
      "Training Loss : 132.7842254638672\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 111.87858581542969\n",
      "Eval_StdReturn : 29.751537322998047\n",
      "Eval_MaxReturn : 163.79156494140625\n",
      "Eval_MinReturn : 50.96563720703125\n",
      "Eval_AverageEpLen : 62.588235294117645\n",
      "Train_AverageReturn : 123.3046875\n",
      "Train_StdReturn : 24.518585205078125\n",
      "Train_MaxReturn : 172.48727416992188\n",
      "Train_MinReturn : 46.26451110839844\n",
      "Train_AverageEpLen : 67.63513513513513\n",
      "Train_EnvstepsSoFar : 531948\n",
      "TimeSinceStart : 309.4867343902588\n",
      "Training Loss : 132.93849182128906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 128.2114715576172\n",
      "Eval_StdReturn : 18.71772003173828\n",
      "Eval_MaxReturn : 167.8057403564453\n",
      "Eval_MinReturn : 101.19175720214844\n",
      "Eval_AverageEpLen : 70.26666666666667\n",
      "Train_AverageReturn : 123.84747314453125\n",
      "Train_StdReturn : 24.278339385986328\n",
      "Train_MaxReturn : 177.02822875976562\n",
      "Train_MinReturn : 49.55580520629883\n",
      "Train_AverageEpLen : 68.03401360544218\n",
      "Train_EnvstepsSoFar : 541949\n",
      "TimeSinceStart : 315.07489466667175\n",
      "Training Loss : 133.25753784179688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10033 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 118.78117370605469\n",
      "Eval_StdReturn : 21.405902862548828\n",
      "Eval_MaxReturn : 141.76902770996094\n",
      "Eval_MinReturn : 54.27899169921875\n",
      "Eval_AverageEpLen : 65.9375\n",
      "Train_AverageReturn : 122.08055114746094\n",
      "Train_StdReturn : 24.899213790893555\n",
      "Train_MaxReturn : 190.35186767578125\n",
      "Train_MinReturn : 47.53677749633789\n",
      "Train_AverageEpLen : 67.33557046979865\n",
      "Train_EnvstepsSoFar : 551982\n",
      "TimeSinceStart : 321.04942321777344\n",
      "Training Loss : 132.6832275390625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 122.27671813964844\n",
      "Eval_StdReturn : 15.624317169189453\n",
      "Eval_MaxReturn : 145.2368927001953\n",
      "Eval_MinReturn : 96.7559585571289\n",
      "Eval_AverageEpLen : 67.2\n",
      "Train_AverageReturn : 120.78353881835938\n",
      "Train_StdReturn : 24.345760345458984\n",
      "Train_MaxReturn : 163.1405029296875\n",
      "Train_MinReturn : 47.571022033691406\n",
      "Train_AverageEpLen : 66.68666666666667\n",
      "Train_EnvstepsSoFar : 561985\n",
      "TimeSinceStart : 326.8825855255127\n",
      "Training Loss : 132.46237182617188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 124.05565643310547\n",
      "Eval_StdReturn : 22.904008865356445\n",
      "Eval_MaxReturn : 182.76438903808594\n",
      "Eval_MinReturn : 95.46936798095703\n",
      "Eval_AverageEpLen : 68.4\n",
      "Train_AverageReturn : 122.53974151611328\n",
      "Train_StdReturn : 22.44059944152832\n",
      "Train_MaxReturn : 181.66299438476562\n",
      "Train_MinReturn : 52.912025451660156\n",
      "Train_AverageEpLen : 67.55704697986577\n",
      "Train_EnvstepsSoFar : 572051\n",
      "TimeSinceStart : 332.52202558517456\n",
      "Training Loss : 132.71849060058594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 105.5025634765625\n",
      "Eval_StdReturn : 22.73848533630371\n",
      "Eval_MaxReturn : 138.19070434570312\n",
      "Eval_MinReturn : 51.39418411254883\n",
      "Eval_AverageEpLen : 60.411764705882355\n",
      "Train_AverageReturn : 115.6633071899414\n",
      "Train_StdReturn : 22.574411392211914\n",
      "Train_MaxReturn : 182.34353637695312\n",
      "Train_MinReturn : 63.72014617919922\n",
      "Train_AverageEpLen : 64.59354838709677\n",
      "Train_EnvstepsSoFar : 582063\n",
      "TimeSinceStart : 338.7259430885315\n",
      "Training Loss : 131.61428833007812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 108.76810455322266\n",
      "Eval_StdReturn : 19.279115676879883\n",
      "Eval_MaxReturn : 137.4833526611328\n",
      "Eval_MinReturn : 70.537841796875\n",
      "Eval_AverageEpLen : 61.588235294117645\n",
      "Train_AverageReturn : 111.90369415283203\n",
      "Train_StdReturn : 20.922834396362305\n",
      "Train_MaxReturn : 156.07073974609375\n",
      "Train_MinReturn : 54.04077911376953\n",
      "Train_AverageEpLen : 63.0503144654088\n",
      "Train_EnvstepsSoFar : 592088\n",
      "TimeSinceStart : 344.9104378223419\n",
      "Training Loss : 130.55015563964844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 85.73503112792969\n",
      "Eval_StdReturn : 32.552242279052734\n",
      "Eval_MaxReturn : 138.65936279296875\n",
      "Eval_MinReturn : 20.97986602783203\n",
      "Eval_AverageEpLen : 50.2\n",
      "Train_AverageReturn : 101.54022979736328\n",
      "Train_StdReturn : 24.25782585144043\n",
      "Train_MaxReturn : 157.50595092773438\n",
      "Train_MinReturn : 18.95108985900879\n",
      "Train_AverageEpLen : 58.16860465116279\n",
      "Train_EnvstepsSoFar : 602093\n",
      "TimeSinceStart : 350.525678396225\n",
      "Training Loss : 128.04656982421875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 71.02511596679688\n",
      "Eval_StdReturn : 41.808448791503906\n",
      "Eval_MaxReturn : 134.38827514648438\n",
      "Eval_MinReturn : 14.367737770080566\n",
      "Eval_AverageEpLen : 41.88\n",
      "Train_AverageReturn : 85.91057586669922\n",
      "Train_StdReturn : 34.74787139892578\n",
      "Train_MaxReturn : 151.9736328125\n",
      "Train_MinReturn : 14.800808906555176\n",
      "Train_AverageEpLen : 50.045\n",
      "Train_EnvstepsSoFar : 612102\n",
      "TimeSinceStart : 356.38552021980286\n",
      "Training Loss : 124.47035217285156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 91.1561508178711\n",
      "Eval_StdReturn : 26.86305809020996\n",
      "Eval_MaxReturn : 122.4799575805664\n",
      "Eval_MinReturn : 20.667997360229492\n",
      "Eval_AverageEpLen : 53.21052631578947\n",
      "Train_AverageReturn : 80.26929473876953\n",
      "Train_StdReturn : 36.563629150390625\n",
      "Train_MaxReturn : 154.4004669189453\n",
      "Train_MinReturn : 17.088138580322266\n",
      "Train_AverageEpLen : 47.2311320754717\n",
      "Train_EnvstepsSoFar : 622115\n",
      "TimeSinceStart : 362.19246673583984\n",
      "Training Loss : 122.89612579345703\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 96.64012908935547\n",
      "Eval_StdReturn : 25.88378143310547\n",
      "Eval_MaxReturn : 133.6407470703125\n",
      "Eval_MinReturn : 20.981904983520508\n",
      "Eval_AverageEpLen : 55.72222222222222\n",
      "Train_AverageReturn : 91.98696899414062\n",
      "Train_StdReturn : 31.093080520629883\n",
      "Train_MaxReturn : 142.52252197265625\n",
      "Train_MinReturn : 18.793989181518555\n",
      "Train_AverageEpLen : 53.68449197860963\n",
      "Train_EnvstepsSoFar : 632154\n",
      "TimeSinceStart : 368.0536918640137\n",
      "Training Loss : 126.01642608642578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 103.09906005859375\n",
      "Eval_StdReturn : 18.820173263549805\n",
      "Eval_MaxReturn : 137.73190307617188\n",
      "Eval_MinReturn : 61.256797790527344\n",
      "Eval_AverageEpLen : 59.1764705882353\n",
      "Train_AverageReturn : 104.54138946533203\n",
      "Train_StdReturn : 22.781312942504883\n",
      "Train_MaxReturn : 140.53175354003906\n",
      "Train_MinReturn : 23.101333618164062\n",
      "Train_AverageEpLen : 59.80357142857143\n",
      "Train_EnvstepsSoFar : 642201\n",
      "TimeSinceStart : 373.7491934299469\n",
      "Training Loss : 129.58187866210938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10041 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 107.46578979492188\n",
      "Eval_StdReturn : 25.505016326904297\n",
      "Eval_MaxReturn : 136.27134704589844\n",
      "Eval_MinReturn : 62.460086822509766\n",
      "Eval_AverageEpLen : 61.705882352941174\n",
      "Train_AverageReturn : 103.12509155273438\n",
      "Train_StdReturn : 28.132692337036133\n",
      "Train_MaxReturn : 173.23863220214844\n",
      "Train_MinReturn : 15.098640441894531\n",
      "Train_AverageEpLen : 59.06470588235294\n",
      "Train_EnvstepsSoFar : 652242\n",
      "TimeSinceStart : 379.9293882846832\n",
      "Training Loss : 128.77565002441406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10034 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 95.7528305053711\n",
      "Eval_StdReturn : 31.2321834564209\n",
      "Eval_MaxReturn : 144.16847229003906\n",
      "Eval_MinReturn : 51.48296356201172\n",
      "Eval_AverageEpLen : 55.68421052631579\n",
      "Train_AverageReturn : 98.02396392822266\n",
      "Train_StdReturn : 30.855249404907227\n",
      "Train_MaxReturn : 140.90367126464844\n",
      "Train_MinReturn : 2.225435733795166\n",
      "Train_AverageEpLen : 56.68926553672316\n",
      "Train_EnvstepsSoFar : 662276\n",
      "TimeSinceStart : 385.9698295593262\n",
      "Training Loss : 128.27914428710938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 65.98609924316406\n",
      "Eval_StdReturn : 21.176712036132812\n",
      "Eval_MaxReturn : 131.81417846679688\n",
      "Eval_MinReturn : 46.52072525024414\n",
      "Eval_AverageEpLen : 39.11538461538461\n",
      "Train_AverageReturn : 85.1570053100586\n",
      "Train_StdReturn : 31.723623275756836\n",
      "Train_MaxReturn : 147.35647583007812\n",
      "Train_MinReturn : 15.29809856414795\n",
      "Train_AverageEpLen : 49.318627450980394\n",
      "Train_EnvstepsSoFar : 672337\n",
      "TimeSinceStart : 392.013596534729\n",
      "Training Loss : 125.52820587158203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 69.56763458251953\n",
      "Eval_StdReturn : 26.87662124633789\n",
      "Eval_MaxReturn : 128.5906524658203\n",
      "Eval_MinReturn : 48.95218276977539\n",
      "Eval_AverageEpLen : 40.84\n",
      "Train_AverageReturn : 78.35481262207031\n",
      "Train_StdReturn : 31.134798049926758\n",
      "Train_MaxReturn : 142.8903350830078\n",
      "Train_MinReturn : 0.9105803966522217\n",
      "Train_AverageEpLen : 46.55348837209302\n",
      "Train_EnvstepsSoFar : 682346\n",
      "TimeSinceStart : 398.01659083366394\n",
      "Training Loss : 121.34794616699219\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 70.16845703125\n",
      "Eval_StdReturn : 21.349401473999023\n",
      "Eval_MaxReturn : 123.40713500976562\n",
      "Eval_MinReturn : 49.797203063964844\n",
      "Eval_AverageEpLen : 41.791666666666664\n",
      "Train_AverageReturn : 72.5763168334961\n",
      "Train_StdReturn : 27.370182037353516\n",
      "Train_MaxReturn : 139.405517578125\n",
      "Train_MinReturn : 47.2528076171875\n",
      "Train_AverageEpLen : 42.81623931623932\n",
      "Train_EnvstepsSoFar : 692365\n",
      "TimeSinceStart : 403.89222860336304\n",
      "Training Loss : 120.15296173095703\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 85.8382568359375\n",
      "Eval_StdReturn : 31.850276947021484\n",
      "Eval_MaxReturn : 135.8750762939453\n",
      "Eval_MinReturn : 49.921531677246094\n",
      "Eval_AverageEpLen : 50.38095238095238\n",
      "Train_AverageReturn : 81.49237060546875\n",
      "Train_StdReturn : 29.850688934326172\n",
      "Train_MaxReturn : 142.79307556152344\n",
      "Train_MinReturn : 46.45546340942383\n",
      "Train_AverageEpLen : 47.55924170616114\n",
      "Train_EnvstepsSoFar : 702400\n",
      "TimeSinceStart : 409.44297218322754\n",
      "Training Loss : 124.9787368774414\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 99.83242797851562\n",
      "Eval_StdReturn : 30.445371627807617\n",
      "Eval_MaxReturn : 140.34153747558594\n",
      "Eval_MinReturn : 53.96809768676758\n",
      "Eval_AverageEpLen : 57.27777777777778\n",
      "Train_AverageReturn : 86.09112548828125\n",
      "Train_StdReturn : 30.373090744018555\n",
      "Train_MaxReturn : 149.010498046875\n",
      "Train_MinReturn : 50.187557220458984\n",
      "Train_AverageEpLen : 50.79187817258883\n",
      "Train_EnvstepsSoFar : 712406\n",
      "TimeSinceStart : 414.89535188674927\n",
      "Training Loss : 124.59474182128906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 110.40110778808594\n",
      "Eval_StdReturn : 37.83035659790039\n",
      "Eval_MaxReturn : 198.8006591796875\n",
      "Eval_MinReturn : 63.83142852783203\n",
      "Eval_AverageEpLen : 63.6875\n",
      "Train_AverageReturn : 100.85172271728516\n",
      "Train_StdReturn : 32.10983657836914\n",
      "Train_MaxReturn : 201.5802459716797\n",
      "Train_MinReturn : 50.9083366394043\n",
      "Train_AverageEpLen : 57.994219653179194\n",
      "Train_EnvstepsSoFar : 722439\n",
      "TimeSinceStart : 420.3605477809906\n",
      "Training Loss : 130.42205810546875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 132.76658630371094\n",
      "Eval_StdReturn : 38.16066360473633\n",
      "Eval_MaxReturn : 196.60072326660156\n",
      "Eval_MinReturn : 71.87998962402344\n",
      "Eval_AverageEpLen : 75.07142857142857\n",
      "Train_AverageReturn : 107.30733489990234\n",
      "Train_StdReturn : 32.039432525634766\n",
      "Train_MaxReturn : 182.61953735351562\n",
      "Train_MinReturn : 2.422227621078491\n",
      "Train_AverageEpLen : 61.374233128834355\n",
      "Train_EnvstepsSoFar : 732443\n",
      "TimeSinceStart : 425.8033559322357\n",
      "Training Loss : 131.19451904296875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 133.46156311035156\n",
      "Eval_StdReturn : 24.436203002929688\n",
      "Eval_MaxReturn : 178.21353149414062\n",
      "Eval_MinReturn : 88.94463348388672\n",
      "Eval_AverageEpLen : 75.0\n",
      "Train_AverageReturn : 119.11172485351562\n",
      "Train_StdReturn : 27.495563507080078\n",
      "Train_MaxReturn : 164.63323974609375\n",
      "Train_MinReturn : 8.741716384887695\n",
      "Train_AverageEpLen : 68.29251700680273\n",
      "Train_EnvstepsSoFar : 742482\n",
      "TimeSinceStart : 431.24657940864563\n",
      "Training Loss : 133.1009521484375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10032 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 130.85586547851562\n",
      "Eval_StdReturn : 22.745121002197266\n",
      "Eval_MaxReturn : 164.01365661621094\n",
      "Eval_MinReturn : 87.53059387207031\n",
      "Eval_AverageEpLen : 72.57142857142857\n",
      "Train_AverageReturn : 127.9455337524414\n",
      "Train_StdReturn : 30.368928909301758\n",
      "Train_MaxReturn : 261.6262512207031\n",
      "Train_MinReturn : 58.08476638793945\n",
      "Train_AverageEpLen : 71.65714285714286\n",
      "Train_EnvstepsSoFar : 752514\n",
      "TimeSinceStart : 436.70701003074646\n",
      "Training Loss : 134.0747833251953\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10152 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 148.489990234375\n",
      "Eval_StdReturn : 36.184234619140625\n",
      "Eval_MaxReturn : 237.0439453125\n",
      "Eval_MinReturn : 93.62631225585938\n",
      "Eval_AverageEpLen : 79.42857142857143\n",
      "Train_AverageReturn : 135.2655029296875\n",
      "Train_StdReturn : 27.36281394958496\n",
      "Train_MaxReturn : 254.080078125\n",
      "Train_MinReturn : 66.5494613647461\n",
      "Train_AverageEpLen : 74.6470588235294\n",
      "Train_EnvstepsSoFar : 762666\n",
      "TimeSinceStart : 442.1785304546356\n",
      "Training Loss : 136.70457458496094\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 153.17584228515625\n",
      "Eval_StdReturn : 39.53798294067383\n",
      "Eval_MaxReturn : 232.78482055664062\n",
      "Eval_MinReturn : 95.93869018554688\n",
      "Eval_AverageEpLen : 81.15384615384616\n",
      "Train_AverageReturn : 135.32711791992188\n",
      "Train_StdReturn : 30.876079559326172\n",
      "Train_MaxReturn : 300.0885925292969\n",
      "Train_MinReturn : 63.61539077758789\n",
      "Train_AverageEpLen : 74.33333333333333\n",
      "Train_EnvstepsSoFar : 772701\n",
      "TimeSinceStart : 447.56586050987244\n",
      "Training Loss : 136.2387237548828\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 139.29164123535156\n",
      "Eval_StdReturn : 25.85468864440918\n",
      "Eval_MaxReturn : 193.22735595703125\n",
      "Eval_MinReturn : 88.77174377441406\n",
      "Eval_AverageEpLen : 73.78571428571429\n",
      "Train_AverageReturn : 136.29994201660156\n",
      "Train_StdReturn : 29.96925926208496\n",
      "Train_MaxReturn : 261.7867126464844\n",
      "Train_MinReturn : 3.034640073776245\n",
      "Train_AverageEpLen : 74.56296296296296\n",
      "Train_EnvstepsSoFar : 782767\n",
      "TimeSinceStart : 453.0151159763336\n",
      "Training Loss : 135.7052001953125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 123.64555358886719\n",
      "Eval_StdReturn : 24.916748046875\n",
      "Eval_MaxReturn : 178.2642822265625\n",
      "Eval_MinReturn : 84.52479553222656\n",
      "Eval_AverageEpLen : 67.5\n",
      "Train_AverageReturn : 137.0811767578125\n",
      "Train_StdReturn : 45.97237014770508\n",
      "Train_MaxReturn : 489.7703857421875\n",
      "Train_MinReturn : 56.13432312011719\n",
      "Train_AverageEpLen : 73.66176470588235\n",
      "Train_EnvstepsSoFar : 792785\n",
      "TimeSinceStart : 458.4378409385681\n",
      "Training Loss : 136.74557495117188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10053 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 124.33000183105469\n",
      "Eval_StdReturn : 31.01078987121582\n",
      "Eval_MaxReturn : 189.0300750732422\n",
      "Eval_MinReturn : 83.20911407470703\n",
      "Eval_AverageEpLen : 68.8\n",
      "Train_AverageReturn : 139.06922912597656\n",
      "Train_StdReturn : 33.917823791503906\n",
      "Train_MaxReturn : 241.79100036621094\n",
      "Train_MinReturn : 29.238609313964844\n",
      "Train_AverageEpLen : 75.0223880597015\n",
      "Train_EnvstepsSoFar : 802838\n",
      "TimeSinceStart : 463.8449447154999\n",
      "Training Loss : 136.525390625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10088 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 142.74734497070312\n",
      "Eval_StdReturn : 55.240474700927734\n",
      "Eval_MaxReturn : 280.454833984375\n",
      "Eval_MinReturn : 99.49954986572266\n",
      "Eval_AverageEpLen : 74.28571428571429\n",
      "Train_AverageReturn : 131.4984130859375\n",
      "Train_StdReturn : 44.02287673950195\n",
      "Train_MaxReturn : 439.186279296875\n",
      "Train_MinReturn : 4.718924522399902\n",
      "Train_AverageEpLen : 70.54545454545455\n",
      "Train_EnvstepsSoFar : 812926\n",
      "TimeSinceStart : 469.20503997802734\n",
      "Training Loss : 135.96994018554688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 120.0819320678711\n",
      "Eval_StdReturn : 16.86972427368164\n",
      "Eval_MaxReturn : 152.4407501220703\n",
      "Eval_MinReturn : 88.46794891357422\n",
      "Eval_AverageEpLen : 66.0\n",
      "Train_AverageReturn : 129.2281951904297\n",
      "Train_StdReturn : 38.73133850097656\n",
      "Train_MaxReturn : 282.8722839355469\n",
      "Train_MinReturn : 14.022079467773438\n",
      "Train_AverageEpLen : 69.45833333333333\n",
      "Train_EnvstepsSoFar : 822928\n",
      "TimeSinceStart : 474.61673307418823\n",
      "Training Loss : 135.0388946533203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 125.52729797363281\n",
      "Eval_StdReturn : 35.992706298828125\n",
      "Eval_MaxReturn : 214.32452392578125\n",
      "Eval_MinReturn : 94.4655990600586\n",
      "Eval_AverageEpLen : 68.13333333333334\n",
      "Train_AverageReturn : 129.27256774902344\n",
      "Train_StdReturn : 54.659019470214844\n",
      "Train_MaxReturn : 393.5256042480469\n",
      "Train_MinReturn : 18.54732894897461\n",
      "Train_AverageEpLen : 68.55479452054794\n",
      "Train_EnvstepsSoFar : 832937\n",
      "TimeSinceStart : 480.0777897834778\n",
      "Training Loss : 134.24703979492188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 120.96583557128906\n",
      "Eval_StdReturn : 52.30227279663086\n",
      "Eval_MaxReturn : 291.36065673828125\n",
      "Eval_MinReturn : 51.85994338989258\n",
      "Eval_AverageEpLen : 64.9375\n",
      "Train_AverageReturn : 124.50971221923828\n",
      "Train_StdReturn : 61.13334274291992\n",
      "Train_MaxReturn : 457.45556640625\n",
      "Train_MinReturn : 7.54105806350708\n",
      "Train_AverageEpLen : 66.48344370860927\n",
      "Train_EnvstepsSoFar : 842976\n",
      "TimeSinceStart : 485.46308946609497\n",
      "Training Loss : 131.71449279785156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 120.97087097167969\n",
      "Eval_StdReturn : 72.33710479736328\n",
      "Eval_MaxReturn : 281.39141845703125\n",
      "Eval_MinReturn : 2.928790330886841\n",
      "Eval_AverageEpLen : 64.4375\n",
      "Train_AverageReturn : 126.61277770996094\n",
      "Train_StdReturn : 61.067134857177734\n",
      "Train_MaxReturn : 366.5703125\n",
      "Train_MinReturn : 32.38238525390625\n",
      "Train_AverageEpLen : 66.45695364238411\n",
      "Train_EnvstepsSoFar : 853011\n",
      "TimeSinceStart : 490.8573124408722\n",
      "Training Loss : 133.10617065429688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 117.2619400024414\n",
      "Eval_StdReturn : 55.70039749145508\n",
      "Eval_MaxReturn : 286.7821044921875\n",
      "Eval_MinReturn : 89.3574447631836\n",
      "Eval_AverageEpLen : 61.705882352941174\n",
      "Train_AverageReturn : 120.26883697509766\n",
      "Train_StdReturn : 71.54515075683594\n",
      "Train_MaxReturn : 521.2310180664062\n",
      "Train_MinReturn : 1.200642466545105\n",
      "Train_AverageEpLen : 63.46835443037975\n",
      "Train_EnvstepsSoFar : 863039\n",
      "TimeSinceStart : 496.25213074684143\n",
      "Training Loss : 132.38084411621094\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 104.64199829101562\n",
      "Eval_StdReturn : 38.8306770324707\n",
      "Eval_MaxReturn : 263.86785888671875\n",
      "Eval_MinReturn : 87.93561553955078\n",
      "Eval_AverageEpLen : 58.05555555555556\n",
      "Train_AverageReturn : 103.32581329345703\n",
      "Train_StdReturn : 46.81978988647461\n",
      "Train_MaxReturn : 386.3205261230469\n",
      "Train_MinReturn : 0.7706743478775024\n",
      "Train_AverageEpLen : 57.58045977011494\n",
      "Train_EnvstepsSoFar : 873058\n",
      "TimeSinceStart : 501.6917679309845\n",
      "Training Loss : 128.95191955566406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 105.86280822753906\n",
      "Eval_StdReturn : 41.243431091308594\n",
      "Eval_MaxReturn : 274.7232666015625\n",
      "Eval_MinReturn : 84.62429809570312\n",
      "Eval_AverageEpLen : 58.388888888888886\n",
      "Train_AverageReturn : 103.74372100830078\n",
      "Train_StdReturn : 39.87321090698242\n",
      "Train_MaxReturn : 312.3226013183594\n",
      "Train_MinReturn : 1.092461347579956\n",
      "Train_AverageEpLen : 57.907514450867055\n",
      "Train_EnvstepsSoFar : 883076\n",
      "TimeSinceStart : 507.62010979652405\n",
      "Training Loss : 129.14895629882812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 98.50534057617188\n",
      "Eval_StdReturn : 28.91281509399414\n",
      "Eval_MaxReturn : 216.5293426513672\n",
      "Eval_MinReturn : 81.50093078613281\n",
      "Eval_AverageEpLen : 55.666666666666664\n",
      "Train_AverageReturn : 97.8729248046875\n",
      "Train_StdReturn : 20.737316131591797\n",
      "Train_MaxReturn : 258.3849182128906\n",
      "Train_MinReturn : 50.63322830200195\n",
      "Train_AverageEpLen : 55.48066298342541\n",
      "Train_EnvstepsSoFar : 893118\n",
      "TimeSinceStart : 513.4886622428894\n",
      "Training Loss : 129.9290313720703\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 89.86054229736328\n",
      "Eval_StdReturn : 4.797637462615967\n",
      "Eval_MaxReturn : 99.02545928955078\n",
      "Eval_MinReturn : 82.64505767822266\n",
      "Eval_AverageEpLen : 51.6\n",
      "Train_AverageReturn : 92.85401916503906\n",
      "Train_StdReturn : 12.635778427124023\n",
      "Train_MaxReturn : 227.8017120361328\n",
      "Train_MinReturn : 81.44781494140625\n",
      "Train_AverageEpLen : 53.03703703703704\n",
      "Train_EnvstepsSoFar : 903142\n",
      "TimeSinceStart : 519.4416871070862\n",
      "Training Loss : 129.38485717773438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10032 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 87.56967163085938\n",
      "Eval_StdReturn : 4.705604076385498\n",
      "Eval_MaxReturn : 93.61792755126953\n",
      "Eval_MinReturn : 77.45328521728516\n",
      "Eval_AverageEpLen : 50.35\n",
      "Train_AverageReturn : 90.73438262939453\n",
      "Train_StdReturn : 15.335789680480957\n",
      "Train_MaxReturn : 279.86480712890625\n",
      "Train_MinReturn : 77.0916519165039\n",
      "Train_AverageEpLen : 51.979274611398964\n",
      "Train_EnvstepsSoFar : 913174\n",
      "TimeSinceStart : 525.2756910324097\n",
      "Training Loss : 128.92507934570312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 86.40040588378906\n",
      "Eval_StdReturn : 8.840645790100098\n",
      "Eval_MaxReturn : 100.31236267089844\n",
      "Eval_MinReturn : 54.96196746826172\n",
      "Eval_AverageEpLen : 49.76190476190476\n",
      "Train_AverageReturn : 87.90032958984375\n",
      "Train_StdReturn : 5.288760185241699\n",
      "Train_MaxReturn : 108.2454833984375\n",
      "Train_MinReturn : 78.06998443603516\n",
      "Train_AverageEpLen : 50.65151515151515\n",
      "Train_EnvstepsSoFar : 923203\n",
      "TimeSinceStart : 531.0715832710266\n",
      "Training Loss : 128.21376037597656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 86.7164306640625\n",
      "Eval_StdReturn : 4.902565956115723\n",
      "Eval_MaxReturn : 96.51823425292969\n",
      "Eval_MinReturn : 78.6961669921875\n",
      "Eval_AverageEpLen : 49.95238095238095\n",
      "Train_AverageReturn : 89.13817596435547\n",
      "Train_StdReturn : 13.317843437194824\n",
      "Train_MaxReturn : 232.36363220214844\n",
      "Train_MinReturn : 54.50701904296875\n",
      "Train_AverageEpLen : 51.08163265306123\n",
      "Train_EnvstepsSoFar : 933215\n",
      "TimeSinceStart : 536.9425027370453\n",
      "Training Loss : 129.34326171875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 83.0506591796875\n",
      "Eval_StdReturn : 10.205706596374512\n",
      "Eval_MaxReturn : 95.22284698486328\n",
      "Eval_MinReturn : 48.59373474121094\n",
      "Eval_AverageEpLen : 48.333333333333336\n",
      "Train_AverageReturn : 85.2696304321289\n",
      "Train_StdReturn : 9.877935409545898\n",
      "Train_MaxReturn : 110.53575134277344\n",
      "Train_MinReturn : 1.0230281352996826\n",
      "Train_AverageEpLen : 49.443349753694584\n",
      "Train_EnvstepsSoFar : 943252\n",
      "TimeSinceStart : 542.627445936203\n",
      "Training Loss : 128.17169189453125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 73.93083190917969\n",
      "Eval_StdReturn : 20.058168411254883\n",
      "Eval_MaxReturn : 93.10658264160156\n",
      "Eval_MinReturn : 2.116868495941162\n",
      "Eval_AverageEpLen : 44.73913043478261\n",
      "Train_AverageReturn : 81.06488800048828\n",
      "Train_StdReturn : 13.423724174499512\n",
      "Train_MaxReturn : 97.695556640625\n",
      "Train_MinReturn : 0.06466591358184814\n",
      "Train_AverageEpLen : 47.40758293838863\n",
      "Train_EnvstepsSoFar : 953255\n",
      "TimeSinceStart : 548.249449968338\n",
      "Training Loss : 125.86731719970703\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 66.63008880615234\n",
      "Eval_StdReturn : 18.05498695373535\n",
      "Eval_MaxReturn : 91.1727294921875\n",
      "Eval_MinReturn : 45.078067779541016\n",
      "Eval_AverageEpLen : 40.96\n",
      "Train_AverageReturn : 71.24799346923828\n",
      "Train_StdReturn : 18.719030380249023\n",
      "Train_MaxReturn : 119.74514770507812\n",
      "Train_MinReturn : 1.284938097000122\n",
      "Train_AverageEpLen : 43.07725321888412\n",
      "Train_EnvstepsSoFar : 963292\n",
      "TimeSinceStart : 553.9890229701996\n",
      "Training Loss : 120.62905883789062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 60.670528411865234\n",
      "Eval_StdReturn : 17.99647331237793\n",
      "Eval_MaxReturn : 90.13404846191406\n",
      "Eval_MinReturn : 43.40486526489258\n",
      "Eval_AverageEpLen : 37.96296296296296\n",
      "Train_AverageReturn : 64.4556655883789\n",
      "Train_StdReturn : 18.14912223815918\n",
      "Train_MaxReturn : 128.16146850585938\n",
      "Train_MinReturn : 42.498416900634766\n",
      "Train_AverageEpLen : 39.79365079365079\n",
      "Train_EnvstepsSoFar : 973320\n",
      "TimeSinceStart : 559.8078513145447\n",
      "Training Loss : 117.71808624267578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 65.12814331054688\n",
      "Eval_StdReturn : 20.269819259643555\n",
      "Eval_MaxReturn : 90.89642333984375\n",
      "Eval_MinReturn : 42.2159538269043\n",
      "Eval_AverageEpLen : 40.0\n",
      "Train_AverageReturn : 62.84623718261719\n",
      "Train_StdReturn : 19.608903884887695\n",
      "Train_MaxReturn : 104.33744049072266\n",
      "Train_MinReturn : 1.6953403949737549\n",
      "Train_AverageEpLen : 38.97276264591439\n",
      "Train_EnvstepsSoFar : 983336\n",
      "TimeSinceStart : 565.5770816802979\n",
      "Training Loss : 116.31206512451172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 62.45740509033203\n",
      "Eval_StdReturn : 19.756790161132812\n",
      "Eval_MaxReturn : 96.71244812011719\n",
      "Eval_MinReturn : 43.15980911254883\n",
      "Eval_AverageEpLen : 38.92307692307692\n",
      "Train_AverageReturn : 63.64152908325195\n",
      "Train_StdReturn : 20.815773010253906\n",
      "Train_MaxReturn : 122.98463439941406\n",
      "Train_MinReturn : 0.5189933776855469\n",
      "Train_AverageEpLen : 39.55511811023622\n",
      "Train_EnvstepsSoFar : 993383\n",
      "TimeSinceStart : 571.359696149826\n",
      "Training Loss : 116.10887908935547\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 51.33548355102539\n",
      "Eval_StdReturn : 17.632665634155273\n",
      "Eval_MaxReturn : 93.049560546875\n",
      "Eval_MinReturn : 2.7555625438690186\n",
      "Eval_AverageEpLen : 33.833333333333336\n",
      "Train_AverageReturn : 62.57081985473633\n",
      "Train_StdReturn : 20.969758987426758\n",
      "Train_MaxReturn : 118.3494644165039\n",
      "Train_MinReturn : 40.498085021972656\n",
      "Train_AverageEpLen : 38.961089494163424\n",
      "Train_EnvstepsSoFar : 1003396\n",
      "TimeSinceStart : 577.0905451774597\n",
      "Training Loss : 115.39261627197266\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "Running policy gradient experiment with seed 1\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/full_returns/seed1\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 156.0057830810547\n",
      "Eval_StdReturn : 61.87272262573242\n",
      "Eval_MaxReturn : 226.05661010742188\n",
      "Eval_MinReturn : 43.40686798095703\n",
      "Eval_AverageEpLen : 85.16666666666667\n",
      "Train_AverageReturn : 13.049403190612793\n",
      "Train_StdReturn : 8.314800262451172\n",
      "Train_MaxReturn : 61.080562591552734\n",
      "Train_MinReturn : 1.8022055625915527\n",
      "Train_AverageEpLen : 18.924385633270322\n",
      "Train_EnvstepsSoFar : 10011\n",
      "TimeSinceStart : 6.168463945388794\n",
      "Training Loss : 42.18347930908203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10017 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 151.44766235351562\n",
      "Eval_StdReturn : 37.795799255371094\n",
      "Eval_MaxReturn : 205.92271423339844\n",
      "Eval_MinReturn : 78.31697845458984\n",
      "Eval_AverageEpLen : 73.57142857142857\n",
      "Train_AverageReturn : 123.43399810791016\n",
      "Train_StdReturn : 76.6324691772461\n",
      "Train_MaxReturn : 295.7572326660156\n",
      "Train_MinReturn : 7.813671112060547\n",
      "Train_AverageEpLen : 71.04255319148936\n",
      "Train_EnvstepsSoFar : 20028\n",
      "TimeSinceStart : 12.018724203109741\n",
      "Training Loss : 103.69954681396484\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 178.64247131347656\n",
      "Eval_StdReturn : 43.044639587402344\n",
      "Eval_MaxReturn : 213.5027618408203\n",
      "Eval_MinReturn : 58.2458610534668\n",
      "Eval_AverageEpLen : 82.46153846153847\n",
      "Train_AverageReturn : 137.03216552734375\n",
      "Train_StdReturn : 50.0324592590332\n",
      "Train_MaxReturn : 222.59335327148438\n",
      "Train_MinReturn : 17.596506118774414\n",
      "Train_AverageEpLen : 69.47222222222223\n",
      "Train_EnvstepsSoFar : 30032\n",
      "TimeSinceStart : 17.820560932159424\n",
      "Training Loss : 121.56002807617188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 94.33336639404297\n",
      "Eval_StdReturn : 36.26255798339844\n",
      "Eval_MaxReturn : 199.69677734375\n",
      "Eval_MinReturn : 55.893314361572266\n",
      "Eval_AverageEpLen : 53.21052631578947\n",
      "Train_AverageReturn : 169.44898986816406\n",
      "Train_StdReturn : 48.03788375854492\n",
      "Train_MaxReturn : 221.86326599121094\n",
      "Train_MinReturn : 59.86515808105469\n",
      "Train_AverageEpLen : 78.74803149606299\n",
      "Train_EnvstepsSoFar : 40033\n",
      "TimeSinceStart : 23.594531536102295\n",
      "Training Loss : 127.8498764038086\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 76.71316528320312\n",
      "Eval_StdReturn : 19.96323013305664\n",
      "Eval_MaxReturn : 116.1887435913086\n",
      "Eval_MinReturn : 28.48827362060547\n",
      "Eval_AverageEpLen : 45.95454545454545\n",
      "Train_AverageReturn : 105.22925567626953\n",
      "Train_StdReturn : 37.5123291015625\n",
      "Train_MaxReturn : 208.1215057373047\n",
      "Train_MinReturn : 10.354082107543945\n",
      "Train_AverageEpLen : 57.50574712643678\n",
      "Train_EnvstepsSoFar : 50039\n",
      "TimeSinceStart : 29.68799924850464\n",
      "Training Loss : 118.55329132080078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 72.05168914794922\n",
      "Eval_StdReturn : 13.106155395507812\n",
      "Eval_MaxReturn : 98.70613098144531\n",
      "Eval_MinReturn : 28.830324172973633\n",
      "Eval_AverageEpLen : 44.0\n",
      "Train_AverageReturn : 75.52084350585938\n",
      "Train_StdReturn : 18.507871627807617\n",
      "Train_MaxReturn : 136.05213928222656\n",
      "Train_MinReturn : 11.283832550048828\n",
      "Train_AverageEpLen : 45.45454545454545\n",
      "Train_EnvstepsSoFar : 60039\n",
      "TimeSinceStart : 35.64568042755127\n",
      "Training Loss : 108.87055969238281\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 57.488399505615234\n",
      "Eval_StdReturn : 18.74118423461914\n",
      "Eval_MaxReturn : 83.9248046875\n",
      "Eval_MinReturn : 17.901851654052734\n",
      "Eval_AverageEpLen : 36.785714285714285\n",
      "Train_AverageReturn : 68.49761962890625\n",
      "Train_StdReturn : 17.565156936645508\n",
      "Train_MaxReturn : 117.10746002197266\n",
      "Train_MinReturn : 17.65397834777832\n",
      "Train_AverageEpLen : 42.13865546218487\n",
      "Train_EnvstepsSoFar : 70068\n",
      "TimeSinceStart : 42.07577133178711\n",
      "Training Loss : 104.62944793701172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 57.404056549072266\n",
      "Eval_StdReturn : 14.571622848510742\n",
      "Eval_MaxReturn : 89.31808471679688\n",
      "Eval_MinReturn : 24.58006477355957\n",
      "Eval_AverageEpLen : 36.82142857142857\n",
      "Train_AverageReturn : 61.01822280883789\n",
      "Train_StdReturn : 17.882156372070312\n",
      "Train_MaxReturn : 103.8866958618164\n",
      "Train_MinReturn : 8.252389907836914\n",
      "Train_AverageEpLen : 38.5\n",
      "Train_EnvstepsSoFar : 80078\n",
      "TimeSinceStart : 48.19644284248352\n",
      "Training Loss : 100.56543731689453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 71.3931655883789\n",
      "Eval_StdReturn : 12.802776336669922\n",
      "Eval_MaxReturn : 94.17552185058594\n",
      "Eval_MinReturn : 23.213720321655273\n",
      "Eval_AverageEpLen : 43.75\n",
      "Train_AverageReturn : 61.95618438720703\n",
      "Train_StdReturn : 13.011117935180664\n",
      "Train_MaxReturn : 95.2846908569336\n",
      "Train_MinReturn : 7.796280384063721\n",
      "Train_AverageEpLen : 39.023346303501945\n",
      "Train_EnvstepsSoFar : 90107\n",
      "TimeSinceStart : 54.26414227485657\n",
      "Training Loss : 101.29462432861328\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 72.87108612060547\n",
      "Eval_StdReturn : 10.226423263549805\n",
      "Eval_MaxReturn : 89.91018676757812\n",
      "Eval_MinReturn : 49.445762634277344\n",
      "Eval_AverageEpLen : 44.56521739130435\n",
      "Train_AverageReturn : 71.49046325683594\n",
      "Train_StdReturn : 11.426504135131836\n",
      "Train_MaxReturn : 104.76687622070312\n",
      "Train_MinReturn : 7.903301239013672\n",
      "Train_AverageEpLen : 43.87280701754386\n",
      "Train_EnvstepsSoFar : 100110\n",
      "TimeSinceStart : 60.186453104019165\n",
      "Training Loss : 106.29031372070312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 78.35626983642578\n",
      "Eval_StdReturn : 10.863032341003418\n",
      "Eval_MaxReturn : 108.40797424316406\n",
      "Eval_MinReturn : 59.804317474365234\n",
      "Eval_AverageEpLen : 47.5\n",
      "Train_AverageReturn : 78.37728118896484\n",
      "Train_StdReturn : 11.22593879699707\n",
      "Train_MaxReturn : 113.7191162109375\n",
      "Train_MinReturn : 51.603050231933594\n",
      "Train_AverageEpLen : 47.278301886792455\n",
      "Train_EnvstepsSoFar : 110133\n",
      "TimeSinceStart : 66.02003169059753\n",
      "Training Loss : 109.49565887451172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10050 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 73.6257095336914\n",
      "Eval_StdReturn : 13.875858306884766\n",
      "Eval_MaxReturn : 107.15174102783203\n",
      "Eval_MinReturn : 49.23521041870117\n",
      "Eval_AverageEpLen : 44.65217391304348\n",
      "Train_AverageReturn : 83.41981506347656\n",
      "Train_StdReturn : 15.569930076599121\n",
      "Train_MaxReturn : 127.54488372802734\n",
      "Train_MinReturn : 53.14230728149414\n",
      "Train_AverageEpLen : 49.50738916256157\n",
      "Train_EnvstepsSoFar : 120183\n",
      "TimeSinceStart : 71.65111875534058\n",
      "Training Loss : 112.40676879882812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 66.7959976196289\n",
      "Eval_StdReturn : 7.654504299163818\n",
      "Eval_MaxReturn : 82.54374694824219\n",
      "Eval_MinReturn : 51.727970123291016\n",
      "Eval_AverageEpLen : 40.72\n",
      "Train_AverageReturn : 72.53978729248047\n",
      "Train_StdReturn : 12.49185562133789\n",
      "Train_MaxReturn : 117.00665283203125\n",
      "Train_MinReturn : 47.034305572509766\n",
      "Train_AverageEpLen : 44.26548672566372\n",
      "Train_EnvstepsSoFar : 130187\n",
      "TimeSinceStart : 77.2686493396759\n",
      "Training Loss : 110.06610107421875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 62.83717727661133\n",
      "Eval_StdReturn : 6.69136381149292\n",
      "Eval_MaxReturn : 79.33702087402344\n",
      "Eval_MinReturn : 48.3122444152832\n",
      "Eval_AverageEpLen : 37.51851851851852\n",
      "Train_AverageReturn : 62.76755905151367\n",
      "Train_StdReturn : 7.391607284545898\n",
      "Train_MaxReturn : 86.39799499511719\n",
      "Train_MinReturn : 47.553184509277344\n",
      "Train_AverageEpLen : 38.40229885057471\n",
      "Train_EnvstepsSoFar : 140210\n",
      "TimeSinceStart : 83.3573534488678\n",
      "Training Loss : 107.7696533203125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 65.26811981201172\n",
      "Eval_StdReturn : 8.969656944274902\n",
      "Eval_MaxReturn : 85.71118927001953\n",
      "Eval_MinReturn : 49.41893768310547\n",
      "Eval_AverageEpLen : 38.5\n",
      "Train_AverageReturn : 61.273983001708984\n",
      "Train_StdReturn : 7.233519554138184\n",
      "Train_MaxReturn : 83.60525512695312\n",
      "Train_MinReturn : 45.20113754272461\n",
      "Train_AverageEpLen : 36.6996336996337\n",
      "Train_EnvstepsSoFar : 150229\n",
      "TimeSinceStart : 89.34480166435242\n",
      "Training Loss : 109.66753387451172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 82.02130889892578\n",
      "Eval_StdReturn : 7.828855514526367\n",
      "Eval_MaxReturn : 95.3761978149414\n",
      "Eval_MinReturn : 60.462650299072266\n",
      "Eval_AverageEpLen : 47.45454545454545\n",
      "Train_AverageReturn : 66.96605682373047\n",
      "Train_StdReturn : 8.427602767944336\n",
      "Train_MaxReturn : 92.22481536865234\n",
      "Train_MinReturn : 47.11603927612305\n",
      "Train_AverageEpLen : 39.32941176470588\n",
      "Train_EnvstepsSoFar : 160258\n",
      "TimeSinceStart : 95.2739028930664\n",
      "Training Loss : 114.64581298828125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 100.8648452758789\n",
      "Eval_StdReturn : 9.314762115478516\n",
      "Eval_MaxReturn : 110.6812515258789\n",
      "Eval_MinReturn : 80.74967193603516\n",
      "Eval_AverageEpLen : 57.77777777777778\n",
      "Train_AverageReturn : 80.990478515625\n",
      "Train_StdReturn : 8.843999862670898\n",
      "Train_MaxReturn : 98.72062683105469\n",
      "Train_MinReturn : 58.576995849609375\n",
      "Train_AverageEpLen : 46.78971962616822\n",
      "Train_EnvstepsSoFar : 170271\n",
      "TimeSinceStart : 101.14692640304565\n",
      "Training Loss : 122.14397430419922\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 142.67391967773438\n",
      "Eval_StdReturn : 16.98332405090332\n",
      "Eval_MaxReturn : 161.20343017578125\n",
      "Eval_MinReturn : 113.37510681152344\n",
      "Eval_AverageEpLen : 77.92307692307692\n",
      "Train_AverageReturn : 100.82426452636719\n",
      "Train_StdReturn : 7.988739013671875\n",
      "Train_MaxReturn : 119.37699890136719\n",
      "Train_MinReturn : 74.52619171142578\n",
      "Train_AverageEpLen : 57.861271676300575\n",
      "Train_EnvstepsSoFar : 180281\n",
      "TimeSinceStart : 106.54582595825195\n",
      "Training Loss : 128.72862243652344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10065 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 153.06851196289062\n",
      "Eval_StdReturn : 21.770116806030273\n",
      "Eval_MaxReturn : 165.61883544921875\n",
      "Eval_MinReturn : 79.01653289794922\n",
      "Eval_AverageEpLen : 80.92307692307692\n",
      "Train_AverageReturn : 138.5375213623047\n",
      "Train_StdReturn : 16.97222137451172\n",
      "Train_MaxReturn : 163.17369079589844\n",
      "Train_MinReturn : 100.82107543945312\n",
      "Train_AverageEpLen : 76.25\n",
      "Train_EnvstepsSoFar : 190346\n",
      "TimeSinceStart : 111.99702858924866\n",
      "Training Loss : 134.65353393554688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10054 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 162.03504943847656\n",
      "Eval_StdReturn : 2.732006549835205\n",
      "Eval_MaxReturn : 166.9790496826172\n",
      "Eval_MinReturn : 156.9879150390625\n",
      "Eval_AverageEpLen : 85.0\n",
      "Train_AverageReturn : 161.60464477539062\n",
      "Train_StdReturn : 3.271638870239258\n",
      "Train_MaxReturn : 169.86611938476562\n",
      "Train_MinReturn : 148.71961975097656\n",
      "Train_AverageEpLen : 85.20338983050847\n",
      "Train_EnvstepsSoFar : 200400\n",
      "TimeSinceStart : 117.44386982917786\n",
      "Training Loss : 137.0692138671875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10072 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 163.46722412109375\n",
      "Eval_StdReturn : 3.7193679809570312\n",
      "Eval_MaxReturn : 169.14651489257812\n",
      "Eval_MinReturn : 157.03419494628906\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 160.8887176513672\n",
      "Train_StdReturn : 8.306330680847168\n",
      "Train_MaxReturn : 168.62840270996094\n",
      "Train_MinReturn : 79.32098388671875\n",
      "Train_AverageEpLen : 84.63865546218487\n",
      "Train_EnvstepsSoFar : 210472\n",
      "TimeSinceStart : 122.88936161994934\n",
      "Training Loss : 136.81674194335938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 162.26332092285156\n",
      "Eval_StdReturn : 3.7203354835510254\n",
      "Eval_MaxReturn : 166.9766082763672\n",
      "Eval_MinReturn : 153.5579376220703\n",
      "Eval_AverageEpLen : 84.91666666666667\n",
      "Train_AverageReturn : 160.62820434570312\n",
      "Train_StdReturn : 16.8068904876709\n",
      "Train_MaxReturn : 169.96893310546875\n",
      "Train_MinReturn : 59.65528869628906\n",
      "Train_AverageEpLen : 83.84166666666667\n",
      "Train_EnvstepsSoFar : 220533\n",
      "TimeSinceStart : 128.32600212097168\n",
      "Training Loss : 136.94754028320312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10052 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 154.9510498046875\n",
      "Eval_StdReturn : 21.172117233276367\n",
      "Eval_MaxReturn : 164.97482299804688\n",
      "Eval_MinReturn : 82.19374084472656\n",
      "Eval_AverageEpLen : 81.76923076923077\n",
      "Train_AverageReturn : 161.32481384277344\n",
      "Train_StdReturn : 12.382829666137695\n",
      "Train_MaxReturn : 169.12574768066406\n",
      "Train_MinReturn : 63.644107818603516\n",
      "Train_AverageEpLen : 84.47058823529412\n",
      "Train_EnvstepsSoFar : 230585\n",
      "TimeSinceStart : 133.80083227157593\n",
      "Training Loss : 136.24000549316406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 155.60870361328125\n",
      "Eval_StdReturn : 9.257904052734375\n",
      "Eval_MaxReturn : 164.93907165527344\n",
      "Eval_MinReturn : 128.11856079101562\n",
      "Eval_AverageEpLen : 82.92307692307692\n",
      "Train_AverageReturn : 156.59744262695312\n",
      "Train_StdReturn : 18.50211524963379\n",
      "Train_MaxReturn : 166.86297607421875\n",
      "Train_MinReturn : 64.03836059570312\n",
      "Train_AverageEpLen : 82.71900826446281\n",
      "Train_EnvstepsSoFar : 240594\n",
      "TimeSinceStart : 139.27288055419922\n",
      "Training Loss : 135.76927185058594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 24 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10034 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 155.6028289794922\n",
      "Eval_StdReturn : 5.324556350708008\n",
      "Eval_MaxReturn : 161.7206573486328\n",
      "Eval_MinReturn : 143.5508575439453\n",
      "Eval_AverageEpLen : 82.92307692307692\n",
      "Train_AverageReturn : 154.79022216796875\n",
      "Train_StdReturn : 16.477514266967773\n",
      "Train_MaxReturn : 166.7356414794922\n",
      "Train_MinReturn : 63.510494232177734\n",
      "Train_AverageEpLen : 82.24590163934427\n",
      "Train_EnvstepsSoFar : 250628\n",
      "TimeSinceStart : 144.80047750473022\n",
      "Training Loss : 135.69647216796875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 25 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 131.9033966064453\n",
      "Eval_StdReturn : 43.6584587097168\n",
      "Eval_MaxReturn : 167.09584045410156\n",
      "Eval_MinReturn : 57.77046203613281\n",
      "Eval_AverageEpLen : 68.86666666666666\n",
      "Train_AverageReturn : 153.18760681152344\n",
      "Train_StdReturn : 19.400846481323242\n",
      "Train_MaxReturn : 166.5583953857422\n",
      "Train_MinReturn : 65.18775939941406\n",
      "Train_AverageEpLen : 81.3225806451613\n",
      "Train_EnvstepsSoFar : 260712\n",
      "TimeSinceStart : 150.30667853355408\n",
      "Training Loss : 134.88818359375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 26 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10082 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 104.65396881103516\n",
      "Eval_StdReturn : 53.88756561279297\n",
      "Eval_MaxReturn : 184.2305908203125\n",
      "Eval_MinReturn : 50.05282974243164\n",
      "Eval_AverageEpLen : 53.8421052631579\n",
      "Train_AverageReturn : 119.92304992675781\n",
      "Train_StdReturn : 48.25092697143555\n",
      "Train_MaxReturn : 183.9281463623047\n",
      "Train_MinReturn : 53.38594055175781\n",
      "Train_AverageEpLen : 63.0125\n",
      "Train_EnvstepsSoFar : 270794\n",
      "TimeSinceStart : 156.13822293281555\n",
      "Training Loss : 130.0687713623047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 27 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 119.90731811523438\n",
      "Eval_StdReturn : 64.15265655517578\n",
      "Eval_MaxReturn : 197.7641143798828\n",
      "Eval_MinReturn : 49.81135940551758\n",
      "Eval_AverageEpLen : 58.833333333333336\n",
      "Train_AverageReturn : 102.24862670898438\n",
      "Train_StdReturn : 54.9689826965332\n",
      "Train_MaxReturn : 209.62069702148438\n",
      "Train_MinReturn : 45.776954650878906\n",
      "Train_AverageEpLen : 52.4375\n",
      "Train_EnvstepsSoFar : 280862\n",
      "TimeSinceStart : 161.9433982372284\n",
      "Training Loss : 123.53340911865234\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 28 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 147.9197540283203\n",
      "Eval_StdReturn : 57.30656051635742\n",
      "Eval_MaxReturn : 208.53765869140625\n",
      "Eval_MinReturn : 46.64493942260742\n",
      "Eval_AverageEpLen : 71.57142857142857\n",
      "Train_AverageReturn : 124.29911804199219\n",
      "Train_StdReturn : 59.78173828125\n",
      "Train_MaxReturn : 214.24099731445312\n",
      "Train_MinReturn : 43.22669219970703\n",
      "Train_AverageEpLen : 61.374233128834355\n",
      "Train_EnvstepsSoFar : 290866\n",
      "TimeSinceStart : 167.6198890209198\n",
      "Training Loss : 125.16165924072266\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 29 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10058 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 133.3095703125\n",
      "Eval_StdReturn : 66.57853698730469\n",
      "Eval_MaxReturn : 210.4509735107422\n",
      "Eval_MinReturn : 49.41636276245117\n",
      "Eval_AverageEpLen : 64.125\n",
      "Train_AverageReturn : 140.75390625\n",
      "Train_StdReturn : 61.36463165283203\n",
      "Train_MaxReturn : 212.81651306152344\n",
      "Train_MinReturn : 21.638029098510742\n",
      "Train_AverageEpLen : 67.95945945945945\n",
      "Train_EnvstepsSoFar : 300924\n",
      "TimeSinceStart : 173.4902160167694\n",
      "Training Loss : 124.71182250976562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 30 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10070 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 127.29793548583984\n",
      "Eval_StdReturn : 74.97982025146484\n",
      "Eval_MaxReturn : 204.8042449951172\n",
      "Eval_MinReturn : 21.7435302734375\n",
      "Eval_AverageEpLen : 62.11764705882353\n",
      "Train_AverageReturn : 148.95034790039062\n",
      "Train_StdReturn : 63.6452522277832\n",
      "Train_MaxReturn : 217.03533935546875\n",
      "Train_MinReturn : 19.60965919494629\n",
      "Train_AverageEpLen : 70.91549295774648\n",
      "Train_EnvstepsSoFar : 310994\n",
      "TimeSinceStart : 179.47581601142883\n",
      "Training Loss : 124.8930892944336\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 31 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10070 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 134.9767303466797\n",
      "Eval_StdReturn : 48.15766143798828\n",
      "Eval_MaxReturn : 193.14007568359375\n",
      "Eval_MinReturn : 21.6400203704834\n",
      "Eval_AverageEpLen : 68.46666666666667\n",
      "Train_AverageReturn : 149.47914123535156\n",
      "Train_StdReturn : 59.32365036010742\n",
      "Train_MaxReturn : 212.02236938476562\n",
      "Train_MinReturn : 16.270771026611328\n",
      "Train_AverageEpLen : 72.44604316546763\n",
      "Train_EnvstepsSoFar : 321064\n",
      "TimeSinceStart : 185.3257155418396\n",
      "Training Loss : 123.68019104003906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 32 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10048 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 114.65882873535156\n",
      "Eval_StdReturn : 28.031965255737305\n",
      "Eval_MaxReturn : 142.37265014648438\n",
      "Eval_MinReturn : 21.44584083557129\n",
      "Eval_AverageEpLen : 62.9375\n",
      "Train_AverageReturn : 127.23985290527344\n",
      "Train_StdReturn : 52.72793960571289\n",
      "Train_MaxReturn : 204.5171661376953\n",
      "Train_MinReturn : 15.708741188049316\n",
      "Train_AverageEpLen : 65.24675324675324\n",
      "Train_EnvstepsSoFar : 331112\n",
      "TimeSinceStart : 191.7782597541809\n",
      "Training Loss : 119.80908966064453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 33 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10065 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 84.33311462402344\n",
      "Eval_StdReturn : 31.675424575805664\n",
      "Eval_MaxReturn : 128.052001953125\n",
      "Eval_MinReturn : 21.76112174987793\n",
      "Eval_AverageEpLen : 50.23809523809524\n",
      "Train_AverageReturn : 99.07914733886719\n",
      "Train_StdReturn : 40.5665397644043\n",
      "Train_MaxReturn : 158.38783264160156\n",
      "Train_MinReturn : 15.729644775390625\n",
      "Train_AverageEpLen : 55.607734806629836\n",
      "Train_EnvstepsSoFar : 341177\n",
      "TimeSinceStart : 197.61103701591492\n",
      "Training Loss : 115.51622009277344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 34 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 92.9831771850586\n",
      "Eval_StdReturn : 22.006589889526367\n",
      "Eval_MaxReturn : 132.37619018554688\n",
      "Eval_MinReturn : 17.27739143371582\n",
      "Eval_AverageEpLen : 55.0\n",
      "Train_AverageReturn : 84.56263732910156\n",
      "Train_StdReturn : 31.971038818359375\n",
      "Train_MaxReturn : 141.00962829589844\n",
      "Train_MinReturn : 14.383068084716797\n",
      "Train_AverageEpLen : 50.55050505050505\n",
      "Train_EnvstepsSoFar : 351186\n",
      "TimeSinceStart : 203.48820638656616\n",
      "Training Loss : 112.58454895019531\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 35 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10050 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 83.00372314453125\n",
      "Eval_StdReturn : 16.592622756958008\n",
      "Eval_MaxReturn : 107.37089538574219\n",
      "Eval_MinReturn : 25.999937057495117\n",
      "Eval_AverageEpLen : 50.4\n",
      "Train_AverageReturn : 84.39936828613281\n",
      "Train_StdReturn : 24.28506088256836\n",
      "Train_MaxReturn : 127.79458618164062\n",
      "Train_MinReturn : 12.484970092773438\n",
      "Train_AverageEpLen : 51.015228426395936\n",
      "Train_EnvstepsSoFar : 361236\n",
      "TimeSinceStart : 209.41151213645935\n",
      "Training Loss : 112.89395141601562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 36 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 91.6041030883789\n",
      "Eval_StdReturn : 8.559252738952637\n",
      "Eval_MaxReturn : 102.07908630371094\n",
      "Eval_MinReturn : 65.23397064208984\n",
      "Eval_AverageEpLen : 54.05263157894737\n",
      "Train_AverageReturn : 85.9207992553711\n",
      "Train_StdReturn : 13.623258590698242\n",
      "Train_MaxReturn : 107.08842468261719\n",
      "Train_MinReturn : 23.95296287536621\n",
      "Train_AverageEpLen : 51.670103092783506\n",
      "Train_EnvstepsSoFar : 371260\n",
      "TimeSinceStart : 215.25062465667725\n",
      "Training Loss : 116.1458511352539\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 37 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 91.2542495727539\n",
      "Eval_StdReturn : 5.143960952758789\n",
      "Eval_MaxReturn : 98.40436553955078\n",
      "Eval_MinReturn : 78.40171813964844\n",
      "Eval_AverageEpLen : 53.21052631578947\n",
      "Train_AverageReturn : 91.09396362304688\n",
      "Train_StdReturn : 9.776152610778809\n",
      "Train_MaxReturn : 107.17768859863281\n",
      "Train_MinReturn : 29.625200271606445\n",
      "Train_AverageEpLen : 53.876344086021504\n",
      "Train_EnvstepsSoFar : 381281\n",
      "TimeSinceStart : 221.24846720695496\n",
      "Training Loss : 120.06127166748047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 38 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10034 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 78.714111328125\n",
      "Eval_StdReturn : 6.477675437927246\n",
      "Eval_MaxReturn : 88.03097534179688\n",
      "Eval_MinReturn : 58.712791442871094\n",
      "Eval_AverageEpLen : 46.04545454545455\n",
      "Train_AverageReturn : 88.10565185546875\n",
      "Train_StdReturn : 7.504347324371338\n",
      "Train_MaxReturn : 105.7834243774414\n",
      "Train_MinReturn : 63.19892120361328\n",
      "Train_AverageEpLen : 51.72164948453608\n",
      "Train_EnvstepsSoFar : 391315\n",
      "TimeSinceStart : 227.2482395172119\n",
      "Training Loss : 119.99131774902344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 39 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10014 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 73.5470962524414\n",
      "Eval_StdReturn : 4.312475681304932\n",
      "Eval_MaxReturn : 84.77788543701172\n",
      "Eval_MinReturn : 66.37712097167969\n",
      "Eval_AverageEpLen : 43.208333333333336\n",
      "Train_AverageReturn : 77.54224395751953\n",
      "Train_StdReturn : 6.250127792358398\n",
      "Train_MaxReturn : 94.02751922607422\n",
      "Train_MinReturn : 58.95698165893555\n",
      "Train_AverageEpLen : 45.518181818181816\n",
      "Train_EnvstepsSoFar : 401329\n",
      "TimeSinceStart : 233.3984410762787\n",
      "Training Loss : 116.26873779296875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 40 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 59.966796875\n",
      "Eval_StdReturn : 7.63839054107666\n",
      "Eval_MaxReturn : 74.36053466796875\n",
      "Eval_MinReturn : 46.87509536743164\n",
      "Eval_AverageEpLen : 35.96551724137931\n",
      "Train_AverageReturn : 71.31427001953125\n",
      "Train_StdReturn : 6.947906017303467\n",
      "Train_MaxReturn : 86.35025024414062\n",
      "Train_MinReturn : 48.430320739746094\n",
      "Train_AverageEpLen : 42.054621848739494\n",
      "Train_EnvstepsSoFar : 411338\n",
      "TimeSinceStart : 239.36206603050232\n",
      "Training Loss : 113.3979263305664\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 41 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 54.322364807128906\n",
      "Eval_StdReturn : 7.056865215301514\n",
      "Eval_MaxReturn : 74.92425537109375\n",
      "Eval_MinReturn : 43.27492904663086\n",
      "Eval_AverageEpLen : 32.903225806451616\n",
      "Train_AverageReturn : 60.46063995361328\n",
      "Train_StdReturn : 7.548907279968262\n",
      "Train_MaxReturn : 77.90966033935547\n",
      "Train_MinReturn : 43.39808654785156\n",
      "Train_AverageEpLen : 36.13718411552347\n",
      "Train_EnvstepsSoFar : 421348\n",
      "TimeSinceStart : 245.25742983818054\n",
      "Training Loss : 106.79139709472656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 42 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10022 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 55.98214340209961\n",
      "Eval_StdReturn : 7.573387622833252\n",
      "Eval_MaxReturn : 70.75469207763672\n",
      "Eval_MinReturn : 43.566673278808594\n",
      "Eval_AverageEpLen : 33.86666666666667\n",
      "Train_AverageReturn : 54.78645706176758\n",
      "Train_StdReturn : 6.230779647827148\n",
      "Train_MaxReturn : 72.9493637084961\n",
      "Train_MinReturn : 43.72441101074219\n",
      "Train_AverageEpLen : 33.07590759075907\n",
      "Train_EnvstepsSoFar : 431370\n",
      "TimeSinceStart : 251.40863180160522\n",
      "Training Loss : 102.3908920288086\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 43 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 51.859554290771484\n",
      "Eval_StdReturn : 5.415157318115234\n",
      "Eval_MaxReturn : 64.15108489990234\n",
      "Eval_MinReturn : 44.490665435791016\n",
      "Eval_AverageEpLen : 31.59375\n",
      "Train_AverageReturn : 53.581703186035156\n",
      "Train_StdReturn : 5.794032096862793\n",
      "Train_MaxReturn : 74.07717895507812\n",
      "Train_MinReturn : 41.94532775878906\n",
      "Train_AverageEpLen : 32.47402597402598\n",
      "Train_EnvstepsSoFar : 441372\n",
      "TimeSinceStart : 257.5247268676758\n",
      "Training Loss : 101.07933044433594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 44 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10022 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 50.648414611816406\n",
      "Eval_StdReturn : 4.970466136932373\n",
      "Eval_MaxReturn : 63.01445007324219\n",
      "Eval_MinReturn : 42.80781173706055\n",
      "Eval_AverageEpLen : 31.060606060606062\n",
      "Train_AverageReturn : 52.379337310791016\n",
      "Train_StdReturn : 5.961588382720947\n",
      "Train_MaxReturn : 70.02850341796875\n",
      "Train_MinReturn : 42.658912658691406\n",
      "Train_AverageEpLen : 31.9171974522293\n",
      "Train_EnvstepsSoFar : 451394\n",
      "TimeSinceStart : 263.56405544281006\n",
      "Training Loss : 100.10995483398438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 45 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 53.64700698852539\n",
      "Eval_StdReturn : 5.230698585510254\n",
      "Eval_MaxReturn : 66.24314880371094\n",
      "Eval_MinReturn : 43.04277801513672\n",
      "Eval_AverageEpLen : 32.61290322580645\n",
      "Train_AverageReturn : 51.51475143432617\n",
      "Train_StdReturn : 5.445184707641602\n",
      "Train_MaxReturn : 66.6009521484375\n",
      "Train_MinReturn : 41.36884689331055\n",
      "Train_AverageEpLen : 31.4874213836478\n",
      "Train_EnvstepsSoFar : 461407\n",
      "TimeSinceStart : 269.51201701164246\n",
      "Training Loss : 99.2823257446289\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 46 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 61.591129302978516\n",
      "Eval_StdReturn : 7.134150981903076\n",
      "Eval_MaxReturn : 72.73919677734375\n",
      "Eval_MinReturn : 46.19948196411133\n",
      "Eval_AverageEpLen : 36.964285714285715\n",
      "Train_AverageReturn : 53.46656036376953\n",
      "Train_StdReturn : 5.609367370605469\n",
      "Train_MaxReturn : 68.88099670410156\n",
      "Train_MinReturn : 41.937416076660156\n",
      "Train_AverageEpLen : 32.59609120521173\n",
      "Train_EnvstepsSoFar : 471414\n",
      "TimeSinceStart : 275.5582129955292\n",
      "Training Loss : 100.58547973632812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 47 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 65.95539855957031\n",
      "Eval_StdReturn : 6.492264747619629\n",
      "Eval_MaxReturn : 75.65582275390625\n",
      "Eval_MinReturn : 49.6883659362793\n",
      "Eval_AverageEpLen : 39.42307692307692\n",
      "Train_AverageReturn : 59.408138275146484\n",
      "Train_StdReturn : 6.850683212280273\n",
      "Train_MaxReturn : 76.66902160644531\n",
      "Train_MinReturn : 41.76255416870117\n",
      "Train_AverageEpLen : 35.84587813620072\n",
      "Train_EnvstepsSoFar : 481415\n",
      "TimeSinceStart : 281.35981369018555\n",
      "Training Loss : 104.83007049560547\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 48 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 70.03384399414062\n",
      "Eval_StdReturn : 5.285841941833496\n",
      "Eval_MaxReturn : 76.5933609008789\n",
      "Eval_MinReturn : 58.972869873046875\n",
      "Eval_AverageEpLen : 41.666666666666664\n",
      "Train_AverageReturn : 64.87039184570312\n",
      "Train_StdReturn : 6.184084892272949\n",
      "Train_MaxReturn : 80.08783721923828\n",
      "Train_MinReturn : 46.5936279296875\n",
      "Train_AverageEpLen : 38.86046511627907\n",
      "Train_EnvstepsSoFar : 491441\n",
      "TimeSinceStart : 287.2750151157379\n",
      "Training Loss : 107.98765563964844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 49 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10027 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 70.04724884033203\n",
      "Eval_StdReturn : 5.334059715270996\n",
      "Eval_MaxReturn : 78.40965270996094\n",
      "Eval_MinReturn : 56.84253692626953\n",
      "Eval_AverageEpLen : 41.666666666666664\n",
      "Train_AverageReturn : 70.50552368164062\n",
      "Train_StdReturn : 5.765300273895264\n",
      "Train_MaxReturn : 85.86102294921875\n",
      "Train_MinReturn : 50.13255310058594\n",
      "Train_AverageEpLen : 41.95397489539749\n",
      "Train_EnvstepsSoFar : 501468\n",
      "TimeSinceStart : 293.2546708583832\n",
      "Training Loss : 110.97859191894531\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 75.1728286743164\n",
      "Eval_StdReturn : 4.852701663970947\n",
      "Eval_MaxReturn : 83.35407257080078\n",
      "Eval_MinReturn : 65.1739501953125\n",
      "Eval_AverageEpLen : 44.52173913043478\n",
      "Train_AverageReturn : 71.62057495117188\n",
      "Train_StdReturn : 5.211546421051025\n",
      "Train_MaxReturn : 87.55317687988281\n",
      "Train_MinReturn : 53.713775634765625\n",
      "Train_AverageEpLen : 42.521186440677965\n",
      "Train_EnvstepsSoFar : 511503\n",
      "TimeSinceStart : 299.0960774421692\n",
      "Training Loss : 111.80995178222656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 79.1758041381836\n",
      "Eval_StdReturn : 4.303563594818115\n",
      "Eval_MaxReturn : 85.9695053100586\n",
      "Eval_MinReturn : 70.00956726074219\n",
      "Eval_AverageEpLen : 46.63636363636363\n",
      "Train_AverageReturn : 75.88848114013672\n",
      "Train_StdReturn : 4.1549577713012695\n",
      "Train_MaxReturn : 85.89303588867188\n",
      "Train_MinReturn : 63.267303466796875\n",
      "Train_AverageEpLen : 44.88789237668161\n",
      "Train_EnvstepsSoFar : 521513\n",
      "TimeSinceStart : 305.2412588596344\n",
      "Training Loss : 113.62539672851562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10017 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 81.33395385742188\n",
      "Eval_StdReturn : 3.562124729156494\n",
      "Eval_MaxReturn : 90.13053894042969\n",
      "Eval_MinReturn : 75.93502044677734\n",
      "Eval_AverageEpLen : 47.904761904761905\n",
      "Train_AverageReturn : 78.2951889038086\n",
      "Train_StdReturn : 3.7231383323669434\n",
      "Train_MaxReturn : 87.76608276367188\n",
      "Train_MinReturn : 64.92799377441406\n",
      "Train_AverageEpLen : 46.16129032258065\n",
      "Train_EnvstepsSoFar : 531530\n",
      "TimeSinceStart : 311.3508777618408\n",
      "Training Loss : 114.43533325195312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10031 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 80.64542388916016\n",
      "Eval_StdReturn : 2.4546127319335938\n",
      "Eval_MaxReturn : 84.2197036743164\n",
      "Eval_MinReturn : 77.0462646484375\n",
      "Eval_AverageEpLen : 47.45454545454545\n",
      "Train_AverageReturn : 79.97801971435547\n",
      "Train_StdReturn : 3.7232513427734375\n",
      "Train_MaxReturn : 91.11793518066406\n",
      "Train_MinReturn : 68.65924835205078\n",
      "Train_AverageEpLen : 47.093896713615024\n",
      "Train_EnvstepsSoFar : 541561\n",
      "TimeSinceStart : 317.55028343200684\n",
      "Training Loss : 115.08232116699219\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 85.56103515625\n",
      "Eval_StdReturn : 3.47068190574646\n",
      "Eval_MaxReturn : 90.9542465209961\n",
      "Eval_MinReturn : 77.96504211425781\n",
      "Eval_AverageEpLen : 50.25\n",
      "Train_AverageReturn : 80.85443878173828\n",
      "Train_StdReturn : 3.697223424911499\n",
      "Train_MaxReturn : 91.73509216308594\n",
      "Train_MinReturn : 68.24466705322266\n",
      "Train_AverageEpLen : 47.5260663507109\n",
      "Train_EnvstepsSoFar : 551589\n",
      "TimeSinceStart : 323.4600110054016\n",
      "Training Loss : 115.99113464355469\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10022 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 86.92295837402344\n",
      "Eval_StdReturn : 3.2013652324676514\n",
      "Eval_MaxReturn : 93.2806625366211\n",
      "Eval_MinReturn : 81.11300659179688\n",
      "Eval_AverageEpLen : 50.9\n",
      "Train_AverageReturn : 85.46885681152344\n",
      "Train_StdReturn : 3.415454626083374\n",
      "Train_MaxReturn : 94.16792297363281\n",
      "Train_MinReturn : 74.60884857177734\n",
      "Train_AverageEpLen : 50.11\n",
      "Train_EnvstepsSoFar : 561611\n",
      "TimeSinceStart : 329.5620403289795\n",
      "Training Loss : 117.29118347167969\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 90.07977294921875\n",
      "Eval_StdReturn : 3.1020865440368652\n",
      "Eval_MaxReturn : 95.2717056274414\n",
      "Eval_MinReturn : 84.81207275390625\n",
      "Eval_AverageEpLen : 52.8421052631579\n",
      "Train_AverageReturn : 86.90316772460938\n",
      "Train_StdReturn : 3.439748525619507\n",
      "Train_MaxReturn : 96.02566528320312\n",
      "Train_MinReturn : 75.68262481689453\n",
      "Train_AverageEpLen : 50.88324873096447\n",
      "Train_EnvstepsSoFar : 571635\n",
      "TimeSinceStart : 335.5514283180237\n",
      "Training Loss : 116.76123809814453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 91.44525909423828\n",
      "Eval_StdReturn : 3.494718551635742\n",
      "Eval_MaxReturn : 98.40974426269531\n",
      "Eval_MinReturn : 86.04338836669922\n",
      "Eval_AverageEpLen : 53.36842105263158\n",
      "Train_AverageReturn : 89.4278793334961\n",
      "Train_StdReturn : 3.306915760040283\n",
      "Train_MaxReturn : 95.64501953125\n",
      "Train_MinReturn : 78.74494934082031\n",
      "Train_AverageEpLen : 52.3125\n",
      "Train_EnvstepsSoFar : 581679\n",
      "TimeSinceStart : 341.5658440589905\n",
      "Training Loss : 118.72029113769531\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10041 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 90.26386260986328\n",
      "Eval_StdReturn : 2.7149882316589355\n",
      "Eval_MaxReturn : 95.96575927734375\n",
      "Eval_MinReturn : 85.6666259765625\n",
      "Eval_AverageEpLen : 52.89473684210526\n",
      "Train_AverageReturn : 90.36576080322266\n",
      "Train_StdReturn : 3.5210816860198975\n",
      "Train_MaxReturn : 99.21922302246094\n",
      "Train_MinReturn : 79.42880249023438\n",
      "Train_AverageEpLen : 52.84736842105263\n",
      "Train_EnvstepsSoFar : 591720\n",
      "TimeSinceStart : 347.6785373687744\n",
      "Training Loss : 118.5282974243164\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 93.08287811279297\n",
      "Eval_StdReturn : 4.033281326293945\n",
      "Eval_MaxReturn : 99.57679748535156\n",
      "Eval_MinReturn : 85.47478485107422\n",
      "Eval_AverageEpLen : 54.36842105263158\n",
      "Train_AverageReturn : 90.495849609375\n",
      "Train_StdReturn : 3.6994781494140625\n",
      "Train_MaxReturn : 100.29923248291016\n",
      "Train_MinReturn : 78.3492660522461\n",
      "Train_AverageEpLen : 52.863157894736844\n",
      "Train_EnvstepsSoFar : 601764\n",
      "TimeSinceStart : 353.4437007904053\n",
      "Training Loss : 118.6006088256836\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 97.58985137939453\n",
      "Eval_StdReturn : 3.182389259338379\n",
      "Eval_MaxReturn : 103.7898178100586\n",
      "Eval_MinReturn : 91.36123657226562\n",
      "Eval_AverageEpLen : 57.05555555555556\n",
      "Train_AverageReturn : 91.96475982666016\n",
      "Train_StdReturn : 3.7081470489501953\n",
      "Train_MaxReturn : 99.95831298828125\n",
      "Train_MinReturn : 79.77413940429688\n",
      "Train_AverageEpLen : 53.711229946524064\n",
      "Train_EnvstepsSoFar : 611808\n",
      "TimeSinceStart : 359.3297975063324\n",
      "Training Loss : 118.95366668701172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 115.5667724609375\n",
      "Eval_StdReturn : 6.624833106994629\n",
      "Eval_MaxReturn : 136.53271484375\n",
      "Eval_MinReturn : 106.06519317626953\n",
      "Eval_AverageEpLen : 67.33333333333333\n",
      "Train_AverageReturn : 99.66583251953125\n",
      "Train_StdReturn : 3.9068844318389893\n",
      "Train_MaxReturn : 107.9854965209961\n",
      "Train_MinReturn : 89.89208221435547\n",
      "Train_AverageEpLen : 58.26162790697674\n",
      "Train_EnvstepsSoFar : 621829\n",
      "TimeSinceStart : 365.2193338871002\n",
      "Training Loss : 120.5296859741211\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10060 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 153.62083435058594\n",
      "Eval_StdReturn : 11.800307273864746\n",
      "Eval_MaxReturn : 163.05284118652344\n",
      "Eval_MinReturn : 115.39488220214844\n",
      "Eval_AverageEpLen : 83.33333333333333\n",
      "Train_AverageReturn : 116.76678466796875\n",
      "Train_StdReturn : 7.05136775970459\n",
      "Train_MaxReturn : 155.9937286376953\n",
      "Train_MinReturn : 106.23751831054688\n",
      "Train_AverageEpLen : 67.97297297297297\n",
      "Train_EnvstepsSoFar : 631889\n",
      "TimeSinceStart : 371.3244547843933\n",
      "Training Loss : 124.9412612915039\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 99.19296264648438\n",
      "Eval_StdReturn : 44.628822326660156\n",
      "Eval_MaxReturn : 166.56643676757812\n",
      "Eval_MinReturn : 60.718441009521484\n",
      "Eval_AverageEpLen : 53.89473684210526\n",
      "Train_AverageReturn : 149.21060180664062\n",
      "Train_StdReturn : 24.842761993408203\n",
      "Train_MaxReturn : 164.6331787109375\n",
      "Train_MinReturn : 58.684043884277344\n",
      "Train_AverageEpLen : 80.64516129032258\n",
      "Train_EnvstepsSoFar : 641889\n",
      "TimeSinceStart : 377.287052154541\n",
      "Training Loss : 126.9889144897461\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 81.22386169433594\n",
      "Eval_StdReturn : 38.75987243652344\n",
      "Eval_MaxReturn : 166.6233367919922\n",
      "Eval_MinReturn : 45.40283966064453\n",
      "Eval_AverageEpLen : 44.73913043478261\n",
      "Train_AverageReturn : 111.43949890136719\n",
      "Train_StdReturn : 47.418338775634766\n",
      "Train_MaxReturn : 166.78652954101562\n",
      "Train_MinReturn : 51.173423767089844\n",
      "Train_AverageEpLen : 60.16167664670659\n",
      "Train_EnvstepsSoFar : 651936\n",
      "TimeSinceStart : 383.2921187877655\n",
      "Training Loss : 122.17218780517578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 59.82703399658203\n",
      "Eval_StdReturn : 6.913198947906494\n",
      "Eval_MaxReturn : 78.56534576416016\n",
      "Eval_MinReturn : 47.61662673950195\n",
      "Eval_AverageEpLen : 34.06666666666667\n",
      "Train_AverageReturn : 74.08103942871094\n",
      "Train_StdReturn : 32.312862396240234\n",
      "Train_MaxReturn : 168.32418823242188\n",
      "Train_MinReturn : 48.62512969970703\n",
      "Train_AverageEpLen : 41.159183673469386\n",
      "Train_EnvstepsSoFar : 662020\n",
      "TimeSinceStart : 389.5525891780853\n",
      "Training Loss : 111.9554214477539\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 66.61092376708984\n",
      "Eval_StdReturn : 33.48854446411133\n",
      "Eval_MaxReturn : 166.6896209716797\n",
      "Eval_MinReturn : 45.43791198730469\n",
      "Eval_AverageEpLen : 36.964285714285715\n",
      "Train_AverageReturn : 62.27083969116211\n",
      "Train_StdReturn : 19.049802780151367\n",
      "Train_MaxReturn : 169.2427520751953\n",
      "Train_MinReturn : 43.893882751464844\n",
      "Train_AverageEpLen : 35.2112676056338\n",
      "Train_EnvstepsSoFar : 672020\n",
      "TimeSinceStart : 395.38600397109985\n",
      "Training Loss : 106.39299011230469\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 86.78804779052734\n",
      "Eval_StdReturn : 50.998409271240234\n",
      "Eval_MaxReturn : 203.14967346191406\n",
      "Eval_MinReturn : 46.82847595214844\n",
      "Eval_AverageEpLen : 45.63636363636363\n",
      "Train_AverageReturn : 64.85889434814453\n",
      "Train_StdReturn : 27.473112106323242\n",
      "Train_MaxReturn : 187.56459045410156\n",
      "Train_MinReturn : 44.786376953125\n",
      "Train_AverageEpLen : 36.289855072463766\n",
      "Train_EnvstepsSoFar : 682036\n",
      "TimeSinceStart : 401.18465209007263\n",
      "Training Loss : 106.58251953125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 146.03868103027344\n",
      "Eval_StdReturn : 61.13289260864258\n",
      "Eval_MaxReturn : 213.413818359375\n",
      "Eval_MinReturn : 50.67786407470703\n",
      "Eval_AverageEpLen : 70.13333333333334\n",
      "Train_AverageReturn : 79.13089752197266\n",
      "Train_StdReturn : 43.75318908691406\n",
      "Train_MaxReturn : 208.47982788085938\n",
      "Train_MinReturn : 44.96619415283203\n",
      "Train_AverageEpLen : 42.56170212765957\n",
      "Train_EnvstepsSoFar : 692038\n",
      "TimeSinceStart : 406.9772152900696\n",
      "Training Loss : 110.7311782836914\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10077 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.28555297851562\n",
      "Eval_StdReturn : 65.26717376708984\n",
      "Eval_MaxReturn : 212.96832275390625\n",
      "Eval_MinReturn : 14.914836883544922\n",
      "Eval_AverageEpLen : 78.15384615384616\n",
      "Train_AverageReturn : 137.85008239746094\n",
      "Train_StdReturn : 59.25857162475586\n",
      "Train_MaxReturn : 215.982177734375\n",
      "Train_MinReturn : 15.292398452758789\n",
      "Train_AverageEpLen : 67.18\n",
      "Train_EnvstepsSoFar : 702115\n",
      "TimeSinceStart : 412.78611493110657\n",
      "Training Loss : 119.43788146972656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.944923400878906\n",
      "Eval_StdReturn : 67.12247467041016\n",
      "Eval_MaxReturn : 208.1999053955078\n",
      "Eval_MinReturn : 8.268569946289062\n",
      "Eval_AverageEpLen : 28.236842105263158\n",
      "Train_AverageReturn : 162.0097198486328\n",
      "Train_StdReturn : 67.99195098876953\n",
      "Train_MaxReturn : 218.43157958984375\n",
      "Train_MinReturn : 14.737031936645508\n",
      "Train_AverageEpLen : 76.33587786259542\n",
      "Train_EnvstepsSoFar : 712115\n",
      "TimeSinceStart : 418.5859296321869\n",
      "Training Loss : 116.2182388305664\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 47.97929000854492\n",
      "Eval_StdReturn : 68.9667739868164\n",
      "Eval_MaxReturn : 204.98829650878906\n",
      "Eval_MinReturn : 6.635730743408203\n",
      "Eval_AverageEpLen : 29.58823529411765\n",
      "Train_AverageReturn : 64.46314239501953\n",
      "Train_StdReturn : 79.60971069335938\n",
      "Train_MaxReturn : 214.4321746826172\n",
      "Train_MinReturn : 8.325379371643066\n",
      "Train_AverageEpLen : 36.51094890510949\n",
      "Train_EnvstepsSoFar : 722119\n",
      "TimeSinceStart : 424.47522020339966\n",
      "Training Loss : 93.18169403076172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.5158805847168\n",
      "Eval_StdReturn : 54.2142219543457\n",
      "Eval_MaxReturn : 215.58200073242188\n",
      "Eval_MinReturn : 9.896805763244629\n",
      "Eval_AverageEpLen : 28.13888888888889\n",
      "Train_AverageReturn : 36.72060012817383\n",
      "Train_StdReturn : 57.46538543701172\n",
      "Train_MaxReturn : 212.2957305908203\n",
      "Train_MinReturn : 5.733816146850586\n",
      "Train_AverageEpLen : 25.042394014962593\n",
      "Train_EnvstepsSoFar : 732161\n",
      "TimeSinceStart : 430.3948640823364\n",
      "Training Loss : 75.47575378417969\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 103.78136444091797\n",
      "Eval_StdReturn : 87.28262329101562\n",
      "Eval_MaxReturn : 205.88687133789062\n",
      "Eval_MinReturn : 10.307344436645508\n",
      "Eval_AverageEpLen : 52.89473684210526\n",
      "Train_AverageReturn : 51.20873260498047\n",
      "Train_StdReturn : 67.75899505615234\n",
      "Train_MaxReturn : 212.68402099609375\n",
      "Train_MinReturn : 6.480217933654785\n",
      "Train_AverageEpLen : 31.47798742138365\n",
      "Train_EnvstepsSoFar : 742171\n",
      "TimeSinceStart : 436.25698947906494\n",
      "Training Loss : 86.76041412353516\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10090 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.43589782714844\n",
      "Eval_StdReturn : 40.19544219970703\n",
      "Eval_MaxReturn : 214.6608428955078\n",
      "Eval_MinReturn : 43.86491775512695\n",
      "Eval_AverageEpLen : 81.07692307692308\n",
      "Train_AverageReturn : 123.23492431640625\n",
      "Train_StdReturn : 80.83484649658203\n",
      "Train_MaxReturn : 216.2478485107422\n",
      "Train_MinReturn : 8.874192237854004\n",
      "Train_AverageEpLen : 61.52439024390244\n",
      "Train_EnvstepsSoFar : 752261\n",
      "TimeSinceStart : 442.09650802612305\n",
      "Training Loss : 111.26276397705078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 107.3289566040039\n",
      "Eval_StdReturn : 49.893821716308594\n",
      "Eval_MaxReturn : 177.8737335205078\n",
      "Eval_MinReturn : 40.885108947753906\n",
      "Eval_AverageEpLen : 56.888888888888886\n",
      "Train_AverageReturn : 138.99044799804688\n",
      "Train_StdReturn : 54.445796966552734\n",
      "Train_MaxReturn : 211.52197265625\n",
      "Train_MinReturn : 20.273677825927734\n",
      "Train_AverageEpLen : 68.91095890410959\n",
      "Train_EnvstepsSoFar : 762322\n",
      "TimeSinceStart : 447.87094593048096\n",
      "Training Loss : 118.91712188720703\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 80.53911590576172\n",
      "Eval_StdReturn : 46.400516510009766\n",
      "Eval_MaxReturn : 189.10296630859375\n",
      "Eval_MinReturn : 43.08261489868164\n",
      "Eval_AverageEpLen : 44.43478260869565\n",
      "Train_AverageReturn : 101.40149688720703\n",
      "Train_StdReturn : 48.20519256591797\n",
      "Train_MaxReturn : 203.01559448242188\n",
      "Train_MinReturn : 38.929508209228516\n",
      "Train_AverageEpLen : 54.07027027027027\n",
      "Train_EnvstepsSoFar : 772325\n",
      "TimeSinceStart : 453.96061515808105\n",
      "Training Loss : 116.5027084350586\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 111.13123321533203\n",
      "Eval_StdReturn : 49.690513610839844\n",
      "Eval_MaxReturn : 172.0641632080078\n",
      "Eval_MinReturn : 46.011802673339844\n",
      "Eval_AverageEpLen : 59.529411764705884\n",
      "Train_AverageReturn : 88.73638916015625\n",
      "Train_StdReturn : 42.677974700927734\n",
      "Train_MaxReturn : 166.17819213867188\n",
      "Train_MinReturn : 28.322845458984375\n",
      "Train_AverageEpLen : 49.09313725490196\n",
      "Train_EnvstepsSoFar : 782340\n",
      "TimeSinceStart : 459.9835059642792\n",
      "Training Loss : 116.27645874023438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 124.80982208251953\n",
      "Eval_StdReturn : 38.8250617980957\n",
      "Eval_MaxReturn : 159.0561065673828\n",
      "Eval_MinReturn : 51.91299057006836\n",
      "Eval_AverageEpLen : 69.8\n",
      "Train_AverageReturn : 99.01190948486328\n",
      "Train_StdReturn : 46.72852325439453\n",
      "Train_MaxReturn : 180.13864135742188\n",
      "Train_MinReturn : 44.361167907714844\n",
      "Train_AverageEpLen : 54.67934782608695\n",
      "Train_EnvstepsSoFar : 792401\n",
      "TimeSinceStart : 465.75197982788086\n",
      "Training Loss : 118.96405792236328\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10079 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 98.70974731445312\n",
      "Eval_StdReturn : 27.261503219604492\n",
      "Eval_MaxReturn : 156.61790466308594\n",
      "Eval_MinReturn : 51.98115921020508\n",
      "Eval_AverageEpLen : 58.22222222222222\n",
      "Train_AverageReturn : 119.34239959716797\n",
      "Train_StdReturn : 43.06623458862305\n",
      "Train_MaxReturn : 168.6603546142578\n",
      "Train_MinReturn : 41.251869201660156\n",
      "Train_AverageEpLen : 66.3092105263158\n",
      "Train_EnvstepsSoFar : 802480\n",
      "TimeSinceStart : 471.9267084598541\n",
      "Training Loss : 122.79369354248047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 81.27751922607422\n",
      "Eval_StdReturn : 21.304407119750977\n",
      "Eval_MaxReturn : 113.23604583740234\n",
      "Eval_MinReturn : 46.59971618652344\n",
      "Eval_AverageEpLen : 48.666666666666664\n",
      "Train_AverageReturn : 100.27706909179688\n",
      "Train_StdReturn : 35.521568298339844\n",
      "Train_MaxReturn : 166.55552673339844\n",
      "Train_MinReturn : 43.729949951171875\n",
      "Train_AverageEpLen : 58.20348837209303\n",
      "Train_EnvstepsSoFar : 812491\n",
      "TimeSinceStart : 477.9081666469574\n",
      "Training Loss : 119.34117126464844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 67.5831527709961\n",
      "Eval_StdReturn : 25.678579330444336\n",
      "Eval_MaxReturn : 134.73934936523438\n",
      "Eval_MinReturn : 6.607504844665527\n",
      "Eval_AverageEpLen : 41.04\n",
      "Train_AverageReturn : 74.31061553955078\n",
      "Train_StdReturn : 29.497249603271484\n",
      "Train_MaxReturn : 155.03292846679688\n",
      "Train_MinReturn : 6.359097957611084\n",
      "Train_AverageEpLen : 44.66517857142857\n",
      "Train_EnvstepsSoFar : 822496\n",
      "TimeSinceStart : 484.0933585166931\n",
      "Training Loss : 112.16842651367188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 55.7696647644043\n",
      "Eval_StdReturn : 23.609630584716797\n",
      "Eval_MaxReturn : 117.58773040771484\n",
      "Eval_MinReturn : 9.911437034606934\n",
      "Eval_AverageEpLen : 34.5\n",
      "Train_AverageReturn : 56.45401382446289\n",
      "Train_StdReturn : 21.964088439941406\n",
      "Train_MaxReturn : 118.83305358886719\n",
      "Train_MinReturn : 6.667284965515137\n",
      "Train_AverageEpLen : 34.84320557491289\n",
      "Train_EnvstepsSoFar : 832496\n",
      "TimeSinceStart : 490.32576417922974\n",
      "Training Loss : 102.67411804199219\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 69.76872253417969\n",
      "Eval_StdReturn : 21.325885772705078\n",
      "Eval_MaxReturn : 123.36231231689453\n",
      "Eval_MinReturn : 39.95802307128906\n",
      "Eval_AverageEpLen : 42.041666666666664\n",
      "Train_AverageReturn : 54.40851974487305\n",
      "Train_StdReturn : 20.43967628479004\n",
      "Train_MaxReturn : 122.00033569335938\n",
      "Train_MinReturn : 6.737093448638916\n",
      "Train_AverageEpLen : 33.68350168350168\n",
      "Train_EnvstepsSoFar : 842500\n",
      "TimeSinceStart : 496.1115424633026\n",
      "Training Loss : 100.6867904663086\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 120.33382415771484\n",
      "Eval_StdReturn : 41.29619216918945\n",
      "Eval_MaxReturn : 161.37281799316406\n",
      "Eval_MinReturn : 23.168231964111328\n",
      "Eval_AverageEpLen : 67.66666666666667\n",
      "Train_AverageReturn : 72.2253189086914\n",
      "Train_StdReturn : 26.115215301513672\n",
      "Train_MaxReturn : 151.93887329101562\n",
      "Train_MinReturn : 6.588310241699219\n",
      "Train_AverageEpLen : 43.49130434782609\n",
      "Train_EnvstepsSoFar : 852503\n",
      "TimeSinceStart : 501.89989042282104\n",
      "Training Loss : 111.59317016601562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 128.04002380371094\n",
      "Eval_StdReturn : 41.91440963745117\n",
      "Eval_MaxReturn : 163.47845458984375\n",
      "Eval_MinReturn : 56.29254913330078\n",
      "Eval_AverageEpLen : 69.93333333333334\n",
      "Train_AverageReturn : 113.1844253540039\n",
      "Train_StdReturn : 33.2979736328125\n",
      "Train_MaxReturn : 165.45089721679688\n",
      "Train_MinReturn : 34.81591796875\n",
      "Train_AverageEpLen : 64.78709677419354\n",
      "Train_EnvstepsSoFar : 862545\n",
      "TimeSinceStart : 507.7179431915283\n",
      "Training Loss : 121.67650604248047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10072 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 110.03030395507812\n",
      "Eval_StdReturn : 49.7185173034668\n",
      "Eval_MaxReturn : 165.47158813476562\n",
      "Eval_MinReturn : 50.34221649169922\n",
      "Eval_AverageEpLen : 59.833333333333336\n",
      "Train_AverageReturn : 137.92666625976562\n",
      "Train_StdReturn : 36.56267547607422\n",
      "Train_MaxReturn : 168.19764709472656\n",
      "Train_MinReturn : 46.25919723510742\n",
      "Train_AverageEpLen : 75.16417910447761\n",
      "Train_EnvstepsSoFar : 872617\n",
      "TimeSinceStart : 513.5240252017975\n",
      "Training Loss : 125.21544647216797\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 91.27529907226562\n",
      "Eval_StdReturn : 46.56386184692383\n",
      "Eval_MaxReturn : 165.7545623779297\n",
      "Eval_MinReturn : 50.414207458496094\n",
      "Eval_AverageEpLen : 50.2\n",
      "Train_AverageReturn : 124.58850860595703\n",
      "Train_StdReturn : 46.1252555847168\n",
      "Train_MaxReturn : 167.7061309814453\n",
      "Train_MinReturn : 43.02655792236328\n",
      "Train_AverageEpLen : 67.42953020134229\n",
      "Train_EnvstepsSoFar : 882664\n",
      "TimeSinceStart : 519.3168425559998\n",
      "Training Loss : 124.08980560302734\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 103.36946868896484\n",
      "Eval_StdReturn : 52.59879684448242\n",
      "Eval_MaxReturn : 164.42298889160156\n",
      "Eval_MinReturn : 44.813594818115234\n",
      "Eval_AverageEpLen : 56.22222222222222\n",
      "Train_AverageReturn : 103.83895874023438\n",
      "Train_StdReturn : 49.56297302246094\n",
      "Train_MaxReturn : 168.45413208007812\n",
      "Train_MinReturn : 39.538238525390625\n",
      "Train_AverageEpLen : 56.50282485875706\n",
      "Train_EnvstepsSoFar : 892665\n",
      "TimeSinceStart : 525.0263633728027\n",
      "Training Loss : 119.84271240234375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 76.6016616821289\n",
      "Eval_StdReturn : 32.52434158325195\n",
      "Eval_MaxReturn : 166.62132263183594\n",
      "Eval_MinReturn : 46.197933197021484\n",
      "Eval_AverageEpLen : 43.0\n",
      "Train_AverageReturn : 87.80876922607422\n",
      "Train_StdReturn : 46.104610443115234\n",
      "Train_MaxReturn : 167.24632263183594\n",
      "Train_MinReturn : 42.601539611816406\n",
      "Train_AverageEpLen : 48.40096618357488\n",
      "Train_EnvstepsSoFar : 902684\n",
      "TimeSinceStart : 530.8779053688049\n",
      "Training Loss : 115.75035858154297\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10030 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 72.69005584716797\n",
      "Eval_StdReturn : 38.39044189453125\n",
      "Eval_MaxReturn : 164.36135864257812\n",
      "Eval_MinReturn : 44.08959197998047\n",
      "Eval_AverageEpLen : 40.88\n",
      "Train_AverageReturn : 78.13310241699219\n",
      "Train_StdReturn : 40.8459358215332\n",
      "Train_MaxReturn : 168.13558959960938\n",
      "Train_MinReturn : 41.234764099121094\n",
      "Train_AverageEpLen : 43.608695652173914\n",
      "Train_EnvstepsSoFar : 912714\n",
      "TimeSinceStart : 536.7766354084015\n",
      "Training Loss : 112.17298889160156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10030 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 82.80425262451172\n",
      "Eval_StdReturn : 42.88312911987305\n",
      "Eval_MaxReturn : 162.5880126953125\n",
      "Eval_MinReturn : 42.30925369262695\n",
      "Eval_AverageEpLen : 46.36363636363637\n",
      "Train_AverageReturn : 73.65646362304688\n",
      "Train_StdReturn : 38.56306457519531\n",
      "Train_MaxReturn : 165.9118194580078\n",
      "Train_MinReturn : 39.3707160949707\n",
      "Train_AverageEpLen : 41.446280991735534\n",
      "Train_EnvstepsSoFar : 922744\n",
      "TimeSinceStart : 542.6101307868958\n",
      "Training Loss : 111.2486801147461\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10027 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 101.53201293945312\n",
      "Eval_StdReturn : 47.628028869628906\n",
      "Eval_MaxReturn : 164.40081787109375\n",
      "Eval_MinReturn : 47.6956672668457\n",
      "Eval_AverageEpLen : 56.27777777777778\n",
      "Train_AverageReturn : 79.21698760986328\n",
      "Train_StdReturn : 43.45854187011719\n",
      "Train_MaxReturn : 167.87844848632812\n",
      "Train_MinReturn : 36.017005920410156\n",
      "Train_AverageEpLen : 44.36725663716814\n",
      "Train_EnvstepsSoFar : 932771\n",
      "TimeSinceStart : 548.3945481777191\n",
      "Training Loss : 111.50867462158203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10065 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 118.4609146118164\n",
      "Eval_StdReturn : 29.02226448059082\n",
      "Eval_MaxReturn : 153.74838256835938\n",
      "Eval_MinReturn : 67.91352844238281\n",
      "Eval_AverageEpLen : 67.93333333333334\n",
      "Train_AverageReturn : 113.89315032958984\n",
      "Train_StdReturn : 50.08354949951172\n",
      "Train_MaxReturn : 166.00601196289062\n",
      "Train_MinReturn : 42.058807373046875\n",
      "Train_AverageEpLen : 62.515527950310556\n",
      "Train_EnvstepsSoFar : 942836\n",
      "TimeSinceStart : 554.1815500259399\n",
      "Training Loss : 119.83174133300781\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10070 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 85.19209289550781\n",
      "Eval_StdReturn : 20.7861270904541\n",
      "Eval_MaxReturn : 116.9322280883789\n",
      "Eval_MinReturn : 54.55174255371094\n",
      "Eval_AverageEpLen : 51.65\n",
      "Train_AverageReturn : 123.60826110839844\n",
      "Train_StdReturn : 30.398258209228516\n",
      "Train_MaxReturn : 159.62754821777344\n",
      "Train_MinReturn : 47.76982498168945\n",
      "Train_AverageEpLen : 70.91549295774648\n",
      "Train_EnvstepsSoFar : 952906\n",
      "TimeSinceStart : 559.9264736175537\n",
      "Training Loss : 120.9764175415039\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 56.381893157958984\n",
      "Eval_StdReturn : 15.175424575805664\n",
      "Eval_MaxReturn : 88.45310974121094\n",
      "Eval_MinReturn : 8.009119033813477\n",
      "Eval_AverageEpLen : 35.13793103448276\n",
      "Train_AverageReturn : 82.46581268310547\n",
      "Train_StdReturn : 23.47562599182129\n",
      "Train_MaxReturn : 154.1818389892578\n",
      "Train_MinReturn : 6.391584396362305\n",
      "Train_AverageEpLen : 49.87064676616915\n",
      "Train_EnvstepsSoFar : 962930\n",
      "TimeSinceStart : 565.684942483902\n",
      "Training Loss : 112.65841674804688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 54.56000900268555\n",
      "Eval_StdReturn : 9.079323768615723\n",
      "Eval_MaxReturn : 72.44391632080078\n",
      "Eval_MinReturn : 39.04841232299805\n",
      "Eval_AverageEpLen : 34.03333333333333\n",
      "Train_AverageReturn : 59.67282485961914\n",
      "Train_StdReturn : 12.77482795715332\n",
      "Train_MaxReturn : 110.40572357177734\n",
      "Train_MinReturn : 21.585826873779297\n",
      "Train_AverageEpLen : 36.97785977859779\n",
      "Train_EnvstepsSoFar : 972951\n",
      "TimeSinceStart : 571.6049196720123\n",
      "Training Loss : 101.47498321533203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 49.976200103759766\n",
      "Eval_StdReturn : 6.90825080871582\n",
      "Eval_MaxReturn : 67.52346801757812\n",
      "Eval_MinReturn : 40.151493072509766\n",
      "Eval_AverageEpLen : 31.46875\n",
      "Train_AverageReturn : 52.886451721191406\n",
      "Train_StdReturn : 11.543645858764648\n",
      "Train_MaxReturn : 93.92520141601562\n",
      "Train_MinReturn : 9.59881591796875\n",
      "Train_AverageEpLen : 33.17218543046358\n",
      "Train_EnvstepsSoFar : 982969\n",
      "TimeSinceStart : 577.7084231376648\n",
      "Training Loss : 96.39898681640625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.19910430908203\n",
      "Eval_StdReturn : 13.540573120117188\n",
      "Eval_MaxReturn : 73.2303237915039\n",
      "Eval_MinReturn : 9.70672607421875\n",
      "Eval_AverageEpLen : 29.441176470588236\n",
      "Train_AverageReturn : 48.973060607910156\n",
      "Train_StdReturn : 11.16067123413086\n",
      "Train_MaxReturn : 85.7073745727539\n",
      "Train_MinReturn : 6.443571090698242\n",
      "Train_AverageEpLen : 30.962848297213622\n",
      "Train_EnvstepsSoFar : 992970\n",
      "TimeSinceStart : 583.5868973731995\n",
      "Training Loss : 93.4225082397461\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.02812194824219\n",
      "Eval_StdReturn : 6.392757892608643\n",
      "Eval_MaxReturn : 66.78559112548828\n",
      "Eval_MinReturn : 25.32854652404785\n",
      "Eval_AverageEpLen : 29.257142857142856\n",
      "Train_AverageReturn : 47.34477996826172\n",
      "Train_StdReturn : 8.355034828186035\n",
      "Train_MaxReturn : 77.98038482666016\n",
      "Train_MinReturn : 7.965350151062012\n",
      "Train_AverageEpLen : 29.98502994011976\n",
      "Train_EnvstepsSoFar : 1002985\n",
      "TimeSinceStart : 589.6628224849701\n",
      "Training Loss : 91.93570709228516\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "Running policy gradient experiment with seed 2\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/full_returns/seed2\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 72.05300903320312\n",
      "Eval_StdReturn : 27.938655853271484\n",
      "Eval_MaxReturn : 178.54859924316406\n",
      "Eval_MinReturn : 24.232091903686523\n",
      "Eval_AverageEpLen : 47.13636363636363\n",
      "Train_AverageReturn : 18.039928436279297\n",
      "Train_StdReturn : 17.921995162963867\n",
      "Train_MaxReturn : 141.83033752441406\n",
      "Train_MinReturn : 3.2006664276123047\n",
      "Train_AverageEpLen : 21.3\n",
      "Train_EnvstepsSoFar : 10011\n",
      "TimeSinceStart : 6.1922993659973145\n",
      "Training Loss : 52.6212272644043\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 56.1874885559082\n",
      "Eval_StdReturn : 14.260284423828125\n",
      "Eval_MaxReturn : 119.25653076171875\n",
      "Eval_MinReturn : 41.613128662109375\n",
      "Eval_AverageEpLen : 33.36666666666667\n",
      "Train_AverageReturn : 71.92474365234375\n",
      "Train_StdReturn : 29.85662078857422\n",
      "Train_MaxReturn : 171.8468475341797\n",
      "Train_MinReturn : 3.4161911010742188\n",
      "Train_AverageEpLen : 47.46919431279621\n",
      "Train_EnvstepsSoFar : 20027\n",
      "TimeSinceStart : 12.011017560958862\n",
      "Training Loss : 97.51644134521484\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10031 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 60.87708282470703\n",
      "Eval_StdReturn : 27.4653377532959\n",
      "Eval_MaxReturn : 190.0204620361328\n",
      "Eval_MinReturn : 42.60499954223633\n",
      "Eval_AverageEpLen : 36.285714285714285\n",
      "Train_AverageReturn : 58.340431213378906\n",
      "Train_StdReturn : 20.813169479370117\n",
      "Train_MaxReturn : 201.78147888183594\n",
      "Train_MinReturn : 37.995121002197266\n",
      "Train_AverageEpLen : 34.58965517241379\n",
      "Train_EnvstepsSoFar : 30058\n",
      "TimeSinceStart : 17.92790722846985\n",
      "Training Loss : 103.97002410888672\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10014 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 47.875038146972656\n",
      "Eval_StdReturn : 30.388137817382812\n",
      "Eval_MaxReturn : 116.91033172607422\n",
      "Eval_MinReturn : 10.439657211303711\n",
      "Eval_AverageEpLen : 32.46875\n",
      "Train_AverageReturn : 62.098751068115234\n",
      "Train_StdReturn : 22.059219360351562\n",
      "Train_MaxReturn : 245.02613830566406\n",
      "Train_MinReturn : 16.46202850341797\n",
      "Train_AverageEpLen : 36.952029520295206\n",
      "Train_EnvstepsSoFar : 40072\n",
      "TimeSinceStart : 24.15817666053772\n",
      "Training Loss : 106.96412658691406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 59.57714080810547\n",
      "Eval_StdReturn : 42.92009353637695\n",
      "Eval_MaxReturn : 142.364990234375\n",
      "Eval_MinReturn : 12.997267723083496\n",
      "Eval_AverageEpLen : 35.892857142857146\n",
      "Train_AverageReturn : 42.67450714111328\n",
      "Train_StdReturn : 31.31557846069336\n",
      "Train_MaxReturn : 144.5839080810547\n",
      "Train_MinReturn : 9.400146484375\n",
      "Train_AverageEpLen : 29.06086956521739\n",
      "Train_EnvstepsSoFar : 50098\n",
      "TimeSinceStart : 30.101561546325684\n",
      "Training Loss : 90.41988372802734\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 85.5884780883789\n",
      "Eval_StdReturn : 21.032732009887695\n",
      "Eval_MaxReturn : 134.75462341308594\n",
      "Eval_MinReturn : 50.88334655761719\n",
      "Eval_AverageEpLen : 48.61904761904762\n",
      "Train_AverageReturn : 58.82576370239258\n",
      "Train_StdReturn : 37.56162643432617\n",
      "Train_MaxReturn : 155.90972900390625\n",
      "Train_MinReturn : 9.003837585449219\n",
      "Train_AverageEpLen : 36.04676258992806\n",
      "Train_EnvstepsSoFar : 60119\n",
      "TimeSinceStart : 36.22529220581055\n",
      "Training Loss : 102.77259063720703\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 74.95232391357422\n",
      "Eval_StdReturn : 20.044593811035156\n",
      "Eval_MaxReturn : 152.02236938476562\n",
      "Eval_MinReturn : 54.643917083740234\n",
      "Eval_AverageEpLen : 42.916666666666664\n",
      "Train_AverageReturn : 82.30855560302734\n",
      "Train_StdReturn : 22.288837432861328\n",
      "Train_MaxReturn : 197.1876678466797\n",
      "Train_MinReturn : 44.812034606933594\n",
      "Train_AverageEpLen : 47.070422535211264\n",
      "Train_EnvstepsSoFar : 70145\n",
      "TimeSinceStart : 42.18422079086304\n",
      "Training Loss : 115.70476531982422\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 68.00277709960938\n",
      "Eval_StdReturn : 10.942890167236328\n",
      "Eval_MaxReturn : 88.16064453125\n",
      "Eval_MinReturn : 44.20515441894531\n",
      "Eval_AverageEpLen : 38.69230769230769\n",
      "Train_AverageReturn : 74.5136947631836\n",
      "Train_StdReturn : 13.76232624053955\n",
      "Train_MaxReturn : 135.09153747558594\n",
      "Train_MinReturn : 47.19094467163086\n",
      "Train_AverageEpLen : 42.5531914893617\n",
      "Train_EnvstepsSoFar : 80145\n",
      "TimeSinceStart : 48.24982833862305\n",
      "Training Loss : 116.5367660522461\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 60.08552551269531\n",
      "Eval_StdReturn : 8.392727851867676\n",
      "Eval_MaxReturn : 79.63410186767578\n",
      "Eval_MinReturn : 46.09415054321289\n",
      "Eval_AverageEpLen : 33.93333333333333\n",
      "Train_AverageReturn : 64.28266143798828\n",
      "Train_StdReturn : 9.76314926147461\n",
      "Train_MaxReturn : 95.031005859375\n",
      "Train_MinReturn : 42.15678024291992\n",
      "Train_AverageEpLen : 36.52189781021898\n",
      "Train_EnvstepsSoFar : 90152\n",
      "TimeSinceStart : 54.39071297645569\n",
      "Training Loss : 112.88048553466797\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 53.32174301147461\n",
      "Eval_StdReturn : 6.94789457321167\n",
      "Eval_MaxReturn : 67.24082946777344\n",
      "Eval_MinReturn : 40.264400482177734\n",
      "Eval_AverageEpLen : 30.11764705882353\n",
      "Train_AverageReturn : 58.971981048583984\n",
      "Train_StdReturn : 7.836675643920898\n",
      "Train_MaxReturn : 85.82356262207031\n",
      "Train_MinReturn : 41.35552978515625\n",
      "Train_AverageEpLen : 33.30232558139535\n",
      "Train_EnvstepsSoFar : 100176\n",
      "TimeSinceStart : 60.7504243850708\n",
      "Training Loss : 110.8554458618164\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 50.03548049926758\n",
      "Eval_StdReturn : 5.424006462097168\n",
      "Eval_MaxReturn : 68.03564453125\n",
      "Eval_MinReturn : 42.249046325683594\n",
      "Eval_AverageEpLen : 28.166666666666668\n",
      "Train_AverageReturn : 52.7808837890625\n",
      "Train_StdReturn : 6.427823543548584\n",
      "Train_MaxReturn : 80.89190673828125\n",
      "Train_MinReturn : 40.761417388916016\n",
      "Train_AverageEpLen : 29.776785714285715\n",
      "Train_EnvstepsSoFar : 110181\n",
      "TimeSinceStart : 67.14800763130188\n",
      "Training Loss : 106.51749420166016\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.96261215209961\n",
      "Eval_StdReturn : 3.5527422428131104\n",
      "Eval_MaxReturn : 53.5547981262207\n",
      "Eval_MinReturn : 39.969993591308594\n",
      "Eval_AverageEpLen : 26.55263157894737\n",
      "Train_AverageReturn : 48.511451721191406\n",
      "Train_StdReturn : 4.606869220733643\n",
      "Train_MaxReturn : 68.28569030761719\n",
      "Train_MinReturn : 38.752838134765625\n",
      "Train_AverageEpLen : 27.40821917808219\n",
      "Train_EnvstepsSoFar : 120185\n",
      "TimeSinceStart : 73.1442322731018\n",
      "Training Loss : 102.92713165283203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.25414276123047\n",
      "Eval_StdReturn : 3.867197275161743\n",
      "Eval_MaxReturn : 56.37682342529297\n",
      "Eval_MinReturn : 40.62657165527344\n",
      "Eval_AverageEpLen : 26.205128205128204\n",
      "Train_AverageReturn : 45.86508560180664\n",
      "Train_StdReturn : 3.6726088523864746\n",
      "Train_MaxReturn : 58.38081359863281\n",
      "Train_MinReturn : 36.6279296875\n",
      "Train_AverageEpLen : 25.984415584415583\n",
      "Train_EnvstepsSoFar : 130189\n",
      "TimeSinceStart : 78.95344877243042\n",
      "Training Loss : 99.26728057861328\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10022 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.8675537109375\n",
      "Eval_StdReturn : 3.325740098953247\n",
      "Eval_MaxReturn : 53.112709045410156\n",
      "Eval_MinReturn : 40.13200378417969\n",
      "Eval_AverageEpLen : 26.55263157894737\n",
      "Train_AverageReturn : 45.9146614074707\n",
      "Train_StdReturn : 3.6197853088378906\n",
      "Train_MaxReturn : 65.03849029541016\n",
      "Train_MinReturn : 38.21608352661133\n",
      "Train_AverageEpLen : 26.03116883116883\n",
      "Train_EnvstepsSoFar : 140211\n",
      "TimeSinceStart : 84.80716133117676\n",
      "Training Loss : 100.07057189941406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 48.232383728027344\n",
      "Eval_StdReturn : 3.887179136276245\n",
      "Eval_MaxReturn : 60.5582160949707\n",
      "Eval_MinReturn : 41.84135437011719\n",
      "Eval_AverageEpLen : 27.243243243243242\n",
      "Train_AverageReturn : 47.430694580078125\n",
      "Train_StdReturn : 3.951700448989868\n",
      "Train_MaxReturn : 62.79624557495117\n",
      "Train_MinReturn : 38.657962799072266\n",
      "Train_AverageEpLen : 26.815013404825738\n",
      "Train_EnvstepsSoFar : 150213\n",
      "TimeSinceStart : 90.65686416625977\n",
      "Training Loss : 101.14140319824219\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 53.315032958984375\n",
      "Eval_StdReturn : 6.660760402679443\n",
      "Eval_MaxReturn : 72.2381362915039\n",
      "Eval_MinReturn : 43.640716552734375\n",
      "Eval_AverageEpLen : 29.970588235294116\n",
      "Train_AverageReturn : 49.09788513183594\n",
      "Train_StdReturn : 4.147603988647461\n",
      "Train_MaxReturn : 66.08675384521484\n",
      "Train_MinReturn : 38.4382438659668\n",
      "Train_AverageEpLen : 27.7202216066482\n",
      "Train_EnvstepsSoFar : 160220\n",
      "TimeSinceStart : 96.48830127716064\n",
      "Training Loss : 102.48096466064453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 57.16758728027344\n",
      "Eval_StdReturn : 6.5854811668396\n",
      "Eval_MaxReturn : 71.66490173339844\n",
      "Eval_MinReturn : 45.47835159301758\n",
      "Eval_AverageEpLen : 32.03125\n",
      "Train_AverageReturn : 51.68159484863281\n",
      "Train_StdReturn : 4.969557285308838\n",
      "Train_MaxReturn : 66.79478454589844\n",
      "Train_MinReturn : 40.29534912109375\n",
      "Train_AverageEpLen : 29.069767441860463\n",
      "Train_EnvstepsSoFar : 170220\n",
      "TimeSinceStart : 102.27424144744873\n",
      "Training Loss : 105.60030364990234\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 64.4566650390625\n",
      "Eval_StdReturn : 9.331672668457031\n",
      "Eval_MaxReturn : 85.04415130615234\n",
      "Eval_MinReturn : 49.255523681640625\n",
      "Eval_AverageEpLen : 35.92857142857143\n",
      "Train_AverageReturn : 55.8061408996582\n",
      "Train_StdReturn : 6.176363945007324\n",
      "Train_MaxReturn : 79.36624145507812\n",
      "Train_MinReturn : 44.12183380126953\n",
      "Train_AverageEpLen : 31.25\n",
      "Train_EnvstepsSoFar : 180220\n",
      "TimeSinceStart : 108.0269992351532\n",
      "Training Loss : 108.99337768554688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10046 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 71.2956771850586\n",
      "Eval_StdReturn : 10.52505874633789\n",
      "Eval_MaxReturn : 97.08528900146484\n",
      "Eval_MinReturn : 56.645477294921875\n",
      "Eval_AverageEpLen : 39.57692307692308\n",
      "Train_AverageReturn : 63.55412292480469\n",
      "Train_StdReturn : 8.055344581604004\n",
      "Train_MaxReturn : 91.95414733886719\n",
      "Train_MinReturn : 44.255584716796875\n",
      "Train_AverageEpLen : 35.37323943661972\n",
      "Train_EnvstepsSoFar : 190266\n",
      "TimeSinceStart : 113.78517532348633\n",
      "Training Loss : 114.09996795654297\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10038 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 78.40018463134766\n",
      "Eval_StdReturn : 11.953818321228027\n",
      "Eval_MaxReturn : 99.43965911865234\n",
      "Eval_MinReturn : 53.44575119018555\n",
      "Eval_AverageEpLen : 43.375\n",
      "Train_AverageReturn : 71.81624603271484\n",
      "Train_StdReturn : 9.755313873291016\n",
      "Train_MaxReturn : 109.37303924560547\n",
      "Train_MinReturn : 49.97617721557617\n",
      "Train_AverageEpLen : 39.833333333333336\n",
      "Train_EnvstepsSoFar : 200304\n",
      "TimeSinceStart : 119.45604300498962\n",
      "Training Loss : 119.51349639892578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 88.52372741699219\n",
      "Eval_StdReturn : 11.80675983428955\n",
      "Eval_MaxReturn : 112.59185028076172\n",
      "Eval_MinReturn : 63.46894073486328\n",
      "Eval_AverageEpLen : 49.0\n",
      "Train_AverageReturn : 78.26908874511719\n",
      "Train_StdReturn : 11.98458480834961\n",
      "Train_MaxReturn : 113.78114318847656\n",
      "Train_MinReturn : 55.71416473388672\n",
      "Train_AverageEpLen : 43.324675324675326\n",
      "Train_EnvstepsSoFar : 210312\n",
      "TimeSinceStart : 125.08547377586365\n",
      "Training Loss : 122.57034301757812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10027 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 106.17292022705078\n",
      "Eval_StdReturn : 23.616809844970703\n",
      "Eval_MaxReturn : 149.09707641601562\n",
      "Eval_MinReturn : 66.69055938720703\n",
      "Eval_AverageEpLen : 57.72222222222222\n",
      "Train_AverageReturn : 89.50199890136719\n",
      "Train_StdReturn : 14.485979080200195\n",
      "Train_MaxReturn : 135.44044494628906\n",
      "Train_MinReturn : 58.92864990234375\n",
      "Train_AverageEpLen : 49.39408866995074\n",
      "Train_EnvstepsSoFar : 220339\n",
      "TimeSinceStart : 130.7555432319641\n",
      "Training Loss : 126.67736053466797\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 142.84555053710938\n",
      "Eval_StdReturn : 18.086313247680664\n",
      "Eval_MaxReturn : 173.11968994140625\n",
      "Eval_MinReturn : 110.21096801757812\n",
      "Eval_AverageEpLen : 74.78571428571429\n",
      "Train_AverageReturn : 100.30380249023438\n",
      "Train_StdReturn : 17.53014373779297\n",
      "Train_MaxReturn : 140.7536163330078\n",
      "Train_MinReturn : 63.320247650146484\n",
      "Train_AverageEpLen : 55.30386740331492\n",
      "Train_EnvstepsSoFar : 230349\n",
      "TimeSinceStart : 136.36913084983826\n",
      "Training Loss : 129.50254821777344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 164.26901245117188\n",
      "Eval_StdReturn : 13.633207321166992\n",
      "Eval_MaxReturn : 178.09422302246094\n",
      "Eval_MinReturn : 126.31309509277344\n",
      "Eval_AverageEpLen : 83.07692307692308\n",
      "Train_AverageReturn : 132.5024871826172\n",
      "Train_StdReturn : 20.973800659179688\n",
      "Train_MaxReturn : 174.00973510742188\n",
      "Train_MinReturn : 80.561279296875\n",
      "Train_AverageEpLen : 70.35664335664336\n",
      "Train_EnvstepsSoFar : 240410\n",
      "TimeSinceStart : 141.96557807922363\n",
      "Training Loss : 134.54391479492188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 24 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.4559326171875\n",
      "Eval_StdReturn : 2.7557685375213623\n",
      "Eval_MaxReturn : 174.5327606201172\n",
      "Eval_MinReturn : 164.7318572998047\n",
      "Eval_AverageEpLen : 86.25\n",
      "Train_AverageReturn : 164.6602325439453\n",
      "Train_StdReturn : 12.459115028381348\n",
      "Train_MaxReturn : 176.40675354003906\n",
      "Train_MinReturn : 110.27163696289062\n",
      "Train_AverageEpLen : 83.575\n",
      "Train_EnvstepsSoFar : 250439\n",
      "TimeSinceStart : 147.61315393447876\n",
      "Training Loss : 137.34579467773438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 25 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.3219757080078\n",
      "Eval_StdReturn : 2.3341619968414307\n",
      "Eval_MaxReturn : 173.4562530517578\n",
      "Eval_MinReturn : 164.8521270751953\n",
      "Eval_AverageEpLen : 86.41666666666667\n",
      "Train_AverageReturn : 170.60546875\n",
      "Train_StdReturn : 2.6212594509124756\n",
      "Train_MaxReturn : 176.16514587402344\n",
      "Train_MinReturn : 159.68246459960938\n",
      "Train_AverageEpLen : 86.42241379310344\n",
      "Train_EnvstepsSoFar : 260464\n",
      "TimeSinceStart : 153.1684284210205\n",
      "Training Loss : 137.8948211669922\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 26 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.03384399414062\n",
      "Eval_StdReturn : 2.324009418487549\n",
      "Eval_MaxReturn : 171.7263946533203\n",
      "Eval_MinReturn : 162.55105590820312\n",
      "Eval_AverageEpLen : 86.5\n",
      "Train_AverageReturn : 170.11537170410156\n",
      "Train_StdReturn : 2.083436965942383\n",
      "Train_MaxReturn : 176.33309936523438\n",
      "Train_MinReturn : 163.81982421875\n",
      "Train_AverageEpLen : 86.51724137931035\n",
      "Train_EnvstepsSoFar : 270500\n",
      "TimeSinceStart : 158.77381706237793\n",
      "Training Loss : 137.64657592773438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 27 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10032 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.52536010742188\n",
      "Eval_StdReturn : 1.7508143186569214\n",
      "Eval_MaxReturn : 173.429443359375\n",
      "Eval_MinReturn : 167.6877899169922\n",
      "Eval_AverageEpLen : 86.5\n",
      "Train_AverageReturn : 169.13201904296875\n",
      "Train_StdReturn : 2.537349224090576\n",
      "Train_MaxReturn : 175.03607177734375\n",
      "Train_MinReturn : 162.90139770507812\n",
      "Train_AverageEpLen : 86.48275862068965\n",
      "Train_EnvstepsSoFar : 280532\n",
      "TimeSinceStart : 164.43174004554749\n",
      "Training Loss : 137.0660858154297\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 28 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.5251007080078\n",
      "Eval_StdReturn : 2.6425979137420654\n",
      "Eval_MaxReturn : 176.01666259765625\n",
      "Eval_MinReturn : 167.08502197265625\n",
      "Eval_AverageEpLen : 86.33333333333333\n",
      "Train_AverageReturn : 170.13742065429688\n",
      "Train_StdReturn : 2.745771884918213\n",
      "Train_MaxReturn : 178.80398559570312\n",
      "Train_MinReturn : 162.8319091796875\n",
      "Train_AverageEpLen : 86.40517241379311\n",
      "Train_EnvstepsSoFar : 290555\n",
      "TimeSinceStart : 170.0237216949463\n",
      "Training Loss : 137.375244140625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 29 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10022 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 164.20956420898438\n",
      "Eval_StdReturn : 20.02613067626953\n",
      "Eval_MaxReturn : 176.0023193359375\n",
      "Eval_MinReturn : 97.19072723388672\n",
      "Eval_AverageEpLen : 82.6923076923077\n",
      "Train_AverageReturn : 170.1147003173828\n",
      "Train_StdReturn : 8.109954833984375\n",
      "Train_MaxReturn : 179.36944580078125\n",
      "Train_MinReturn : 105.9695816040039\n",
      "Train_AverageEpLen : 85.65811965811966\n",
      "Train_EnvstepsSoFar : 300577\n",
      "TimeSinceStart : 175.66306829452515\n",
      "Training Loss : 138.04840087890625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 30 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10045 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 129.32394409179688\n",
      "Eval_StdReturn : 21.25966453552246\n",
      "Eval_MaxReturn : 169.27549743652344\n",
      "Eval_MinReturn : 95.64447784423828\n",
      "Eval_AverageEpLen : 68.93333333333334\n",
      "Train_AverageReturn : 154.17515563964844\n",
      "Train_StdReturn : 18.980478286743164\n",
      "Train_MaxReturn : 177.03985595703125\n",
      "Train_MinReturn : 98.33757019042969\n",
      "Train_AverageEpLen : 79.09448818897638\n",
      "Train_EnvstepsSoFar : 310622\n",
      "TimeSinceStart : 181.23534059524536\n",
      "Training Loss : 137.5537872314453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 31 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 134.7541046142578\n",
      "Eval_StdReturn : 22.343891143798828\n",
      "Eval_MaxReturn : 171.21563720703125\n",
      "Eval_MinReturn : 86.26103210449219\n",
      "Eval_AverageEpLen : 71.26666666666667\n",
      "Train_AverageReturn : 141.73779296875\n",
      "Train_StdReturn : 19.246862411499023\n",
      "Train_MaxReturn : 177.06069946289062\n",
      "Train_MinReturn : 84.4683609008789\n",
      "Train_AverageEpLen : 74.21481481481482\n",
      "Train_EnvstepsSoFar : 320641\n",
      "TimeSinceStart : 186.84612941741943\n",
      "Training Loss : 136.97323608398438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 32 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 110.46867370605469\n",
      "Eval_StdReturn : 18.784250259399414\n",
      "Eval_MaxReturn : 139.08355712890625\n",
      "Eval_MinReturn : 60.62091827392578\n",
      "Eval_AverageEpLen : 61.11764705882353\n",
      "Train_AverageReturn : 130.41024780273438\n",
      "Train_StdReturn : 22.70660972595215\n",
      "Train_MaxReturn : 177.1537628173828\n",
      "Train_MinReturn : 57.42026138305664\n",
      "Train_AverageEpLen : 69.54861111111111\n",
      "Train_EnvstepsSoFar : 330656\n",
      "TimeSinceStart : 192.4509596824646\n",
      "Training Loss : 136.18121337890625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 33 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 110.59954071044922\n",
      "Eval_StdReturn : 16.021692276000977\n",
      "Eval_MaxReturn : 138.3227081298828\n",
      "Eval_MinReturn : 68.46000671386719\n",
      "Eval_AverageEpLen : 61.11764705882353\n",
      "Train_AverageReturn : 113.22340393066406\n",
      "Train_StdReturn : 19.252553939819336\n",
      "Train_MaxReturn : 173.75344848632812\n",
      "Train_MinReturn : 58.39531326293945\n",
      "Train_AverageEpLen : 61.80246913580247\n",
      "Train_EnvstepsSoFar : 340668\n",
      "TimeSinceStart : 198.06166315078735\n",
      "Training Loss : 133.27102661132812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 34 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 95.08306121826172\n",
      "Eval_StdReturn : 14.358170509338379\n",
      "Eval_MaxReturn : 125.12190246582031\n",
      "Eval_MinReturn : 67.21814727783203\n",
      "Eval_AverageEpLen : 52.9\n",
      "Train_AverageReturn : 105.65509796142578\n",
      "Train_StdReturn : 18.642410278320312\n",
      "Train_MaxReturn : 171.0699920654297\n",
      "Train_MinReturn : 62.98717498779297\n",
      "Train_AverageEpLen : 57.907514450867055\n",
      "Train_EnvstepsSoFar : 350686\n",
      "TimeSinceStart : 203.65029883384705\n",
      "Training Loss : 132.59762573242188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 35 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 94.55934143066406\n",
      "Eval_StdReturn : 10.661081314086914\n",
      "Eval_MaxReturn : 113.6268539428711\n",
      "Eval_MinReturn : 80.18899536132812\n",
      "Eval_AverageEpLen : 52.25\n",
      "Train_AverageReturn : 98.8837890625\n",
      "Train_StdReturn : 15.508748054504395\n",
      "Train_MaxReturn : 141.1349639892578\n",
      "Train_MinReturn : 62.56840896606445\n",
      "Train_AverageEpLen : 54.55978260869565\n",
      "Train_EnvstepsSoFar : 360725\n",
      "TimeSinceStart : 209.25971269607544\n",
      "Training Loss : 131.1383056640625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 36 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 87.82193756103516\n",
      "Eval_StdReturn : 10.919676780700684\n",
      "Eval_MaxReturn : 104.49575805664062\n",
      "Eval_MinReturn : 66.1131362915039\n",
      "Eval_AverageEpLen : 48.76190476190476\n",
      "Train_AverageReturn : 93.32101440429688\n",
      "Train_StdReturn : 15.090641021728516\n",
      "Train_MaxReturn : 131.42233276367188\n",
      "Train_MinReturn : 61.28562927246094\n",
      "Train_AverageEpLen : 51.69072164948454\n",
      "Train_EnvstepsSoFar : 370753\n",
      "TimeSinceStart : 214.87696480751038\n",
      "Training Loss : 129.21177673339844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 37 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 88.48384857177734\n",
      "Eval_StdReturn : 11.336613655090332\n",
      "Eval_MaxReturn : 105.71725463867188\n",
      "Eval_MinReturn : 70.13934326171875\n",
      "Eval_AverageEpLen : 49.23809523809524\n",
      "Train_AverageReturn : 90.05610656738281\n",
      "Train_StdReturn : 13.943467140197754\n",
      "Train_MaxReturn : 121.55638885498047\n",
      "Train_MinReturn : 58.76682662963867\n",
      "Train_AverageEpLen : 50.195\n",
      "Train_EnvstepsSoFar : 380792\n",
      "TimeSinceStart : 220.4860816001892\n",
      "Training Loss : 128.85557556152344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 38 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 81.9954833984375\n",
      "Eval_StdReturn : 13.611919403076172\n",
      "Eval_MaxReturn : 104.0024185180664\n",
      "Eval_MinReturn : 60.42131423950195\n",
      "Eval_AverageEpLen : 46.27272727272727\n",
      "Train_AverageReturn : 85.79645538330078\n",
      "Train_StdReturn : 11.615157127380371\n",
      "Train_MaxReturn : 117.32821655273438\n",
      "Train_MinReturn : 55.99382781982422\n",
      "Train_AverageEpLen : 47.7952380952381\n",
      "Train_EnvstepsSoFar : 390829\n",
      "TimeSinceStart : 226.0799422264099\n",
      "Training Loss : 127.45025634765625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 39 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 73.7046127319336\n",
      "Eval_StdReturn : 9.772270202636719\n",
      "Eval_MaxReturn : 98.90959930419922\n",
      "Eval_MinReturn : 60.02368927001953\n",
      "Eval_AverageEpLen : 42.125\n",
      "Train_AverageReturn : 82.77327728271484\n",
      "Train_StdReturn : 11.744634628295898\n",
      "Train_MaxReturn : 157.40809631347656\n",
      "Train_MinReturn : 56.295188903808594\n",
      "Train_AverageEpLen : 46.324074074074076\n",
      "Train_EnvstepsSoFar : 400835\n",
      "TimeSinceStart : 231.6719832420349\n",
      "Training Loss : 126.70747375488281\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 40 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 77.71648406982422\n",
      "Eval_StdReturn : 7.578609943389893\n",
      "Eval_MaxReturn : 96.82305908203125\n",
      "Eval_MinReturn : 66.84565734863281\n",
      "Eval_AverageEpLen : 43.78260869565217\n",
      "Train_AverageReturn : 79.84819793701172\n",
      "Train_StdReturn : 9.743306159973145\n",
      "Train_MaxReturn : 107.8943099975586\n",
      "Train_MinReturn : 55.34882736206055\n",
      "Train_AverageEpLen : 44.6875\n",
      "Train_EnvstepsSoFar : 410845\n",
      "TimeSinceStart : 237.28025460243225\n",
      "Training Loss : 124.58582305908203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 41 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 76.93950653076172\n",
      "Eval_StdReturn : 10.12476634979248\n",
      "Eval_MaxReturn : 91.50477600097656\n",
      "Eval_MinReturn : 56.8639030456543\n",
      "Eval_AverageEpLen : 43.416666666666664\n",
      "Train_AverageReturn : 75.8557357788086\n",
      "Train_StdReturn : 9.326984405517578\n",
      "Train_MaxReturn : 107.11385345458984\n",
      "Train_MinReturn : 52.624420166015625\n",
      "Train_AverageEpLen : 42.85470085470085\n",
      "Train_EnvstepsSoFar : 420873\n",
      "TimeSinceStart : 242.91364312171936\n",
      "Training Loss : 123.29883575439453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 42 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 79.26570892333984\n",
      "Eval_StdReturn : 9.860641479492188\n",
      "Eval_MaxReturn : 105.71984100341797\n",
      "Eval_MinReturn : 65.36244201660156\n",
      "Eval_AverageEpLen : 44.56521739130435\n",
      "Train_AverageReturn : 77.13681030273438\n",
      "Train_StdReturn : 9.960456848144531\n",
      "Train_MaxReturn : 124.90870666503906\n",
      "Train_MinReturn : 55.40877151489258\n",
      "Train_AverageEpLen : 43.78165938864629\n",
      "Train_EnvstepsSoFar : 430899\n",
      "TimeSinceStart : 248.47134256362915\n",
      "Training Loss : 123.82244873046875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 43 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 70.41064453125\n",
      "Eval_StdReturn : 8.892614364624023\n",
      "Eval_MaxReturn : 89.89090728759766\n",
      "Eval_MinReturn : 59.116615295410156\n",
      "Eval_AverageEpLen : 40.0\n",
      "Train_AverageReturn : 75.3615951538086\n",
      "Train_StdReturn : 9.17961311340332\n",
      "Train_MaxReturn : 110.62691497802734\n",
      "Train_MinReturn : 53.67910385131836\n",
      "Train_AverageEpLen : 42.73931623931624\n",
      "Train_EnvstepsSoFar : 440900\n",
      "TimeSinceStart : 254.02061223983765\n",
      "Training Loss : 123.01131439208984\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 44 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 71.73699951171875\n",
      "Eval_StdReturn : 9.520513534545898\n",
      "Eval_MaxReturn : 104.8128662109375\n",
      "Eval_MinReturn : 60.44719314575195\n",
      "Eval_AverageEpLen : 40.68\n",
      "Train_AverageReturn : 73.69567108154297\n",
      "Train_StdReturn : 9.445911407470703\n",
      "Train_MaxReturn : 116.34111785888672\n",
      "Train_MinReturn : 54.429718017578125\n",
      "Train_AverageEpLen : 41.85355648535565\n",
      "Train_EnvstepsSoFar : 450903\n",
      "TimeSinceStart : 259.6106026172638\n",
      "Training Loss : 122.40731811523438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 45 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 67.79823303222656\n",
      "Eval_StdReturn : 8.384961128234863\n",
      "Eval_MaxReturn : 91.43018341064453\n",
      "Eval_MinReturn : 55.782711029052734\n",
      "Eval_AverageEpLen : 38.2962962962963\n",
      "Train_AverageReturn : 71.62950897216797\n",
      "Train_StdReturn : 10.480759620666504\n",
      "Train_MaxReturn : 145.09344482421875\n",
      "Train_MinReturn : 52.48270797729492\n",
      "Train_AverageEpLen : 40.506072874493924\n",
      "Train_EnvstepsSoFar : 460908\n",
      "TimeSinceStart : 265.2425847053528\n",
      "Training Loss : 122.36502075195312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 46 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 61.8095703125\n",
      "Eval_StdReturn : 8.158197402954102\n",
      "Eval_MaxReturn : 76.00499725341797\n",
      "Eval_MinReturn : 50.252418518066406\n",
      "Eval_AverageEpLen : 35.206896551724135\n",
      "Train_AverageReturn : 67.3853530883789\n",
      "Train_StdReturn : 7.826179027557373\n",
      "Train_MaxReturn : 98.01831817626953\n",
      "Train_MinReturn : 48.65157699584961\n",
      "Train_AverageEpLen : 38.163498098859314\n",
      "Train_EnvstepsSoFar : 470945\n",
      "TimeSinceStart : 270.88016843795776\n",
      "Training Loss : 119.29082489013672\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 47 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 55.587921142578125\n",
      "Eval_StdReturn : 5.719722270965576\n",
      "Eval_MaxReturn : 72.22727966308594\n",
      "Eval_MinReturn : 46.9361457824707\n",
      "Eval_AverageEpLen : 31.8125\n",
      "Train_AverageReturn : 61.044132232666016\n",
      "Train_StdReturn : 8.084880828857422\n",
      "Train_MaxReturn : 97.00239562988281\n",
      "Train_MinReturn : 47.019168853759766\n",
      "Train_AverageEpLen : 34.69896193771626\n",
      "Train_EnvstepsSoFar : 480973\n",
      "TimeSinceStart : 276.53165650367737\n",
      "Training Loss : 115.10453033447266\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 48 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 53.3125114440918\n",
      "Eval_StdReturn : 6.21051549911499\n",
      "Eval_MaxReturn : 70.58741760253906\n",
      "Eval_MinReturn : 45.442691802978516\n",
      "Eval_AverageEpLen : 30.484848484848484\n",
      "Train_AverageReturn : 56.368831634521484\n",
      "Train_StdReturn : 6.305598735809326\n",
      "Train_MaxReturn : 76.53411865234375\n",
      "Train_MinReturn : 43.74440002441406\n",
      "Train_AverageEpLen : 32.19292604501608\n",
      "Train_EnvstepsSoFar : 490985\n",
      "TimeSinceStart : 282.261990070343\n",
      "Training Loss : 111.97802734375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 49 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10032 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 53.21153259277344\n",
      "Eval_StdReturn : 9.629861831665039\n",
      "Eval_MaxReturn : 100.08174133300781\n",
      "Eval_MinReturn : 41.25753402709961\n",
      "Eval_AverageEpLen : 30.515151515151516\n",
      "Train_AverageReturn : 54.054073333740234\n",
      "Train_StdReturn : 6.386849880218506\n",
      "Train_MaxReturn : 95.45586395263672\n",
      "Train_MinReturn : 43.70178985595703\n",
      "Train_AverageEpLen : 30.962962962962962\n",
      "Train_EnvstepsSoFar : 501017\n",
      "TimeSinceStart : 287.99704027175903\n",
      "Training Loss : 110.02493286132812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 49.97061538696289\n",
      "Eval_StdReturn : 2.963956594467163\n",
      "Eval_MaxReturn : 56.5118408203125\n",
      "Eval_MinReturn : 43.22933578491211\n",
      "Eval_AverageEpLen : 28.857142857142858\n",
      "Train_AverageReturn : 52.610572814941406\n",
      "Train_StdReturn : 6.099161148071289\n",
      "Train_MaxReturn : 106.3284683227539\n",
      "Train_MinReturn : 43.5849494934082\n",
      "Train_AverageEpLen : 30.211480362537763\n",
      "Train_EnvstepsSoFar : 511017\n",
      "TimeSinceStart : 293.67376375198364\n",
      "Training Loss : 108.96607208251953\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 54.19646072387695\n",
      "Eval_StdReturn : 11.411385536193848\n",
      "Eval_MaxReturn : 98.70435333251953\n",
      "Eval_MinReturn : 44.90985107421875\n",
      "Eval_AverageEpLen : 31.09090909090909\n",
      "Train_AverageReturn : 52.19527053833008\n",
      "Train_StdReturn : 4.45468807220459\n",
      "Train_MaxReturn : 70.45125579833984\n",
      "Train_MinReturn : 43.102020263671875\n",
      "Train_AverageEpLen : 29.976047904191617\n",
      "Train_EnvstepsSoFar : 521029\n",
      "TimeSinceStart : 299.41395115852356\n",
      "Training Loss : 107.99855041503906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 51.405906677246094\n",
      "Eval_StdReturn : 4.601266860961914\n",
      "Eval_MaxReturn : 66.08698272705078\n",
      "Eval_MinReturn : 42.734127044677734\n",
      "Eval_AverageEpLen : 29.676470588235293\n",
      "Train_AverageReturn : 51.96239471435547\n",
      "Train_StdReturn : 5.466764450073242\n",
      "Train_MaxReturn : 115.95435333251953\n",
      "Train_MinReturn : 41.332550048828125\n",
      "Train_AverageEpLen : 29.913432835820895\n",
      "Train_EnvstepsSoFar : 531050\n",
      "TimeSinceStart : 305.1708505153656\n",
      "Training Loss : 107.8436279296875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 50.77714920043945\n",
      "Eval_StdReturn : 4.005671977996826\n",
      "Eval_MaxReturn : 57.452606201171875\n",
      "Eval_MinReturn : 39.821533203125\n",
      "Eval_AverageEpLen : 29.257142857142856\n",
      "Train_AverageReturn : 51.154693603515625\n",
      "Train_StdReturn : 3.8457236289978027\n",
      "Train_MaxReturn : 66.73236083984375\n",
      "Train_MinReturn : 41.58332824707031\n",
      "Train_AverageEpLen : 29.470588235294116\n",
      "Train_EnvstepsSoFar : 541070\n",
      "TimeSinceStart : 310.9157598018646\n",
      "Training Loss : 106.97236633300781\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 50.402408599853516\n",
      "Eval_StdReturn : 4.539322376251221\n",
      "Eval_MaxReturn : 60.82216262817383\n",
      "Eval_MinReturn : 41.37204360961914\n",
      "Eval_AverageEpLen : 29.142857142857142\n",
      "Train_AverageReturn : 51.20201873779297\n",
      "Train_StdReturn : 4.3483076095581055\n",
      "Train_MaxReturn : 66.24002838134766\n",
      "Train_MinReturn : 39.71489334106445\n",
      "Train_AverageEpLen : 29.52212389380531\n",
      "Train_EnvstepsSoFar : 551078\n",
      "TimeSinceStart : 316.64735651016235\n",
      "Training Loss : 107.02297973632812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 48.84805679321289\n",
      "Eval_StdReturn : 5.399640083312988\n",
      "Eval_MaxReturn : 74.37708282470703\n",
      "Eval_MinReturn : 41.25990295410156\n",
      "Eval_AverageEpLen : 28.27777777777778\n",
      "Train_AverageReturn : 50.02616500854492\n",
      "Train_StdReturn : 3.63240385055542\n",
      "Train_MaxReturn : 61.28929138183594\n",
      "Train_MinReturn : 39.4351921081543\n",
      "Train_AverageEpLen : 28.904624277456648\n",
      "Train_EnvstepsSoFar : 561079\n",
      "TimeSinceStart : 322.4518840312958\n",
      "Training Loss : 106.32990264892578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 47.964378356933594\n",
      "Eval_StdReturn : 2.60370135307312\n",
      "Eval_MaxReturn : 53.354610443115234\n",
      "Eval_MinReturn : 39.46336364746094\n",
      "Eval_AverageEpLen : 27.833333333333332\n",
      "Train_AverageReturn : 48.935546875\n",
      "Train_StdReturn : 3.237873077392578\n",
      "Train_MaxReturn : 58.41196060180664\n",
      "Train_MinReturn : 39.586692810058594\n",
      "Train_AverageEpLen : 28.319209039548024\n",
      "Train_EnvstepsSoFar : 571104\n",
      "TimeSinceStart : 328.2450375556946\n",
      "Training Loss : 104.83820343017578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.00203323364258\n",
      "Eval_StdReturn : 2.7657053470611572\n",
      "Eval_MaxReturn : 51.6339111328125\n",
      "Eval_MinReturn : 39.438812255859375\n",
      "Eval_AverageEpLen : 26.710526315789473\n",
      "Train_AverageReturn : 47.46274948120117\n",
      "Train_StdReturn : 2.4437811374664307\n",
      "Train_MaxReturn : 53.468997955322266\n",
      "Train_MinReturn : 40.64686965942383\n",
      "Train_AverageEpLen : 27.535714285714285\n",
      "Train_EnvstepsSoFar : 581127\n",
      "TimeSinceStart : 334.1214828491211\n",
      "Training Loss : 103.4177017211914\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 45.16059112548828\n",
      "Eval_StdReturn : 2.492931604385376\n",
      "Eval_MaxReturn : 49.60676193237305\n",
      "Eval_MinReturn : 39.38056945800781\n",
      "Eval_AverageEpLen : 26.36842105263158\n",
      "Train_AverageReturn : 46.152610778808594\n",
      "Train_StdReturn : 2.5078237056732178\n",
      "Train_MaxReturn : 51.74354934692383\n",
      "Train_MinReturn : 39.07215881347656\n",
      "Train_AverageEpLen : 26.82573726541555\n",
      "Train_EnvstepsSoFar : 591133\n",
      "TimeSinceStart : 339.9571096897125\n",
      "Training Loss : 101.27052307128906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.890193939208984\n",
      "Eval_StdReturn : 1.9330509901046753\n",
      "Eval_MaxReturn : 49.8126335144043\n",
      "Eval_MinReturn : 40.667808532714844\n",
      "Eval_AverageEpLen : 26.23076923076923\n",
      "Train_AverageReturn : 45.21541976928711\n",
      "Train_StdReturn : 2.2023699283599854\n",
      "Train_MaxReturn : 51.357051849365234\n",
      "Train_MinReturn : 37.531898498535156\n",
      "Train_AverageEpLen : 26.35\n",
      "Train_EnvstepsSoFar : 601146\n",
      "TimeSinceStart : 345.85597038269043\n",
      "Training Loss : 100.3137435913086\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10014 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.748863220214844\n",
      "Eval_StdReturn : 1.8979408740997314\n",
      "Eval_MaxReturn : 47.97236251831055\n",
      "Eval_MinReturn : 39.304115295410156\n",
      "Eval_AverageEpLen : 26.23076923076923\n",
      "Train_AverageReturn : 44.51288986206055\n",
      "Train_StdReturn : 2.350550651550293\n",
      "Train_MaxReturn : 51.2603874206543\n",
      "Train_MinReturn : 38.689971923828125\n",
      "Train_AverageEpLen : 26.01038961038961\n",
      "Train_EnvstepsSoFar : 611160\n",
      "TimeSinceStart : 351.6661114692688\n",
      "Training Loss : 99.49681854248047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 43.86023712158203\n",
      "Eval_StdReturn : 1.9372273683547974\n",
      "Eval_MaxReturn : 47.70486831665039\n",
      "Eval_MinReturn : 40.62656021118164\n",
      "Eval_AverageEpLen : 25.71794871794872\n",
      "Train_AverageReturn : 44.26897048950195\n",
      "Train_StdReturn : 2.1626508235931396\n",
      "Train_MaxReturn : 49.92997741699219\n",
      "Train_MinReturn : 38.75839614868164\n",
      "Train_AverageEpLen : 25.935233160621763\n",
      "Train_EnvstepsSoFar : 621171\n",
      "TimeSinceStart : 357.4512059688568\n",
      "Training Loss : 99.41554260253906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 42.93560791015625\n",
      "Eval_StdReturn : 1.8517683744430542\n",
      "Eval_MaxReturn : 46.70540237426758\n",
      "Eval_MinReturn : 39.363712310791016\n",
      "Eval_AverageEpLen : 25.25\n",
      "Train_AverageReturn : 43.7311897277832\n",
      "Train_StdReturn : 2.1681277751922607\n",
      "Train_MaxReturn : 50.944026947021484\n",
      "Train_MinReturn : 37.4920654296875\n",
      "Train_AverageEpLen : 25.648717948717948\n",
      "Train_EnvstepsSoFar : 631174\n",
      "TimeSinceStart : 363.2499132156372\n",
      "Training Loss : 98.20954895019531\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 43.43523406982422\n",
      "Eval_StdReturn : 1.853318691253662\n",
      "Eval_MaxReturn : 46.267879486083984\n",
      "Eval_MinReturn : 37.610008239746094\n",
      "Eval_AverageEpLen : 25.5\n",
      "Train_AverageReturn : 42.99917984008789\n",
      "Train_StdReturn : 2.14198637008667\n",
      "Train_MaxReturn : 48.265045166015625\n",
      "Train_MinReturn : 37.128334045410156\n",
      "Train_AverageEpLen : 25.28030303030303\n",
      "Train_EnvstepsSoFar : 641185\n",
      "TimeSinceStart : 369.1523802280426\n",
      "Training Loss : 97.47988891601562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 42.92584991455078\n",
      "Eval_StdReturn : 1.9558089971542358\n",
      "Eval_MaxReturn : 47.29908752441406\n",
      "Eval_MinReturn : 38.9732666015625\n",
      "Eval_AverageEpLen : 25.35\n",
      "Train_AverageReturn : 42.813720703125\n",
      "Train_StdReturn : 1.9920352697372437\n",
      "Train_MaxReturn : 49.19207000732422\n",
      "Train_MinReturn : 37.24835968017578\n",
      "Train_AverageEpLen : 25.221662468513856\n",
      "Train_EnvstepsSoFar : 651198\n",
      "TimeSinceStart : 375.0227437019348\n",
      "Training Loss : 96.8116226196289\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 42.77173614501953\n",
      "Eval_StdReturn : 2.0893776416778564\n",
      "Eval_MaxReturn : 47.50112533569336\n",
      "Eval_MinReturn : 38.204280853271484\n",
      "Eval_AverageEpLen : 25.3\n",
      "Train_AverageReturn : 42.668949127197266\n",
      "Train_StdReturn : 2.044705867767334\n",
      "Train_MaxReturn : 48.0306510925293\n",
      "Train_MinReturn : 37.188995361328125\n",
      "Train_AverageEpLen : 25.198992443324936\n",
      "Train_EnvstepsSoFar : 661202\n",
      "TimeSinceStart : 380.84727668762207\n",
      "Training Loss : 96.71324157714844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 42.55237579345703\n",
      "Eval_StdReturn : 1.9471503496170044\n",
      "Eval_MaxReturn : 45.98905944824219\n",
      "Eval_MinReturn : 36.9967041015625\n",
      "Eval_AverageEpLen : 25.2\n",
      "Train_AverageReturn : 42.746158599853516\n",
      "Train_StdReturn : 2.1159956455230713\n",
      "Train_MaxReturn : 50.620365142822266\n",
      "Train_MinReturn : 36.826416015625\n",
      "Train_AverageEpLen : 25.282828282828284\n",
      "Train_EnvstepsSoFar : 671214\n",
      "TimeSinceStart : 386.5962836742401\n",
      "Training Loss : 96.54617309570312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 42.655540466308594\n",
      "Eval_StdReturn : 1.8102389574050903\n",
      "Eval_MaxReturn : 47.35515594482422\n",
      "Eval_MinReturn : 38.59736633300781\n",
      "Eval_AverageEpLen : 25.325\n",
      "Train_AverageReturn : 42.57044219970703\n",
      "Train_StdReturn : 1.9951926469802856\n",
      "Train_MaxReturn : 47.924522399902344\n",
      "Train_MinReturn : 36.993995666503906\n",
      "Train_AverageEpLen : 25.221662468513856\n",
      "Train_EnvstepsSoFar : 681227\n",
      "TimeSinceStart : 392.31439232826233\n",
      "Training Loss : 96.29742431640625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.859771728515625\n",
      "Eval_StdReturn : 1.8325953483581543\n",
      "Eval_MaxReturn : 46.01744842529297\n",
      "Eval_MinReturn : 37.08203125\n",
      "Eval_AverageEpLen : 24.951219512195124\n",
      "Train_AverageReturn : 42.242584228515625\n",
      "Train_StdReturn : 2.008226156234741\n",
      "Train_MaxReturn : 48.766170501708984\n",
      "Train_MinReturn : 36.75944900512695\n",
      "Train_AverageEpLen : 25.095238095238095\n",
      "Train_EnvstepsSoFar : 691240\n",
      "TimeSinceStart : 398.0679895877838\n",
      "Training Loss : 96.03131103515625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.7403678894043\n",
      "Eval_StdReturn : 1.886957049369812\n",
      "Eval_MaxReturn : 46.21797561645508\n",
      "Eval_MinReturn : 38.28551483154297\n",
      "Eval_AverageEpLen : 24.829268292682926\n",
      "Train_AverageReturn : 41.8502197265625\n",
      "Train_StdReturn : 1.9071776866912842\n",
      "Train_MaxReturn : 46.81119918823242\n",
      "Train_MinReturn : 37.97728729248047\n",
      "Train_AverageEpLen : 24.90547263681592\n",
      "Train_EnvstepsSoFar : 701252\n",
      "TimeSinceStart : 403.7796468734741\n",
      "Training Loss : 95.38449096679688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.891944885253906\n",
      "Eval_StdReturn : 1.9506009817123413\n",
      "Eval_MaxReturn : 45.89396286010742\n",
      "Eval_MinReturn : 38.06179428100586\n",
      "Eval_AverageEpLen : 25.025\n",
      "Train_AverageReturn : 41.77338409423828\n",
      "Train_StdReturn : 1.9425957202911377\n",
      "Train_MaxReturn : 47.78013610839844\n",
      "Train_MinReturn : 36.68955612182617\n",
      "Train_AverageEpLen : 24.927860696517413\n",
      "Train_EnvstepsSoFar : 711273\n",
      "TimeSinceStart : 409.5071060657501\n",
      "Training Loss : 94.76935577392578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.9109001159668\n",
      "Eval_StdReturn : 1.956728458404541\n",
      "Eval_MaxReturn : 45.28001022338867\n",
      "Eval_MinReturn : 38.451053619384766\n",
      "Eval_AverageEpLen : 25.05\n",
      "Train_AverageReturn : 41.968868255615234\n",
      "Train_StdReturn : 1.8700730800628662\n",
      "Train_MaxReturn : 49.09062194824219\n",
      "Train_MinReturn : 36.83789825439453\n",
      "Train_AverageEpLen : 25.06516290726817\n",
      "Train_EnvstepsSoFar : 721274\n",
      "TimeSinceStart : 415.27003741264343\n",
      "Training Loss : 94.698486328125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 43.14314651489258\n",
      "Eval_StdReturn : 2.022639274597168\n",
      "Eval_MaxReturn : 47.217430114746094\n",
      "Eval_MinReturn : 39.32024383544922\n",
      "Eval_AverageEpLen : 25.82051282051282\n",
      "Train_AverageReturn : 42.48030090332031\n",
      "Train_StdReturn : 1.9678990840911865\n",
      "Train_MaxReturn : 48.879730224609375\n",
      "Train_MinReturn : 36.42007064819336\n",
      "Train_AverageEpLen : 25.385786802030456\n",
      "Train_EnvstepsSoFar : 731276\n",
      "TimeSinceStart : 420.9636116027832\n",
      "Training Loss : 95.56986236572266\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.13431930541992\n",
      "Eval_StdReturn : 2.0999507904052734\n",
      "Eval_MaxReturn : 48.37789535522461\n",
      "Eval_MinReturn : 38.39113998413086\n",
      "Eval_AverageEpLen : 26.28205128205128\n",
      "Train_AverageReturn : 43.18937301635742\n",
      "Train_StdReturn : 2.2097885608673096\n",
      "Train_MaxReturn : 49.12785720825195\n",
      "Train_MinReturn : 37.96128845214844\n",
      "Train_AverageEpLen : 25.778350515463917\n",
      "Train_EnvstepsSoFar : 741278\n",
      "TimeSinceStart : 426.6621639728546\n",
      "Training Loss : 96.34703826904297\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 45.70225524902344\n",
      "Eval_StdReturn : 2.1443536281585693\n",
      "Eval_MaxReturn : 49.152530670166016\n",
      "Eval_MinReturn : 40.153404235839844\n",
      "Eval_AverageEpLen : 27.18918918918919\n",
      "Train_AverageReturn : 43.87681198120117\n",
      "Train_StdReturn : 2.3277599811553955\n",
      "Train_MaxReturn : 50.4764518737793\n",
      "Train_MinReturn : 38.1536750793457\n",
      "Train_AverageEpLen : 26.172323759791123\n",
      "Train_EnvstepsSoFar : 751302\n",
      "TimeSinceStart : 432.3452215194702\n",
      "Training Loss : 96.85957336425781\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.32907485961914\n",
      "Eval_StdReturn : 2.0396504402160645\n",
      "Eval_MaxReturn : 50.46018600463867\n",
      "Eval_MinReturn : 41.268035888671875\n",
      "Eval_AverageEpLen : 27.54054054054054\n",
      "Train_AverageReturn : 45.322322845458984\n",
      "Train_StdReturn : 2.459833860397339\n",
      "Train_MaxReturn : 50.850215911865234\n",
      "Train_MinReturn : 38.01808166503906\n",
      "Train_AverageEpLen : 26.973045822102424\n",
      "Train_EnvstepsSoFar : 761309\n",
      "TimeSinceStart : 438.0135214328766\n",
      "Training Loss : 98.62716674804688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 47.07167053222656\n",
      "Eval_StdReturn : 1.789257287979126\n",
      "Eval_MaxReturn : 50.979408264160156\n",
      "Eval_MinReturn : 43.4131965637207\n",
      "Eval_AverageEpLen : 27.944444444444443\n",
      "Train_AverageReturn : 46.556339263916016\n",
      "Train_StdReturn : 2.2682766914367676\n",
      "Train_MaxReturn : 52.33684158325195\n",
      "Train_MinReturn : 38.60965347290039\n",
      "Train_AverageEpLen : 27.68232044198895\n",
      "Train_EnvstepsSoFar : 771330\n",
      "TimeSinceStart : 443.6332733631134\n",
      "Training Loss : 99.17240142822266\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 45.60397720336914\n",
      "Eval_StdReturn : 1.875182032585144\n",
      "Eval_MaxReturn : 48.87440872192383\n",
      "Eval_MinReturn : 40.282005310058594\n",
      "Eval_AverageEpLen : 27.16216216216216\n",
      "Train_AverageReturn : 46.601314544677734\n",
      "Train_StdReturn : 2.3926141262054443\n",
      "Train_MaxReturn : 53.84248352050781\n",
      "Train_MinReturn : 38.66913986206055\n",
      "Train_AverageEpLen : 27.70360110803324\n",
      "Train_EnvstepsSoFar : 781331\n",
      "TimeSinceStart : 449.32619428634644\n",
      "Training Loss : 99.38898468017578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 45.114501953125\n",
      "Eval_StdReturn : 2.858377456665039\n",
      "Eval_MaxReturn : 50.58823013305664\n",
      "Eval_MinReturn : 38.27804946899414\n",
      "Eval_AverageEpLen : 26.86842105263158\n",
      "Train_AverageReturn : 45.949462890625\n",
      "Train_StdReturn : 2.3766250610351562\n",
      "Train_MaxReturn : 52.25553512573242\n",
      "Train_MinReturn : 38.5218391418457\n",
      "Train_AverageEpLen : 27.327868852459016\n",
      "Train_EnvstepsSoFar : 791333\n",
      "TimeSinceStart : 455.05650067329407\n",
      "Training Loss : 98.69746398925781\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 45.36920928955078\n",
      "Eval_StdReturn : 2.0317890644073486\n",
      "Eval_MaxReturn : 48.01837158203125\n",
      "Eval_MinReturn : 40.07112121582031\n",
      "Eval_AverageEpLen : 26.894736842105264\n",
      "Train_AverageReturn : 45.56291198730469\n",
      "Train_StdReturn : 2.2742490768432617\n",
      "Train_MaxReturn : 52.588966369628906\n",
      "Train_MinReturn : 39.75653076171875\n",
      "Train_AverageEpLen : 27.089189189189188\n",
      "Train_EnvstepsSoFar : 801356\n",
      "TimeSinceStart : 460.8045423030853\n",
      "Training Loss : 98.23127746582031\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.34122085571289\n",
      "Eval_StdReturn : 2.6801509857177734\n",
      "Eval_MaxReturn : 52.44696044921875\n",
      "Eval_MinReturn : 38.491912841796875\n",
      "Eval_AverageEpLen : 27.43243243243243\n",
      "Train_AverageReturn : 45.87959671020508\n",
      "Train_StdReturn : 2.2752482891082764\n",
      "Train_MaxReturn : 52.432308197021484\n",
      "Train_MinReturn : 38.73808288574219\n",
      "Train_AverageEpLen : 27.22554347826087\n",
      "Train_EnvstepsSoFar : 811375\n",
      "TimeSinceStart : 466.518435716629\n",
      "Training Loss : 99.00080871582031\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.30656433105469\n",
      "Eval_StdReturn : 2.687889814376831\n",
      "Eval_MaxReturn : 50.81558609008789\n",
      "Eval_MinReturn : 40.266929626464844\n",
      "Eval_AverageEpLen : 27.35135135135135\n",
      "Train_AverageReturn : 46.21592330932617\n",
      "Train_StdReturn : 2.3033993244171143\n",
      "Train_MaxReturn : 52.40155029296875\n",
      "Train_MinReturn : 38.462013244628906\n",
      "Train_AverageEpLen : 27.37431693989071\n",
      "Train_EnvstepsSoFar : 821394\n",
      "TimeSinceStart : 472.2151446342468\n",
      "Training Loss : 99.4978256225586\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10014 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 46.36452102661133\n",
      "Eval_StdReturn : 2.227628707885742\n",
      "Eval_MaxReturn : 50.99741744995117\n",
      "Eval_MinReturn : 40.44268798828125\n",
      "Eval_AverageEpLen : 27.43243243243243\n",
      "Train_AverageReturn : 46.11107635498047\n",
      "Train_StdReturn : 2.328861951828003\n",
      "Train_MaxReturn : 52.54477310180664\n",
      "Train_MinReturn : 36.78716278076172\n",
      "Train_AverageEpLen : 27.286103542234333\n",
      "Train_EnvstepsSoFar : 831408\n",
      "TimeSinceStart : 477.99110102653503\n",
      "Training Loss : 98.82821655273438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 45.566619873046875\n",
      "Eval_StdReturn : 2.0888144969940186\n",
      "Eval_MaxReturn : 51.063785552978516\n",
      "Eval_MinReturn : 40.49223327636719\n",
      "Eval_AverageEpLen : 26.973684210526315\n",
      "Train_AverageReturn : 46.015010833740234\n",
      "Train_StdReturn : 2.123418092727661\n",
      "Train_MaxReturn : 52.83091735839844\n",
      "Train_MinReturn : 40.07569885253906\n",
      "Train_AverageEpLen : 27.22826086956522\n",
      "Train_EnvstepsSoFar : 841428\n",
      "TimeSinceStart : 483.8025827407837\n",
      "Training Loss : 98.60610961914062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.72007369995117\n",
      "Eval_StdReturn : 2.2451534271240234\n",
      "Eval_MaxReturn : 50.567867279052734\n",
      "Eval_MinReturn : 40.26688003540039\n",
      "Eval_AverageEpLen : 26.57894736842105\n",
      "Train_AverageReturn : 45.6964111328125\n",
      "Train_StdReturn : 2.2200520038604736\n",
      "Train_MaxReturn : 52.09270095825195\n",
      "Train_MinReturn : 38.60556411743164\n",
      "Train_AverageEpLen : 27.06756756756757\n",
      "Train_EnvstepsSoFar : 851443\n",
      "TimeSinceStart : 489.5643994808197\n",
      "Training Loss : 98.3194580078125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10017 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.926979064941406\n",
      "Eval_StdReturn : 2.240201473236084\n",
      "Eval_MaxReturn : 49.145626068115234\n",
      "Eval_MinReturn : 41.410762786865234\n",
      "Eval_AverageEpLen : 26.710526315789473\n",
      "Train_AverageReturn : 45.403804779052734\n",
      "Train_StdReturn : 2.2003941535949707\n",
      "Train_MaxReturn : 52.234169006347656\n",
      "Train_MinReturn : 38.541587829589844\n",
      "Train_AverageEpLen : 26.927419354838708\n",
      "Train_EnvstepsSoFar : 861460\n",
      "TimeSinceStart : 495.29290413856506\n",
      "Training Loss : 98.12570190429688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 45.273887634277344\n",
      "Eval_StdReturn : 2.2069807052612305\n",
      "Eval_MaxReturn : 53.59939193725586\n",
      "Eval_MinReturn : 41.38759994506836\n",
      "Eval_AverageEpLen : 26.92105263157895\n",
      "Train_AverageReturn : 45.11194610595703\n",
      "Train_StdReturn : 2.0747811794281006\n",
      "Train_MaxReturn : 50.69783401489258\n",
      "Train_MinReturn : 38.768009185791016\n",
      "Train_AverageEpLen : 26.807486631016044\n",
      "Train_EnvstepsSoFar : 871486\n",
      "TimeSinceStart : 501.09353256225586\n",
      "Training Loss : 97.79022979736328\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.8356819152832\n",
      "Eval_StdReturn : 1.9620198011398315\n",
      "Eval_MaxReturn : 48.3204231262207\n",
      "Eval_MinReturn : 39.926048278808594\n",
      "Eval_AverageEpLen : 26.789473684210527\n",
      "Train_AverageReturn : 44.99781799316406\n",
      "Train_StdReturn : 2.2591633796691895\n",
      "Train_MaxReturn : 51.853233337402344\n",
      "Train_MinReturn : 38.48557662963867\n",
      "Train_AverageEpLen : 26.802139037433154\n",
      "Train_EnvstepsSoFar : 881510\n",
      "TimeSinceStart : 506.89900064468384\n",
      "Training Loss : 96.66824340820312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.22292709350586\n",
      "Eval_StdReturn : 2.3260908126831055\n",
      "Eval_MaxReturn : 48.76756286621094\n",
      "Eval_MinReturn : 38.10742950439453\n",
      "Eval_AverageEpLen : 26.473684210526315\n",
      "Train_AverageReturn : 45.16217803955078\n",
      "Train_StdReturn : 2.1066184043884277\n",
      "Train_MaxReturn : 50.429908752441406\n",
      "Train_MinReturn : 38.2800178527832\n",
      "Train_AverageEpLen : 26.962264150943398\n",
      "Train_EnvstepsSoFar : 891513\n",
      "TimeSinceStart : 512.57972240448\n",
      "Training Loss : 96.65750885009766\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.60206985473633\n",
      "Eval_StdReturn : 1.6211652755737305\n",
      "Eval_MaxReturn : 48.256656646728516\n",
      "Eval_MinReturn : 39.72266387939453\n",
      "Eval_AverageEpLen : 26.736842105263158\n",
      "Train_AverageReturn : 44.798866271972656\n",
      "Train_StdReturn : 2.020977735519409\n",
      "Train_MaxReturn : 52.524681091308594\n",
      "Train_MinReturn : 39.74278259277344\n",
      "Train_AverageEpLen : 26.80965147453083\n",
      "Train_EnvstepsSoFar : 901513\n",
      "TimeSinceStart : 518.3024597167969\n",
      "Training Loss : 96.430908203125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 43.73577880859375\n",
      "Eval_StdReturn : 2.4514169692993164\n",
      "Eval_MaxReturn : 48.96110153198242\n",
      "Eval_MinReturn : 39.27735137939453\n",
      "Eval_AverageEpLen : 26.256410256410255\n",
      "Train_AverageReturn : 44.48017883300781\n",
      "Train_StdReturn : 1.9480137825012207\n",
      "Train_MaxReturn : 51.95363235473633\n",
      "Train_MinReturn : 38.02623748779297\n",
      "Train_AverageEpLen : 26.669333333333334\n",
      "Train_EnvstepsSoFar : 911514\n",
      "TimeSinceStart : 524.0346448421478\n",
      "Training Loss : 96.14766693115234\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 44.50728225708008\n",
      "Eval_StdReturn : 1.8961217403411865\n",
      "Eval_MaxReturn : 48.07599639892578\n",
      "Eval_MinReturn : 40.069976806640625\n",
      "Eval_AverageEpLen : 26.789473684210527\n",
      "Train_AverageReturn : 44.30605697631836\n",
      "Train_StdReturn : 2.0406057834625244\n",
      "Train_MaxReturn : 49.97534942626953\n",
      "Train_MinReturn : 38.08191680908203\n",
      "Train_AverageEpLen : 26.617021276595743\n",
      "Train_EnvstepsSoFar : 921522\n",
      "TimeSinceStart : 529.7686548233032\n",
      "Training Loss : 95.29296112060547\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 43.55162048339844\n",
      "Eval_StdReturn : 1.8941346406936646\n",
      "Eval_MaxReturn : 47.93042755126953\n",
      "Eval_MinReturn : 37.94410705566406\n",
      "Eval_AverageEpLen : 26.28205128205128\n",
      "Train_AverageReturn : 43.87957763671875\n",
      "Train_StdReturn : 2.069045066833496\n",
      "Train_MaxReturn : 48.9484748840332\n",
      "Train_MinReturn : 37.953086853027344\n",
      "Train_AverageEpLen : 26.424802110817943\n",
      "Train_EnvstepsSoFar : 931537\n",
      "TimeSinceStart : 535.4888527393341\n",
      "Training Loss : 95.03589630126953\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 43.06088638305664\n",
      "Eval_StdReturn : 1.866147518157959\n",
      "Eval_MaxReturn : 46.328834533691406\n",
      "Eval_MinReturn : 39.084381103515625\n",
      "Eval_AverageEpLen : 26.076923076923077\n",
      "Train_AverageReturn : 43.757896423339844\n",
      "Train_StdReturn : 1.9552184343338013\n",
      "Train_MaxReturn : 49.71504592895508\n",
      "Train_MinReturn : 38.16200637817383\n",
      "Train_AverageEpLen : 26.41952506596306\n",
      "Train_EnvstepsSoFar : 941550\n",
      "TimeSinceStart : 541.1594634056091\n",
      "Training Loss : 94.34668731689453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.76140594482422\n",
      "Eval_StdReturn : 2.020556688308716\n",
      "Eval_MaxReturn : 46.3292236328125\n",
      "Eval_MinReturn : 37.471229553222656\n",
      "Eval_AverageEpLen : 25.375\n",
      "Train_AverageReturn : 42.88037872314453\n",
      "Train_StdReturn : 1.9545066356658936\n",
      "Train_MaxReturn : 50.160884857177734\n",
      "Train_MinReturn : 36.466434478759766\n",
      "Train_AverageEpLen : 25.98701298701299\n",
      "Train_EnvstepsSoFar : 951555\n",
      "TimeSinceStart : 546.9610197544098\n",
      "Training Loss : 93.9914321899414\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.42906951904297\n",
      "Eval_StdReturn : 1.4666554927825928\n",
      "Eval_MaxReturn : 44.47542190551758\n",
      "Eval_MinReturn : 38.71573257446289\n",
      "Eval_AverageEpLen : 25.325\n",
      "Train_AverageReturn : 41.93603515625\n",
      "Train_StdReturn : 2.039677619934082\n",
      "Train_MaxReturn : 48.09803009033203\n",
      "Train_MinReturn : 36.241615295410156\n",
      "Train_AverageEpLen : 25.551020408163264\n",
      "Train_EnvstepsSoFar : 961571\n",
      "TimeSinceStart : 552.748049736023\n",
      "Training Loss : 91.96746063232422\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 40.709312438964844\n",
      "Eval_StdReturn : 1.7689546346664429\n",
      "Eval_MaxReturn : 44.75067901611328\n",
      "Eval_MinReturn : 37.5013542175293\n",
      "Eval_AverageEpLen : 25.025\n",
      "Train_AverageReturn : 41.273136138916016\n",
      "Train_StdReturn : 1.818524956703186\n",
      "Train_MaxReturn : 46.614356994628906\n",
      "Train_MinReturn : 37.19892501831055\n",
      "Train_AverageEpLen : 25.251889168765743\n",
      "Train_EnvstepsSoFar : 971596\n",
      "TimeSinceStart : 558.5044341087341\n",
      "Training Loss : 91.39574432373047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.39547348022461\n",
      "Eval_StdReturn : 1.6098296642303467\n",
      "Eval_MaxReturn : 44.87355041503906\n",
      "Eval_MinReturn : 38.27706527709961\n",
      "Eval_AverageEpLen : 25.45\n",
      "Train_AverageReturn : 41.15616226196289\n",
      "Train_StdReturn : 1.7224969863891602\n",
      "Train_MaxReturn : 46.166015625\n",
      "Train_MinReturn : 36.1923828125\n",
      "Train_AverageEpLen : 25.282828282828284\n",
      "Train_EnvstepsSoFar : 981608\n",
      "TimeSinceStart : 564.3001255989075\n",
      "Training Loss : 91.08844757080078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 41.656864166259766\n",
      "Eval_StdReturn : 2.1696674823760986\n",
      "Eval_MaxReturn : 47.518516540527344\n",
      "Eval_MinReturn : 37.09865188598633\n",
      "Eval_AverageEpLen : 25.76923076923077\n",
      "Train_AverageReturn : 41.23927688598633\n",
      "Train_StdReturn : 1.8398219347000122\n",
      "Train_MaxReturn : 46.059486389160156\n",
      "Train_MinReturn : 35.616844177246094\n",
      "Train_AverageEpLen : 25.418781725888326\n",
      "Train_EnvstepsSoFar : 991623\n",
      "TimeSinceStart : 570.056384563446\n",
      "Training Loss : 90.56840515136719\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 42.771846771240234\n",
      "Eval_StdReturn : 2.756645441055298\n",
      "Eval_MaxReturn : 47.33414077758789\n",
      "Eval_MinReturn : 36.88722229003906\n",
      "Eval_AverageEpLen : 26.473684210526315\n",
      "Train_AverageReturn : 41.76591873168945\n",
      "Train_StdReturn : 1.975016713142395\n",
      "Train_MaxReturn : 48.68483352661133\n",
      "Train_MinReturn : 35.17029571533203\n",
      "Train_AverageEpLen : 25.822164948453608\n",
      "Train_EnvstepsSoFar : 1001642\n",
      "TimeSinceStart : 575.7439687252045\n",
      "Training Loss : 90.90025329589844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'Hopper'\n",
    "pg_args['env_name'] = '{}-v2'.format(env_str)\n",
    "pg_args['learning_rate'] = 0.01\n",
    "pg_args['reward_to_go'] = True\n",
    "pg_args['batch_size'] = 10000\n",
    "pg_args['train_batch_size'] = 10000\n",
    "pg_args['n_iter'] = 100\n",
    "\n",
    "# Delete all previous logs\n",
    "remove_folder('logs/policy_gradient/{}/return_to_go/'.format(env_str))\n",
    "\n",
    "for seed in range(3):\n",
    "    print(\"Running policy gradient experiment with seed\", seed)\n",
    "    pg_args['seed'] = seed\n",
    "    pg_args['logdir'] = 'logs/policy_gradient/{}/return_to_go/seed{}'.format(env_str, seed)\n",
    "    pgtrainer = PG_Trainer(pg_args)\n",
    "    pgtrainer.run_training_loop()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Clearing old results at logs/policy_gradient/Hopper/return_to_go/\n",
      "Running policy gradient experiment with seed 0\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/return_to_go/seed0\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Collecting train rollouts to be used for saving videos...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "At timestep:     1023 / 1000\n",
      "Collecting video rollouts eval\n",
      "\n",
      "Saving train rollouts as videos...\n",
      "Eval_AverageReturn : 98.25846862792969\n",
      "Eval_StdReturn : 60.002906799316406\n",
      "Eval_MaxReturn : 223.3446044921875\n",
      "Eval_MinReturn : 9.597315788269043\n",
      "Eval_AverageEpLen : 60.1764705882353\n",
      "Train_AverageReturn : 9.657980918884277\n",
      "Train_StdReturn : 5.853752613067627\n",
      "Train_MaxReturn : 87.45542907714844\n",
      "Train_MinReturn : 3.010934352874756\n",
      "Train_AverageEpLen : 13.215323645970939\n",
      "Train_EnvstepsSoFar : 10004\n",
      "TimeSinceStart : 14.388614416122437\n",
      "Training Loss : 18.090417861938477\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 77.28364562988281\n",
      "Eval_StdReturn : 35.344791412353516\n",
      "Eval_MaxReturn : 223.3142547607422\n",
      "Eval_MinReturn : 51.73746871948242\n",
      "Eval_AverageEpLen : 48.76190476190476\n",
      "Train_AverageReturn : 94.4906997680664\n",
      "Train_StdReturn : 55.68022918701172\n",
      "Train_MaxReturn : 263.97686767578125\n",
      "Train_MinReturn : 10.588821411132812\n",
      "Train_AverageEpLen : 58.567251461988306\n",
      "Train_EnvstepsSoFar : 20019\n",
      "TimeSinceStart : 21.79885768890381\n",
      "Training Loss : 106.51622772216797\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 101.08629608154297\n",
      "Eval_StdReturn : 41.75547409057617\n",
      "Eval_MaxReturn : 206.1228790283203\n",
      "Eval_MinReturn : 60.409523010253906\n",
      "Eval_AverageEpLen : 55.1578947368421\n",
      "Train_AverageReturn : 79.7961654663086\n",
      "Train_StdReturn : 27.53388786315918\n",
      "Train_MaxReturn : 207.76516723632812\n",
      "Train_MinReturn : 41.94245529174805\n",
      "Train_AverageEpLen : 47.91866028708134\n",
      "Train_EnvstepsSoFar : 30034\n",
      "TimeSinceStart : 27.73679780960083\n",
      "Training Loss : 100.02169036865234\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 142.38693237304688\n",
      "Eval_StdReturn : 38.55751419067383\n",
      "Eval_MaxReturn : 217.34298706054688\n",
      "Eval_MinReturn : 93.75106811523438\n",
      "Eval_AverageEpLen : 72.57142857142857\n",
      "Train_AverageReturn : 117.55840301513672\n",
      "Train_StdReturn : 56.66990661621094\n",
      "Train_MaxReturn : 232.78514099121094\n",
      "Train_MinReturn : 55.161224365234375\n",
      "Train_AverageEpLen : 61.94444444444444\n",
      "Train_EnvstepsSoFar : 40069\n",
      "TimeSinceStart : 34.005531311035156\n",
      "Training Loss : 127.46867370605469\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10052 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 158.81117248535156\n",
      "Eval_StdReturn : 38.31800079345703\n",
      "Eval_MaxReturn : 215.52297973632812\n",
      "Eval_MinReturn : 99.6468276977539\n",
      "Eval_AverageEpLen : 80.23076923076923\n",
      "Train_AverageReturn : 144.49362182617188\n",
      "Train_StdReturn : 39.345462799072266\n",
      "Train_MaxReturn : 238.47340393066406\n",
      "Train_MinReturn : 32.05133819580078\n",
      "Train_AverageEpLen : 73.91176470588235\n",
      "Train_EnvstepsSoFar : 50121\n",
      "TimeSinceStart : 39.976969957351685\n",
      "Training Loss : 136.22152709960938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10087 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 208.30996704101562\n",
      "Eval_StdReturn : 4.943470478057861\n",
      "Eval_MaxReturn : 221.73634338378906\n",
      "Eval_MinReturn : 203.21595764160156\n",
      "Eval_AverageEpLen : 94.36363636363636\n",
      "Train_AverageReturn : 165.09799194335938\n",
      "Train_StdReturn : 31.191497802734375\n",
      "Train_MaxReturn : 240.03204345703125\n",
      "Train_MinReturn : 61.844383239746094\n",
      "Train_AverageEpLen : 80.05555555555556\n",
      "Train_EnvstepsSoFar : 60208\n",
      "TimeSinceStart : 45.86276078224182\n",
      "Training Loss : 147.15663146972656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10083 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 199.1322021484375\n",
      "Eval_StdReturn : 27.48796844482422\n",
      "Eval_MaxReturn : 215.7488555908203\n",
      "Eval_MinReturn : 114.959716796875\n",
      "Eval_AverageEpLen : 88.75\n",
      "Train_AverageReturn : 207.55337524414062\n",
      "Train_StdReturn : 8.191028594970703\n",
      "Train_MaxReturn : 219.28250122070312\n",
      "Train_MinReturn : 151.62734985351562\n",
      "Train_AverageEpLen : 92.5045871559633\n",
      "Train_EnvstepsSoFar : 70291\n",
      "TimeSinceStart : 51.63752222061157\n",
      "Training Loss : 165.310302734375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10034 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 158.4246063232422\n",
      "Eval_StdReturn : 45.812538146972656\n",
      "Eval_MaxReturn : 216.2965850830078\n",
      "Eval_MinReturn : 86.15617370605469\n",
      "Eval_AverageEpLen : 74.78571428571429\n",
      "Train_AverageReturn : 184.2089385986328\n",
      "Train_StdReturn : 44.207923889160156\n",
      "Train_MaxReturn : 218.4606170654297\n",
      "Train_MinReturn : 65.49732971191406\n",
      "Train_AverageEpLen : 83.61666666666666\n",
      "Train_EnvstepsSoFar : 80325\n",
      "TimeSinceStart : 57.33916425704956\n",
      "Training Loss : 158.8643341064453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10059 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 207.832763671875\n",
      "Eval_StdReturn : 4.401607990264893\n",
      "Eval_MaxReturn : 216.18560791015625\n",
      "Eval_MinReturn : 199.33816528320312\n",
      "Eval_AverageEpLen : 92.0\n",
      "Train_AverageReturn : 176.96519470214844\n",
      "Train_StdReturn : 43.377323150634766\n",
      "Train_MaxReturn : 216.259521484375\n",
      "Train_MinReturn : 56.83982467651367\n",
      "Train_AverageEpLen : 81.12096774193549\n",
      "Train_EnvstepsSoFar : 90384\n",
      "TimeSinceStart : 63.09507656097412\n",
      "Training Loss : 156.48536682128906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 202.8172607421875\n",
      "Eval_StdReturn : 6.055408954620361\n",
      "Eval_MaxReturn : 211.10494995117188\n",
      "Eval_MinReturn : 190.53392028808594\n",
      "Eval_AverageEpLen : 90.41666666666667\n",
      "Train_AverageReturn : 205.91307067871094\n",
      "Train_StdReturn : 9.139778137207031\n",
      "Train_MaxReturn : 215.81405639648438\n",
      "Train_MinReturn : 139.2078094482422\n",
      "Train_AverageEpLen : 91.05454545454545\n",
      "Train_EnvstepsSoFar : 100400\n",
      "TimeSinceStart : 68.96322894096375\n",
      "Training Loss : 165.23695373535156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 205.7596893310547\n",
      "Eval_StdReturn : 3.0419652462005615\n",
      "Eval_MaxReturn : 209.52667236328125\n",
      "Eval_MinReturn : 197.21380615234375\n",
      "Eval_AverageEpLen : 90.91666666666667\n",
      "Train_AverageReturn : 204.59811401367188\n",
      "Train_StdReturn : 5.575235366821289\n",
      "Train_MaxReturn : 214.04925537109375\n",
      "Train_MinReturn : 183.757080078125\n",
      "Train_AverageEpLen : 90.84684684684684\n",
      "Train_EnvstepsSoFar : 110484\n",
      "TimeSinceStart : 74.96345019340515\n",
      "Training Loss : 164.33840942382812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10082 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.43324279785156\n",
      "Eval_StdReturn : 31.928447723388672\n",
      "Eval_MaxReturn : 211.0248565673828\n",
      "Eval_MinReturn : 112.16218566894531\n",
      "Eval_AverageEpLen : 83.0\n",
      "Train_AverageReturn : 200.61331176757812\n",
      "Train_StdReturn : 13.211255073547363\n",
      "Train_MaxReturn : 216.50103759765625\n",
      "Train_MinReturn : 96.2942886352539\n",
      "Train_AverageEpLen : 89.22123893805309\n",
      "Train_EnvstepsSoFar : 120566\n",
      "TimeSinceStart : 81.17529535293579\n",
      "Training Loss : 163.54808044433594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 190.26055908203125\n",
      "Eval_StdReturn : 14.763318061828613\n",
      "Eval_MaxReturn : 205.03280639648438\n",
      "Eval_MinReturn : 161.6988983154297\n",
      "Eval_AverageEpLen : 85.66666666666667\n",
      "Train_AverageReturn : 185.79896545410156\n",
      "Train_StdReturn : 24.004501342773438\n",
      "Train_MaxReturn : 216.09356689453125\n",
      "Train_MinReturn : 87.7455825805664\n",
      "Train_AverageEpLen : 84.22689075630252\n",
      "Train_EnvstepsSoFar : 130589\n",
      "TimeSinceStart : 87.13786125183105\n",
      "Training Loss : 157.3535919189453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 190.9957275390625\n",
      "Eval_StdReturn : 3.8565938472747803\n",
      "Eval_MaxReturn : 196.72962951660156\n",
      "Eval_MinReturn : 183.04457092285156\n",
      "Eval_AverageEpLen : 86.41666666666667\n",
      "Train_AverageReturn : 179.638671875\n",
      "Train_StdReturn : 24.764387130737305\n",
      "Train_MaxReturn : 210.95724487304688\n",
      "Train_MinReturn : 91.69186401367188\n",
      "Train_AverageEpLen : 82.1311475409836\n",
      "Train_EnvstepsSoFar : 140609\n",
      "TimeSinceStart : 93.20685243606567\n",
      "Training Loss : 155.78675842285156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10048 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 185.66087341308594\n",
      "Eval_StdReturn : 4.314590930938721\n",
      "Eval_MaxReturn : 193.5205841064453\n",
      "Eval_MinReturn : 176.02084350585938\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 187.28460693359375\n",
      "Train_StdReturn : 14.577991485595703\n",
      "Train_MaxReturn : 204.7440948486328\n",
      "Train_MinReturn : 97.89830780029297\n",
      "Train_AverageEpLen : 85.15254237288136\n",
      "Train_EnvstepsSoFar : 150657\n",
      "TimeSinceStart : 99.50346088409424\n",
      "Training Loss : 156.9077911376953\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10074 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 176.889892578125\n",
      "Eval_StdReturn : 5.148016452789307\n",
      "Eval_MaxReturn : 187.04165649414062\n",
      "Eval_MinReturn : 170.2552032470703\n",
      "Eval_AverageEpLen : 83.66666666666667\n",
      "Train_AverageReturn : 183.93898010253906\n",
      "Train_StdReturn : 5.623469829559326\n",
      "Train_MaxReturn : 197.05934143066406\n",
      "Train_MinReturn : 171.9888458251953\n",
      "Train_AverageEpLen : 84.65546218487395\n",
      "Train_EnvstepsSoFar : 160731\n",
      "TimeSinceStart : 105.54974722862244\n",
      "Training Loss : 155.71092224121094\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 152.04727172851562\n",
      "Eval_StdReturn : 18.432626724243164\n",
      "Eval_MaxReturn : 173.2176513671875\n",
      "Eval_MinReturn : 125.76414489746094\n",
      "Eval_AverageEpLen : 76.64285714285714\n",
      "Train_AverageReturn : 177.0529022216797\n",
      "Train_StdReturn : 4.811324119567871\n",
      "Train_MaxReturn : 189.96304321289062\n",
      "Train_MinReturn : 167.72032165527344\n",
      "Train_AverageEpLen : 83.48333333333333\n",
      "Train_EnvstepsSoFar : 170749\n",
      "TimeSinceStart : 111.59237265586853\n",
      "Training Loss : 150.28167724609375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10030 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 119.5140151977539\n",
      "Eval_StdReturn : 18.316064834594727\n",
      "Eval_MaxReturn : 153.35873413085938\n",
      "Eval_MinReturn : 89.02667999267578\n",
      "Eval_AverageEpLen : 66.8\n",
      "Train_AverageReturn : 148.8184051513672\n",
      "Train_StdReturn : 19.636873245239258\n",
      "Train_MaxReturn : 181.6559600830078\n",
      "Train_MinReturn : 107.73640441894531\n",
      "Train_AverageEpLen : 75.98484848484848\n",
      "Train_EnvstepsSoFar : 180779\n",
      "TimeSinceStart : 117.63608598709106\n",
      "Training Loss : 134.12562561035156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 130.31524658203125\n",
      "Eval_StdReturn : 20.664020538330078\n",
      "Eval_MaxReturn : 170.37374877929688\n",
      "Eval_MinReturn : 98.72428131103516\n",
      "Eval_AverageEpLen : 71.2\n",
      "Train_AverageReturn : 123.72379302978516\n",
      "Train_StdReturn : 18.871732711791992\n",
      "Train_MaxReturn : 166.93894958496094\n",
      "Train_MinReturn : 84.77934265136719\n",
      "Train_AverageEpLen : 67.64864864864865\n",
      "Train_EnvstepsSoFar : 190791\n",
      "TimeSinceStart : 123.66640830039978\n",
      "Training Loss : 118.92098236083984\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 155.60687255859375\n",
      "Eval_StdReturn : 18.075998306274414\n",
      "Eval_MaxReturn : 168.4400634765625\n",
      "Eval_MinReturn : 101.97977447509766\n",
      "Eval_AverageEpLen : 81.15384615384616\n",
      "Train_AverageReturn : 131.77459716796875\n",
      "Train_StdReturn : 22.267009735107422\n",
      "Train_MaxReturn : 169.4942626953125\n",
      "Train_MinReturn : 84.82406616210938\n",
      "Train_AverageEpLen : 71.23404255319149\n",
      "Train_EnvstepsSoFar : 200835\n",
      "TimeSinceStart : 129.7358422279358\n",
      "Training Loss : 121.72393798828125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.92919921875\n",
      "Eval_StdReturn : 2.609687566757202\n",
      "Eval_MaxReturn : 172.33380126953125\n",
      "Eval_MinReturn : 162.56114196777344\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 164.03085327148438\n",
      "Train_StdReturn : 8.752326011657715\n",
      "Train_MaxReturn : 175.47006225585938\n",
      "Train_MinReturn : 114.80516052246094\n",
      "Train_AverageEpLen : 83.68333333333334\n",
      "Train_EnvstepsSoFar : 210877\n",
      "TimeSinceStart : 136.21403884887695\n",
      "Training Loss : 136.47080993652344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10038 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.6727752685547\n",
      "Eval_StdReturn : 2.447648525238037\n",
      "Eval_MaxReturn : 174.42547607421875\n",
      "Eval_MinReturn : 165.57147216796875\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 167.1394500732422\n",
      "Train_StdReturn : 3.530717611312866\n",
      "Train_MaxReturn : 175.11181640625\n",
      "Train_MinReturn : 146.4388427734375\n",
      "Train_AverageEpLen : 85.0677966101695\n",
      "Train_EnvstepsSoFar : 220915\n",
      "TimeSinceStart : 141.96065139770508\n",
      "Training Loss : 138.0065460205078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10033 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.35693359375\n",
      "Eval_StdReturn : 2.5758326053619385\n",
      "Eval_MaxReturn : 174.82022094726562\n",
      "Eval_MinReturn : 165.91510009765625\n",
      "Eval_AverageEpLen : 86.08333333333333\n",
      "Train_AverageReturn : 168.86154174804688\n",
      "Train_StdReturn : 3.2470054626464844\n",
      "Train_MaxReturn : 178.35707092285156\n",
      "Train_MinReturn : 158.8939971923828\n",
      "Train_AverageEpLen : 85.75213675213675\n",
      "Train_EnvstepsSoFar : 230948\n",
      "TimeSinceStart : 147.6277289390564\n",
      "Training Loss : 138.48916625976562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10033 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.50213623046875\n",
      "Eval_StdReturn : 4.034015655517578\n",
      "Eval_MaxReturn : 177.76251220703125\n",
      "Eval_MinReturn : 161.49240112304688\n",
      "Eval_AverageEpLen : 85.58333333333333\n",
      "Train_AverageReturn : 170.8634796142578\n",
      "Train_StdReturn : 3.2450814247131348\n",
      "Train_MaxReturn : 179.0553741455078\n",
      "Train_MinReturn : 160.36505126953125\n",
      "Train_AverageEpLen : 85.75213675213675\n",
      "Train_EnvstepsSoFar : 240981\n",
      "TimeSinceStart : 153.76605463027954\n",
      "Training Loss : 139.90261840820312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 24 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10078 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.2481689453125\n",
      "Eval_StdReturn : 3.855489492416382\n",
      "Eval_MaxReturn : 180.24989318847656\n",
      "Eval_MinReturn : 163.02110290527344\n",
      "Eval_AverageEpLen : 86.25\n",
      "Train_AverageReturn : 172.72683715820312\n",
      "Train_StdReturn : 3.6638870239257812\n",
      "Train_MaxReturn : 185.71522521972656\n",
      "Train_MinReturn : 160.80267333984375\n",
      "Train_AverageEpLen : 86.13675213675214\n",
      "Train_EnvstepsSoFar : 251059\n",
      "TimeSinceStart : 159.97846055030823\n",
      "Training Loss : 141.88697814941406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 25 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 175.5128936767578\n",
      "Eval_StdReturn : 3.572530508041382\n",
      "Eval_MaxReturn : 183.517578125\n",
      "Eval_MinReturn : 169.48995971679688\n",
      "Eval_AverageEpLen : 87.5\n",
      "Train_AverageReturn : 174.10447692871094\n",
      "Train_StdReturn : 4.006383895874023\n",
      "Train_MaxReturn : 183.45498657226562\n",
      "Train_MinReturn : 154.09133911132812\n",
      "Train_AverageEpLen : 86.31896551724138\n",
      "Train_EnvstepsSoFar : 261072\n",
      "TimeSinceStart : 165.8307375907898\n",
      "Training Loss : 143.3631134033203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 26 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.700439453125\n",
      "Eval_StdReturn : 2.005155563354492\n",
      "Eval_MaxReturn : 177.01930236816406\n",
      "Eval_MinReturn : 170.72190856933594\n",
      "Eval_AverageEpLen : 86.58333333333333\n",
      "Train_AverageReturn : 173.5120086669922\n",
      "Train_StdReturn : 6.339649200439453\n",
      "Train_MaxReturn : 186.49485778808594\n",
      "Train_MinReturn : 132.59432983398438\n",
      "Train_AverageEpLen : 86.41379310344827\n",
      "Train_EnvstepsSoFar : 271096\n",
      "TimeSinceStart : 171.6472556591034\n",
      "Training Loss : 141.74180603027344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 27 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10055 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.7500457763672\n",
      "Eval_StdReturn : 15.892662048339844\n",
      "Eval_MaxReturn : 188.0709686279297\n",
      "Eval_MinReturn : 125.42668151855469\n",
      "Eval_AverageEpLen : 85.83333333333333\n",
      "Train_AverageReturn : 173.50059509277344\n",
      "Train_StdReturn : 8.405739784240723\n",
      "Train_MaxReturn : 186.99176025390625\n",
      "Train_MinReturn : 132.6211395263672\n",
      "Train_AverageEpLen : 86.68103448275862\n",
      "Train_EnvstepsSoFar : 281151\n",
      "TimeSinceStart : 177.66563773155212\n",
      "Training Loss : 141.36410522460938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 28 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10071 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.0968780517578\n",
      "Eval_StdReturn : 7.90241003036499\n",
      "Eval_MaxReturn : 187.13890075683594\n",
      "Eval_MinReturn : 153.6525115966797\n",
      "Eval_AverageEpLen : 86.0\n",
      "Train_AverageReturn : 171.3148956298828\n",
      "Train_StdReturn : 11.916097640991211\n",
      "Train_MaxReturn : 199.822998046875\n",
      "Train_MinReturn : 126.57292938232422\n",
      "Train_AverageEpLen : 85.34745762711864\n",
      "Train_EnvstepsSoFar : 291222\n",
      "TimeSinceStart : 183.5093035697937\n",
      "Training Loss : 142.27264404296875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 29 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10027 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 155.29507446289062\n",
      "Eval_StdReturn : 15.249208450317383\n",
      "Eval_MaxReturn : 181.70521545410156\n",
      "Eval_MinReturn : 132.6390380859375\n",
      "Eval_AverageEpLen : 79.61538461538461\n",
      "Train_AverageReturn : 168.4001922607422\n",
      "Train_StdReturn : 16.11884117126465\n",
      "Train_MaxReturn : 212.27529907226562\n",
      "Train_MinReturn : 115.86876678466797\n",
      "Train_AverageEpLen : 84.26050420168067\n",
      "Train_EnvstepsSoFar : 301249\n",
      "TimeSinceStart : 189.2615761756897\n",
      "Training Loss : 141.67190551757812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 30 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 156.64036560058594\n",
      "Eval_StdReturn : 22.060850143432617\n",
      "Eval_MaxReturn : 199.02647399902344\n",
      "Eval_MinReturn : 123.79335021972656\n",
      "Eval_AverageEpLen : 79.76923076923077\n",
      "Train_AverageReturn : 160.77777099609375\n",
      "Train_StdReturn : 22.986621856689453\n",
      "Train_MaxReturn : 201.532958984375\n",
      "Train_MinReturn : 98.49745178222656\n",
      "Train_AverageEpLen : 81.34959349593495\n",
      "Train_EnvstepsSoFar : 311255\n",
      "TimeSinceStart : 194.96451592445374\n",
      "Training Loss : 138.33470153808594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 31 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10085 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.84361267089844\n",
      "Eval_StdReturn : 19.02275848388672\n",
      "Eval_MaxReturn : 198.32334899902344\n",
      "Eval_MinReturn : 135.76019287109375\n",
      "Eval_AverageEpLen : 84.0\n",
      "Train_AverageReturn : 156.2047882080078\n",
      "Train_StdReturn : 22.30866813659668\n",
      "Train_MaxReturn : 215.00677490234375\n",
      "Train_MinReturn : 109.1204833984375\n",
      "Train_AverageEpLen : 79.40944881889764\n",
      "Train_EnvstepsSoFar : 321340\n",
      "TimeSinceStart : 200.79619002342224\n",
      "Training Loss : 137.06607055664062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 32 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 147.6422119140625\n",
      "Eval_StdReturn : 22.041839599609375\n",
      "Eval_MaxReturn : 186.49012756347656\n",
      "Eval_MinReturn : 114.50638580322266\n",
      "Eval_AverageEpLen : 75.57142857142857\n",
      "Train_AverageReturn : 150.56845092773438\n",
      "Train_StdReturn : 21.028141021728516\n",
      "Train_MaxReturn : 216.04592895507812\n",
      "Train_MinReturn : 106.38468170166016\n",
      "Train_AverageEpLen : 77.2\n",
      "Train_EnvstepsSoFar : 331376\n",
      "TimeSinceStart : 206.83098793029785\n",
      "Training Loss : 135.2924041748047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 33 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10038 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 150.74227905273438\n",
      "Eval_StdReturn : 22.553918838500977\n",
      "Eval_MaxReturn : 211.31842041015625\n",
      "Eval_MinReturn : 116.99917602539062\n",
      "Eval_AverageEpLen : 78.38461538461539\n",
      "Train_AverageReturn : 145.3890838623047\n",
      "Train_StdReturn : 21.599912643432617\n",
      "Train_MaxReturn : 200.02552795410156\n",
      "Train_MinReturn : 95.81444549560547\n",
      "Train_AverageEpLen : 74.91044776119404\n",
      "Train_EnvstepsSoFar : 341414\n",
      "TimeSinceStart : 212.5165660381317\n",
      "Training Loss : 133.35093688964844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 34 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 138.2049102783203\n",
      "Eval_StdReturn : 12.568842887878418\n",
      "Eval_MaxReturn : 162.79576110839844\n",
      "Eval_MinReturn : 116.64031982421875\n",
      "Eval_AverageEpLen : 71.57142857142857\n",
      "Train_AverageReturn : 144.3424530029297\n",
      "Train_StdReturn : 23.413347244262695\n",
      "Train_MaxReturn : 204.5155792236328\n",
      "Train_MinReturn : 96.01470184326172\n",
      "Train_AverageEpLen : 74.12592592592593\n",
      "Train_EnvstepsSoFar : 351421\n",
      "TimeSinceStart : 218.07433891296387\n",
      "Training Loss : 133.59213256835938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 35 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10057 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 128.0058135986328\n",
      "Eval_StdReturn : 16.40669059753418\n",
      "Eval_MaxReturn : 148.42774963378906\n",
      "Eval_MinReturn : 89.76472473144531\n",
      "Eval_AverageEpLen : 67.66666666666667\n",
      "Train_AverageReturn : 135.208984375\n",
      "Train_StdReturn : 20.69231414794922\n",
      "Train_MaxReturn : 204.61105346679688\n",
      "Train_MinReturn : 95.83464813232422\n",
      "Train_AverageEpLen : 70.82394366197182\n",
      "Train_EnvstepsSoFar : 361478\n",
      "TimeSinceStart : 223.6706347465515\n",
      "Training Loss : 129.05543518066406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 36 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 115.90657806396484\n",
      "Eval_StdReturn : 19.06709098815918\n",
      "Eval_MaxReturn : 152.963134765625\n",
      "Eval_MinReturn : 82.72362518310547\n",
      "Eval_AverageEpLen : 62.23529411764706\n",
      "Train_AverageReturn : 126.92448425292969\n",
      "Train_StdReturn : 19.170129776000977\n",
      "Train_MaxReturn : 211.3478240966797\n",
      "Train_MinReturn : 88.67965698242188\n",
      "Train_AverageEpLen : 67.63513513513513\n",
      "Train_EnvstepsSoFar : 371488\n",
      "TimeSinceStart : 229.52345442771912\n",
      "Training Loss : 124.46278381347656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 37 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 112.98019409179688\n",
      "Eval_StdReturn : 15.678407669067383\n",
      "Eval_MaxReturn : 141.43020629882812\n",
      "Eval_MinReturn : 84.83853149414062\n",
      "Eval_AverageEpLen : 61.94117647058823\n",
      "Train_AverageReturn : 114.3990707397461\n",
      "Train_StdReturn : 16.713977813720703\n",
      "Train_MaxReturn : 159.40223693847656\n",
      "Train_MinReturn : 76.55799102783203\n",
      "Train_AverageEpLen : 62.29192546583851\n",
      "Train_EnvstepsSoFar : 381517\n",
      "TimeSinceStart : 235.39944505691528\n",
      "Training Loss : 118.14439392089844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 38 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 115.01268005371094\n",
      "Eval_StdReturn : 14.1752347946167\n",
      "Eval_MaxReturn : 145.37969970703125\n",
      "Eval_MinReturn : 97.31814575195312\n",
      "Eval_AverageEpLen : 62.8125\n",
      "Train_AverageReturn : 109.29827880859375\n",
      "Train_StdReturn : 15.059005737304688\n",
      "Train_MaxReturn : 152.44456481933594\n",
      "Train_MinReturn : 74.05599212646484\n",
      "Train_AverageEpLen : 60.1437125748503\n",
      "Train_EnvstepsSoFar : 391561\n",
      "TimeSinceStart : 241.3413758277893\n",
      "Training Loss : 115.27399444580078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 39 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 109.74506378173828\n",
      "Eval_StdReturn : 17.532711029052734\n",
      "Eval_MaxReturn : 147.41497802734375\n",
      "Eval_MinReturn : 86.39986419677734\n",
      "Eval_AverageEpLen : 59.705882352941174\n",
      "Train_AverageReturn : 109.23014068603516\n",
      "Train_StdReturn : 13.895476341247559\n",
      "Train_MaxReturn : 150.5149688720703\n",
      "Train_MinReturn : 82.08381652832031\n",
      "Train_AverageEpLen : 60.131736526946106\n",
      "Train_EnvstepsSoFar : 401603\n",
      "TimeSinceStart : 247.36322593688965\n",
      "Training Loss : 114.6874008178711\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 40 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10045 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 114.24291229248047\n",
      "Eval_StdReturn : 10.000701904296875\n",
      "Eval_MaxReturn : 140.5480499267578\n",
      "Eval_MinReturn : 97.65316772460938\n",
      "Eval_AverageEpLen : 62.529411764705884\n",
      "Train_AverageReturn : 108.7406997680664\n",
      "Train_StdReturn : 15.778254508972168\n",
      "Train_MaxReturn : 189.69688415527344\n",
      "Train_MinReturn : 79.15705871582031\n",
      "Train_AverageEpLen : 59.791666666666664\n",
      "Train_EnvstepsSoFar : 411648\n",
      "TimeSinceStart : 253.37273955345154\n",
      "Training Loss : 114.87181091308594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 41 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10064 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 114.69503784179688\n",
      "Eval_StdReturn : 19.557174682617188\n",
      "Eval_MaxReturn : 152.19725036621094\n",
      "Eval_MinReturn : 82.20902252197266\n",
      "Eval_AverageEpLen : 61.705882352941174\n",
      "Train_AverageReturn : 108.27040100097656\n",
      "Train_StdReturn : 14.905797004699707\n",
      "Train_MaxReturn : 154.6176300048828\n",
      "Train_MinReturn : 73.62812805175781\n",
      "Train_AverageEpLen : 59.55029585798817\n",
      "Train_EnvstepsSoFar : 421712\n",
      "TimeSinceStart : 259.6525504589081\n",
      "Training Loss : 114.99838256835938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 42 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10014 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 123.44254302978516\n",
      "Eval_StdReturn : 17.467721939086914\n",
      "Eval_MaxReturn : 155.4114990234375\n",
      "Eval_MinReturn : 89.96915435791016\n",
      "Eval_AverageEpLen : 66.0\n",
      "Train_AverageReturn : 108.31663513183594\n",
      "Train_StdReturn : 14.172039985656738\n",
      "Train_MaxReturn : 154.341552734375\n",
      "Train_MinReturn : 77.87421417236328\n",
      "Train_AverageEpLen : 59.607142857142854\n",
      "Train_EnvstepsSoFar : 431726\n",
      "TimeSinceStart : 265.8721866607666\n",
      "Training Loss : 114.8262710571289\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 43 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10043 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 131.16712951660156\n",
      "Eval_StdReturn : 18.054237365722656\n",
      "Eval_MaxReturn : 164.31246948242188\n",
      "Eval_MinReturn : 102.0631332397461\n",
      "Eval_AverageEpLen : 69.26666666666667\n",
      "Train_AverageReturn : 116.37991333007812\n",
      "Train_StdReturn : 17.106678009033203\n",
      "Train_MaxReturn : 168.1812286376953\n",
      "Train_MinReturn : 81.32280731201172\n",
      "Train_AverageEpLen : 63.16352201257862\n",
      "Train_EnvstepsSoFar : 441769\n",
      "TimeSinceStart : 271.8804278373718\n",
      "Training Loss : 118.69577026367188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 44 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 152.9292449951172\n",
      "Eval_StdReturn : 22.122528076171875\n",
      "Eval_MaxReturn : 176.33677673339844\n",
      "Eval_MinReturn : 111.1621322631836\n",
      "Eval_AverageEpLen : 77.38461538461539\n",
      "Train_AverageReturn : 124.25496673583984\n",
      "Train_StdReturn : 18.92251968383789\n",
      "Train_MaxReturn : 176.09613037109375\n",
      "Train_MinReturn : 92.52503204345703\n",
      "Train_AverageEpLen : 66.66225165562913\n",
      "Train_EnvstepsSoFar : 451835\n",
      "TimeSinceStart : 277.81425285339355\n",
      "Training Loss : 122.19496154785156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 45 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.13717651367188\n",
      "Eval_StdReturn : 13.023236274719238\n",
      "Eval_MaxReturn : 177.52015686035156\n",
      "Eval_MinReturn : 124.33671569824219\n",
      "Eval_AverageEpLen : 82.76923076923077\n",
      "Train_AverageReturn : 144.8043975830078\n",
      "Train_StdReturn : 23.873815536499023\n",
      "Train_MaxReturn : 184.49009704589844\n",
      "Train_MinReturn : 97.03446197509766\n",
      "Train_AverageEpLen : 74.28148148148148\n",
      "Train_EnvstepsSoFar : 461863\n",
      "TimeSinceStart : 283.5857367515564\n",
      "Training Loss : 133.36769104003906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 46 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10078 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.56077575683594\n",
      "Eval_StdReturn : 3.4732916355133057\n",
      "Eval_MaxReturn : 183.6049041748047\n",
      "Eval_MinReturn : 170.13601684570312\n",
      "Eval_AverageEpLen : 85.58333333333333\n",
      "Train_AverageReturn : 166.15147399902344\n",
      "Train_StdReturn : 15.811140060424805\n",
      "Train_MaxReturn : 181.02748107910156\n",
      "Train_MinReturn : 95.32904052734375\n",
      "Train_AverageEpLen : 82.60655737704919\n",
      "Train_EnvstepsSoFar : 471941\n",
      "TimeSinceStart : 289.3611590862274\n",
      "Training Loss : 141.9598388671875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 47 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10082 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.3740692138672\n",
      "Eval_StdReturn : 1.2866947650909424\n",
      "Eval_MaxReturn : 172.15135192871094\n",
      "Eval_MinReturn : 167.333740234375\n",
      "Eval_AverageEpLen : 85.25\n",
      "Train_AverageReturn : 171.78260803222656\n",
      "Train_StdReturn : 3.7370212078094482\n",
      "Train_MaxReturn : 188.51947021484375\n",
      "Train_MinReturn : 163.89138793945312\n",
      "Train_AverageEpLen : 85.44067796610169\n",
      "Train_EnvstepsSoFar : 482023\n",
      "TimeSinceStart : 295.39925146102905\n",
      "Training Loss : 142.51966857910156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 48 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.7561492919922\n",
      "Eval_StdReturn : 2.813594341278076\n",
      "Eval_MaxReturn : 172.22622680664062\n",
      "Eval_MinReturn : 161.83468627929688\n",
      "Eval_AverageEpLen : 85.25\n",
      "Train_AverageReturn : 170.42222595214844\n",
      "Train_StdReturn : 3.9849436283111572\n",
      "Train_MaxReturn : 188.6446990966797\n",
      "Train_MinReturn : 159.54251098632812\n",
      "Train_AverageEpLen : 85.10169491525424\n",
      "Train_EnvstepsSoFar : 492065\n",
      "TimeSinceStart : 301.45172023773193\n",
      "Training Loss : 142.3978271484375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 49 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10057 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.7063446044922\n",
      "Eval_StdReturn : 2.686793804168701\n",
      "Eval_MaxReturn : 171.6536865234375\n",
      "Eval_MinReturn : 160.55844116210938\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 169.32301330566406\n",
      "Train_StdReturn : 3.767812728881836\n",
      "Train_MaxReturn : 185.02200317382812\n",
      "Train_MinReturn : 156.29428100585938\n",
      "Train_AverageEpLen : 85.22881355932203\n",
      "Train_EnvstepsSoFar : 502122\n",
      "TimeSinceStart : 307.3916120529175\n",
      "Training Loss : 140.65391540527344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.89720153808594\n",
      "Eval_StdReturn : 4.265141010284424\n",
      "Eval_MaxReturn : 181.45919799804688\n",
      "Eval_MinReturn : 165.6193389892578\n",
      "Eval_AverageEpLen : 85.0\n",
      "Train_AverageReturn : 167.61538696289062\n",
      "Train_StdReturn : 4.124837398529053\n",
      "Train_MaxReturn : 176.55508422851562\n",
      "Train_MinReturn : 153.24069213867188\n",
      "Train_AverageEpLen : 84.95762711864407\n",
      "Train_EnvstepsSoFar : 512147\n",
      "TimeSinceStart : 313.22659182548523\n",
      "Training Loss : 139.96937561035156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.6957244873047\n",
      "Eval_StdReturn : 2.485938549041748\n",
      "Eval_MaxReturn : 171.68576049804688\n",
      "Eval_MinReturn : 163.77561950683594\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 167.96322631835938\n",
      "Train_StdReturn : 3.098850965499878\n",
      "Train_MaxReturn : 175.16432189941406\n",
      "Train_MinReturn : 159.9984893798828\n",
      "Train_AverageEpLen : 84.99152542372882\n",
      "Train_EnvstepsSoFar : 522176\n",
      "TimeSinceStart : 318.728364944458\n",
      "Training Loss : 140.78684997558594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.63682556152344\n",
      "Eval_StdReturn : 5.403648853302002\n",
      "Eval_MaxReturn : 184.04376220703125\n",
      "Eval_MinReturn : 161.66172790527344\n",
      "Eval_AverageEpLen : 84.33333333333333\n",
      "Train_AverageReturn : 168.2252655029297\n",
      "Train_StdReturn : 3.5322492122650146\n",
      "Train_MaxReturn : 179.0128631591797\n",
      "Train_MinReturn : 159.0603485107422\n",
      "Train_AverageEpLen : 84.94067796610169\n",
      "Train_EnvstepsSoFar : 532199\n",
      "TimeSinceStart : 324.52047777175903\n",
      "Training Loss : 140.85906982421875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.4363555908203\n",
      "Eval_StdReturn : 5.817749500274658\n",
      "Eval_MaxReturn : 181.54788208007812\n",
      "Eval_MinReturn : 156.38809204101562\n",
      "Eval_AverageEpLen : 84.83333333333333\n",
      "Train_AverageReturn : 169.0347442626953\n",
      "Train_StdReturn : 4.053542613983154\n",
      "Train_MaxReturn : 184.94610595703125\n",
      "Train_MinReturn : 155.18524169921875\n",
      "Train_AverageEpLen : 84.87288135593221\n",
      "Train_EnvstepsSoFar : 542214\n",
      "TimeSinceStart : 330.3428285121918\n",
      "Training Loss : 141.83135986328125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.94622802734375\n",
      "Eval_StdReturn : 3.1415164470672607\n",
      "Eval_MaxReturn : 176.5968780517578\n",
      "Eval_MinReturn : 164.26998901367188\n",
      "Eval_AverageEpLen : 85.0\n",
      "Train_AverageReturn : 169.47203063964844\n",
      "Train_StdReturn : 3.508253335952759\n",
      "Train_MaxReturn : 181.71507263183594\n",
      "Train_MinReturn : 158.6819305419922\n",
      "Train_AverageEpLen : 84.8135593220339\n",
      "Train_EnvstepsSoFar : 552222\n",
      "TimeSinceStart : 336.1659789085388\n",
      "Training Loss : 141.93948364257812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.45806884765625\n",
      "Eval_StdReturn : 3.3687584400177\n",
      "Eval_MaxReturn : 171.80628967285156\n",
      "Eval_MinReturn : 160.26028442382812\n",
      "Eval_AverageEpLen : 84.75\n",
      "Train_AverageReturn : 168.70855712890625\n",
      "Train_StdReturn : 3.495777130126953\n",
      "Train_MaxReturn : 180.52874755859375\n",
      "Train_MinReturn : 158.97244262695312\n",
      "Train_AverageEpLen : 84.88135593220339\n",
      "Train_EnvstepsSoFar : 562238\n",
      "TimeSinceStart : 342.00447177886963\n",
      "Training Loss : 140.9401397705078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10014 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.1969757080078\n",
      "Eval_StdReturn : 2.3929169178009033\n",
      "Eval_MaxReturn : 172.45782470703125\n",
      "Eval_MinReturn : 165.32591247558594\n",
      "Eval_AverageEpLen : 84.58333333333333\n",
      "Train_AverageReturn : 168.7856903076172\n",
      "Train_StdReturn : 4.005270481109619\n",
      "Train_MaxReturn : 181.4746856689453\n",
      "Train_MinReturn : 156.0285186767578\n",
      "Train_AverageEpLen : 84.86440677966101\n",
      "Train_EnvstepsSoFar : 572252\n",
      "TimeSinceStart : 347.59337639808655\n",
      "Training Loss : 141.22952270507812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.8091583251953\n",
      "Eval_StdReturn : 4.314101219177246\n",
      "Eval_MaxReturn : 173.70660400390625\n",
      "Eval_MinReturn : 156.9990997314453\n",
      "Eval_AverageEpLen : 84.41666666666667\n",
      "Train_AverageReturn : 169.3003692626953\n",
      "Train_StdReturn : 4.64453125\n",
      "Train_MaxReturn : 189.79730224609375\n",
      "Train_MinReturn : 154.4881134033203\n",
      "Train_AverageEpLen : 84.83050847457628\n",
      "Train_EnvstepsSoFar : 582262\n",
      "TimeSinceStart : 353.2182071208954\n",
      "Training Loss : 142.40548706054688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.6925811767578\n",
      "Eval_StdReturn : 4.010390758514404\n",
      "Eval_MaxReturn : 178.0570068359375\n",
      "Eval_MinReturn : 163.14712524414062\n",
      "Eval_AverageEpLen : 84.75\n",
      "Train_AverageReturn : 169.05599975585938\n",
      "Train_StdReturn : 4.312920093536377\n",
      "Train_MaxReturn : 183.57708740234375\n",
      "Train_MinReturn : 157.19686889648438\n",
      "Train_AverageEpLen : 84.79661016949153\n",
      "Train_EnvstepsSoFar : 592268\n",
      "TimeSinceStart : 358.95410537719727\n",
      "Training Loss : 141.69830322265625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10043 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 172.3670654296875\n",
      "Eval_StdReturn : 4.603176116943359\n",
      "Eval_MaxReturn : 185.22244262695312\n",
      "Eval_MinReturn : 165.6260223388672\n",
      "Eval_AverageEpLen : 84.66666666666667\n",
      "Train_AverageReturn : 170.6426239013672\n",
      "Train_StdReturn : 4.3394694328308105\n",
      "Train_MaxReturn : 183.3539276123047\n",
      "Train_MinReturn : 161.7477569580078\n",
      "Train_AverageEpLen : 84.39495798319328\n",
      "Train_EnvstepsSoFar : 602311\n",
      "TimeSinceStart : 364.58921933174133\n",
      "Training Loss : 144.0540008544922\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10046 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.96026611328125\n",
      "Eval_StdReturn : 4.131293296813965\n",
      "Eval_MaxReturn : 181.1192169189453\n",
      "Eval_MinReturn : 166.11720275878906\n",
      "Eval_AverageEpLen : 84.41666666666667\n",
      "Train_AverageReturn : 172.3014373779297\n",
      "Train_StdReturn : 5.181374549865723\n",
      "Train_MaxReturn : 186.9408416748047\n",
      "Train_MinReturn : 151.06446838378906\n",
      "Train_AverageEpLen : 84.4201680672269\n",
      "Train_EnvstepsSoFar : 612357\n",
      "TimeSinceStart : 370.09309339523315\n",
      "Training Loss : 146.54312133789062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10051 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.3012237548828\n",
      "Eval_StdReturn : 5.951819896697998\n",
      "Eval_MaxReturn : 183.82228088378906\n",
      "Eval_MinReturn : 166.12062072753906\n",
      "Eval_AverageEpLen : 85.0\n",
      "Train_AverageReturn : 173.85768127441406\n",
      "Train_StdReturn : 4.664414405822754\n",
      "Train_MaxReturn : 192.314697265625\n",
      "Train_MinReturn : 164.08108520507812\n",
      "Train_AverageEpLen : 84.46218487394958\n",
      "Train_EnvstepsSoFar : 622408\n",
      "TimeSinceStart : 375.7749924659729\n",
      "Training Loss : 148.56202697753906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10031 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.8487548828125\n",
      "Eval_StdReturn : 4.8748602867126465\n",
      "Eval_MaxReturn : 193.13352966308594\n",
      "Eval_MinReturn : 174.77757263183594\n",
      "Eval_AverageEpLen : 85.08333333333333\n",
      "Train_AverageReturn : 176.6697235107422\n",
      "Train_StdReturn : 5.04659366607666\n",
      "Train_MaxReturn : 192.78858947753906\n",
      "Train_MinReturn : 162.81845092773438\n",
      "Train_AverageEpLen : 84.29411764705883\n",
      "Train_EnvstepsSoFar : 632439\n",
      "TimeSinceStart : 381.5051164627075\n",
      "Training Loss : 151.541259765625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 182.24488830566406\n",
      "Eval_StdReturn : 5.388319969177246\n",
      "Eval_MaxReturn : 188.98622131347656\n",
      "Eval_MinReturn : 173.2590789794922\n",
      "Eval_AverageEpLen : 85.91666666666667\n",
      "Train_AverageReturn : 178.15261840820312\n",
      "Train_StdReturn : 5.907454013824463\n",
      "Train_MaxReturn : 194.10202026367188\n",
      "Train_MinReturn : 167.89784240722656\n",
      "Train_AverageEpLen : 84.66386554621849\n",
      "Train_EnvstepsSoFar : 642514\n",
      "TimeSinceStart : 387.4745788574219\n",
      "Training Loss : 152.96827697753906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10053 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 184.0546417236328\n",
      "Eval_StdReturn : 6.906805038452148\n",
      "Eval_MaxReturn : 196.69142150878906\n",
      "Eval_MinReturn : 173.36451721191406\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 180.14791870117188\n",
      "Train_StdReturn : 6.718290328979492\n",
      "Train_MaxReturn : 207.8363494873047\n",
      "Train_MinReturn : 167.79129028320312\n",
      "Train_AverageEpLen : 85.19491525423729\n",
      "Train_EnvstepsSoFar : 652567\n",
      "TimeSinceStart : 393.2895107269287\n",
      "Training Loss : 153.9650115966797\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10080 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 186.75071716308594\n",
      "Eval_StdReturn : 6.661416053771973\n",
      "Eval_MaxReturn : 197.0716552734375\n",
      "Eval_MinReturn : 171.85641479492188\n",
      "Eval_AverageEpLen : 85.66666666666667\n",
      "Train_AverageReturn : 181.99920654296875\n",
      "Train_StdReturn : 13.78731918334961\n",
      "Train_MaxReturn : 204.59344482421875\n",
      "Train_MinReturn : 88.86688232421875\n",
      "Train_AverageEpLen : 85.42372881355932\n",
      "Train_EnvstepsSoFar : 662647\n",
      "TimeSinceStart : 399.1260290145874\n",
      "Training Loss : 156.6853790283203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10027 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 187.5517120361328\n",
      "Eval_StdReturn : 5.204684257507324\n",
      "Eval_MaxReturn : 194.97802734375\n",
      "Eval_MinReturn : 177.9512481689453\n",
      "Eval_AverageEpLen : 87.66666666666667\n",
      "Train_AverageReturn : 186.23931884765625\n",
      "Train_StdReturn : 7.637442588806152\n",
      "Train_MaxReturn : 207.89100646972656\n",
      "Train_MinReturn : 168.03857421875\n",
      "Train_AverageEpLen : 86.4396551724138\n",
      "Train_EnvstepsSoFar : 672674\n",
      "TimeSinceStart : 404.711816072464\n",
      "Training Loss : 159.3103790283203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 188.3954315185547\n",
      "Eval_StdReturn : 13.338385581970215\n",
      "Eval_MaxReturn : 207.69271850585938\n",
      "Eval_MinReturn : 160.48338317871094\n",
      "Eval_AverageEpLen : 87.58333333333333\n",
      "Train_AverageReturn : 186.86102294921875\n",
      "Train_StdReturn : 16.578821182250977\n",
      "Train_MaxReturn : 216.39862060546875\n",
      "Train_MinReturn : 86.90441131591797\n",
      "Train_AverageEpLen : 86.97391304347826\n",
      "Train_EnvstepsSoFar : 682676\n",
      "TimeSinceStart : 410.39037251472473\n",
      "Training Loss : 159.30958557128906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 197.56044006347656\n",
      "Eval_StdReturn : 8.891156196594238\n",
      "Eval_MaxReturn : 209.89138793945312\n",
      "Eval_MinReturn : 180.29168701171875\n",
      "Eval_AverageEpLen : 90.5\n",
      "Train_AverageReturn : 191.86276245117188\n",
      "Train_StdReturn : 8.900206565856934\n",
      "Train_MaxReturn : 214.03855895996094\n",
      "Train_MinReturn : 160.70445251464844\n",
      "Train_AverageEpLen : 88.86725663716814\n",
      "Train_EnvstepsSoFar : 692718\n",
      "TimeSinceStart : 416.40654039382935\n",
      "Training Loss : 160.88880920410156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 186.93589782714844\n",
      "Eval_StdReturn : 4.303798198699951\n",
      "Eval_MaxReturn : 196.66403198242188\n",
      "Eval_MinReturn : 180.5545196533203\n",
      "Eval_AverageEpLen : 86.0\n",
      "Train_AverageReturn : 190.8484649658203\n",
      "Train_StdReturn : 12.726923942565918\n",
      "Train_MaxReturn : 215.52615356445312\n",
      "Train_MinReturn : 139.33047485351562\n",
      "Train_AverageEpLen : 88.56637168141593\n",
      "Train_EnvstepsSoFar : 702726\n",
      "TimeSinceStart : 422.24780678749084\n",
      "Training Loss : 161.31602478027344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10031 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 187.5916290283203\n",
      "Eval_StdReturn : 10.943441390991211\n",
      "Eval_MaxReturn : 205.17710876464844\n",
      "Eval_MinReturn : 170.86489868164062\n",
      "Eval_AverageEpLen : 86.5\n",
      "Train_AverageReturn : 191.017822265625\n",
      "Train_StdReturn : 11.085182189941406\n",
      "Train_MaxReturn : 217.1540985107422\n",
      "Train_MinReturn : 151.4145965576172\n",
      "Train_AverageEpLen : 88.76991150442478\n",
      "Train_EnvstepsSoFar : 712757\n",
      "TimeSinceStart : 428.55781865119934\n",
      "Training Loss : 161.17861938476562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 194.7065887451172\n",
      "Eval_StdReturn : 6.541161060333252\n",
      "Eval_MaxReturn : 205.81692504882812\n",
      "Eval_MinReturn : 184.43618774414062\n",
      "Eval_AverageEpLen : 90.0\n",
      "Train_AverageReturn : 191.3451385498047\n",
      "Train_StdReturn : 9.461851119995117\n",
      "Train_MaxReturn : 220.73703002929688\n",
      "Train_MinReturn : 164.95599365234375\n",
      "Train_AverageEpLen : 88.51327433628319\n",
      "Train_EnvstepsSoFar : 722759\n",
      "TimeSinceStart : 435.0642557144165\n",
      "Training Loss : 161.88845825195312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10045 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 189.7726593017578\n",
      "Eval_StdReturn : 8.671737670898438\n",
      "Eval_MaxReturn : 202.3145751953125\n",
      "Eval_MinReturn : 175.7544403076172\n",
      "Eval_AverageEpLen : 87.5\n",
      "Train_AverageReturn : 189.7453155517578\n",
      "Train_StdReturn : 8.087579727172852\n",
      "Train_MaxReturn : 208.75701904296875\n",
      "Train_MinReturn : 172.640625\n",
      "Train_AverageEpLen : 87.34782608695652\n",
      "Train_EnvstepsSoFar : 732804\n",
      "TimeSinceStart : 441.14553213119507\n",
      "Training Loss : 162.89508056640625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10067 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 189.46131896972656\n",
      "Eval_StdReturn : 8.178730964660645\n",
      "Eval_MaxReturn : 201.3081512451172\n",
      "Eval_MinReturn : 176.5164031982422\n",
      "Eval_AverageEpLen : 86.75\n",
      "Train_AverageReturn : 188.67344665527344\n",
      "Train_StdReturn : 8.940980911254883\n",
      "Train_MaxReturn : 213.62283325195312\n",
      "Train_MinReturn : 172.572021484375\n",
      "Train_AverageEpLen : 86.78448275862068\n",
      "Train_EnvstepsSoFar : 742871\n",
      "TimeSinceStart : 447.18209767341614\n",
      "Training Loss : 163.341552734375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 186.2965087890625\n",
      "Eval_StdReturn : 7.021047115325928\n",
      "Eval_MaxReturn : 197.565673828125\n",
      "Eval_MinReturn : 172.4674530029297\n",
      "Eval_AverageEpLen : 85.25\n",
      "Train_AverageReturn : 188.95497131347656\n",
      "Train_StdReturn : 8.1161470413208\n",
      "Train_MaxReturn : 206.97067260742188\n",
      "Train_MinReturn : 170.1629638671875\n",
      "Train_AverageEpLen : 86.42241379310344\n",
      "Train_EnvstepsSoFar : 752896\n",
      "TimeSinceStart : 453.19241738319397\n",
      "Training Loss : 163.34640502929688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 186.4619598388672\n",
      "Eval_StdReturn : 5.19268798828125\n",
      "Eval_MaxReturn : 197.42018127441406\n",
      "Eval_MinReturn : 178.4060821533203\n",
      "Eval_AverageEpLen : 85.25\n",
      "Train_AverageReturn : 186.69046020507812\n",
      "Train_StdReturn : 8.572758674621582\n",
      "Train_MaxReturn : 205.9269561767578\n",
      "Train_MinReturn : 170.75454711914062\n",
      "Train_AverageEpLen : 85.71794871794872\n",
      "Train_EnvstepsSoFar : 762925\n",
      "TimeSinceStart : 458.95799350738525\n",
      "Training Loss : 163.4095916748047\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 183.3387451171875\n",
      "Eval_StdReturn : 10.004767417907715\n",
      "Eval_MaxReturn : 198.92864990234375\n",
      "Eval_MinReturn : 168.9110870361328\n",
      "Eval_AverageEpLen : 85.08333333333333\n",
      "Train_AverageReturn : 184.06039428710938\n",
      "Train_StdReturn : 7.327335834503174\n",
      "Train_MaxReturn : 203.70030212402344\n",
      "Train_MinReturn : 166.23089599609375\n",
      "Train_AverageEpLen : 84.85593220338983\n",
      "Train_EnvstepsSoFar : 772938\n",
      "TimeSinceStart : 464.40731596946716\n",
      "Training Loss : 161.90968322753906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.17355346679688\n",
      "Eval_StdReturn : 24.45336151123047\n",
      "Eval_MaxReturn : 200.27369689941406\n",
      "Eval_MinReturn : 92.81501770019531\n",
      "Eval_AverageEpLen : 81.92307692307692\n",
      "Train_AverageReturn : 182.85302734375\n",
      "Train_StdReturn : 7.829435348510742\n",
      "Train_MaxReturn : 205.03744506835938\n",
      "Train_MinReturn : 167.99057006835938\n",
      "Train_AverageEpLen : 84.60504201680672\n",
      "Train_EnvstepsSoFar : 783006\n",
      "TimeSinceStart : 469.9029839038849\n",
      "Training Loss : 160.63124084472656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.2452392578125\n",
      "Eval_StdReturn : 8.800601959228516\n",
      "Eval_MaxReturn : 199.70819091796875\n",
      "Eval_MinReturn : 168.4775390625\n",
      "Eval_AverageEpLen : 84.16666666666667\n",
      "Train_AverageReturn : 180.44775390625\n",
      "Train_StdReturn : 6.703067302703857\n",
      "Train_MaxReturn : 201.22523498535156\n",
      "Train_MinReturn : 165.97119140625\n",
      "Train_AverageEpLen : 83.9\n",
      "Train_EnvstepsSoFar : 793074\n",
      "TimeSinceStart : 475.36100697517395\n",
      "Training Loss : 160.23890686035156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10067 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.26638793945312\n",
      "Eval_StdReturn : 41.85548782348633\n",
      "Eval_MaxReturn : 189.77247619628906\n",
      "Eval_MinReturn : 23.11906623840332\n",
      "Eval_AverageEpLen : 78.61538461538461\n",
      "Train_AverageReturn : 177.08966064453125\n",
      "Train_StdReturn : 20.917043685913086\n",
      "Train_MaxReturn : 206.3208770751953\n",
      "Train_MinReturn : 18.150447845458984\n",
      "Train_AverageEpLen : 82.51639344262296\n",
      "Train_EnvstepsSoFar : 803141\n",
      "TimeSinceStart : 480.82171654701233\n",
      "Training Loss : 159.50750732421875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 132.48353576660156\n",
      "Eval_StdReturn : 72.61084747314453\n",
      "Eval_MaxReturn : 201.0366973876953\n",
      "Eval_MinReturn : 20.56137466430664\n",
      "Eval_AverageEpLen : 63.875\n",
      "Train_AverageReturn : 153.63526916503906\n",
      "Train_StdReturn : 59.45921325683594\n",
      "Train_MaxReturn : 198.41204833984375\n",
      "Train_MinReturn : 17.093006134033203\n",
      "Train_AverageEpLen : 72.5\n",
      "Train_EnvstepsSoFar : 813146\n",
      "TimeSinceStart : 486.25115299224854\n",
      "Training Loss : 155.5918426513672\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 120.26980590820312\n",
      "Eval_StdReturn : 77.73387908935547\n",
      "Eval_MaxReturn : 191.9537353515625\n",
      "Eval_MinReturn : 18.62158203125\n",
      "Eval_AverageEpLen : 58.27777777777778\n",
      "Train_AverageReturn : 134.10568237304688\n",
      "Train_StdReturn : 70.97264862060547\n",
      "Train_MaxReturn : 196.62071228027344\n",
      "Train_MinReturn : 15.009323120117188\n",
      "Train_AverageEpLen : 64.54193548387097\n",
      "Train_EnvstepsSoFar : 823150\n",
      "TimeSinceStart : 491.6798357963562\n",
      "Training Loss : 150.93606567382812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.17620849609375\n",
      "Eval_StdReturn : 43.147945404052734\n",
      "Eval_MaxReturn : 190.74484252929688\n",
      "Eval_MinReturn : 19.423019409179688\n",
      "Eval_AverageEpLen : 78.53846153846153\n",
      "Train_AverageReturn : 130.74684143066406\n",
      "Train_StdReturn : 73.15693664550781\n",
      "Train_MaxReturn : 193.21792602539062\n",
      "Train_MinReturn : 16.64282989501953\n",
      "Train_AverageEpLen : 62.937106918238996\n",
      "Train_EnvstepsSoFar : 833157\n",
      "TimeSinceStart : 497.0940568447113\n",
      "Training Loss : 150.83639526367188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10065 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.669189453125\n",
      "Eval_StdReturn : 21.5325870513916\n",
      "Eval_MaxReturn : 190.37330627441406\n",
      "Eval_MinReturn : 112.7247314453125\n",
      "Eval_AverageEpLen : 79.6923076923077\n",
      "Train_AverageReturn : 167.82916259765625\n",
      "Train_StdReturn : 41.120052337646484\n",
      "Train_MaxReturn : 201.57867431640625\n",
      "Train_MinReturn : 18.036087036132812\n",
      "Train_AverageEpLen : 78.6328125\n",
      "Train_EnvstepsSoFar : 843222\n",
      "TimeSinceStart : 502.5180995464325\n",
      "Training Loss : 158.075439453125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 152.3221435546875\n",
      "Eval_StdReturn : 25.28734016418457\n",
      "Eval_MaxReturn : 192.3564910888672\n",
      "Eval_MinReturn : 103.10938262939453\n",
      "Eval_AverageEpLen : 74.42857142857143\n",
      "Train_AverageReturn : 162.1271209716797\n",
      "Train_StdReturn : 26.9299259185791\n",
      "Train_MaxReturn : 196.60597229003906\n",
      "Train_MinReturn : 75.42851257324219\n",
      "Train_AverageEpLen : 77.53488372093024\n",
      "Train_EnvstepsSoFar : 853224\n",
      "TimeSinceStart : 508.0070538520813\n",
      "Training Loss : 152.1186065673828\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 140.5592498779297\n",
      "Eval_StdReturn : 31.06905174255371\n",
      "Eval_MaxReturn : 197.86312866210938\n",
      "Eval_MinReturn : 89.72537994384766\n",
      "Eval_AverageEpLen : 70.53333333333333\n",
      "Train_AverageReturn : 145.3101348876953\n",
      "Train_StdReturn : 30.462900161743164\n",
      "Train_MaxReturn : 203.24627685546875\n",
      "Train_MinReturn : 71.48706817626953\n",
      "Train_AverageEpLen : 72.01438848920863\n",
      "Train_EnvstepsSoFar : 863234\n",
      "TimeSinceStart : 513.4124481678009\n",
      "Training Loss : 144.90240478515625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10052 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 175.1025390625\n",
      "Eval_StdReturn : 23.42588996887207\n",
      "Eval_MaxReturn : 204.12062072753906\n",
      "Eval_MinReturn : 120.11040496826172\n",
      "Eval_AverageEpLen : 83.38461538461539\n",
      "Train_AverageReturn : 152.53787231445312\n",
      "Train_StdReturn : 32.28535842895508\n",
      "Train_MaxReturn : 197.9195556640625\n",
      "Train_MinReturn : 74.41969299316406\n",
      "Train_AverageEpLen : 75.01492537313433\n",
      "Train_EnvstepsSoFar : 873286\n",
      "TimeSinceStart : 518.8459906578064\n",
      "Training Loss : 146.48948669433594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 184.70933532714844\n",
      "Eval_StdReturn : 3.9362432956695557\n",
      "Eval_MaxReturn : 192.1602325439453\n",
      "Eval_MinReturn : 178.27908325195312\n",
      "Eval_AverageEpLen : 86.66666666666667\n",
      "Train_AverageReturn : 182.8980712890625\n",
      "Train_StdReturn : 16.327444076538086\n",
      "Train_MaxReturn : 207.5491943359375\n",
      "Train_MinReturn : 121.1900405883789\n",
      "Train_AverageEpLen : 86.42241379310344\n",
      "Train_EnvstepsSoFar : 883311\n",
      "TimeSinceStart : 524.323014497757\n",
      "Training Loss : 157.56800842285156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10069 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 183.89837646484375\n",
      "Eval_StdReturn : 4.8313446044921875\n",
      "Eval_MaxReturn : 191.05978393554688\n",
      "Eval_MinReturn : 178.63743591308594\n",
      "Eval_AverageEpLen : 88.08333333333333\n",
      "Train_AverageReturn : 185.6718292236328\n",
      "Train_StdReturn : 9.35002613067627\n",
      "Train_MaxReturn : 207.53713989257812\n",
      "Train_MinReturn : 136.9881591796875\n",
      "Train_AverageEpLen : 88.32456140350877\n",
      "Train_EnvstepsSoFar : 893380\n",
      "TimeSinceStart : 529.7559661865234\n",
      "Training Loss : 157.64561462402344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10078 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 186.65928649902344\n",
      "Eval_StdReturn : 5.609119415283203\n",
      "Eval_MaxReturn : 195.8063201904297\n",
      "Eval_MinReturn : 174.4155731201172\n",
      "Eval_AverageEpLen : 90.08333333333333\n",
      "Train_AverageReturn : 186.09010314941406\n",
      "Train_StdReturn : 6.612236976623535\n",
      "Train_MaxReturn : 202.1154327392578\n",
      "Train_MinReturn : 171.48934936523438\n",
      "Train_AverageEpLen : 89.1858407079646\n",
      "Train_EnvstepsSoFar : 903458\n",
      "TimeSinceStart : 535.2209045886993\n",
      "Training Loss : 156.333740234375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10076 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 184.91847229003906\n",
      "Eval_StdReturn : 4.902597427368164\n",
      "Eval_MaxReturn : 196.64111328125\n",
      "Eval_MinReturn : 177.83236694335938\n",
      "Eval_AverageEpLen : 87.58333333333333\n",
      "Train_AverageReturn : 183.82933044433594\n",
      "Train_StdReturn : 6.356738567352295\n",
      "Train_MaxReturn : 204.2594451904297\n",
      "Train_MinReturn : 171.2555389404297\n",
      "Train_AverageEpLen : 88.3859649122807\n",
      "Train_EnvstepsSoFar : 913534\n",
      "TimeSinceStart : 540.6848866939545\n",
      "Training Loss : 155.45277404785156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.7693634033203\n",
      "Eval_StdReturn : 4.530882835388184\n",
      "Eval_MaxReturn : 188.49630737304688\n",
      "Eval_MinReturn : 174.76849365234375\n",
      "Eval_AverageEpLen : 88.16666666666667\n",
      "Train_AverageReturn : 183.58970642089844\n",
      "Train_StdReturn : 6.995269298553467\n",
      "Train_MaxReturn : 206.23480224609375\n",
      "Train_MinReturn : 166.60604858398438\n",
      "Train_AverageEpLen : 88.65486725663717\n",
      "Train_EnvstepsSoFar : 923552\n",
      "TimeSinceStart : 546.0833990573883\n",
      "Training Loss : 153.57870483398438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10076 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 177.36944580078125\n",
      "Eval_StdReturn : 6.528174877166748\n",
      "Eval_MaxReturn : 188.25025939941406\n",
      "Eval_MinReturn : 168.28475952148438\n",
      "Eval_AverageEpLen : 86.83333333333333\n",
      "Train_AverageReturn : 181.38641357421875\n",
      "Train_StdReturn : 6.695426940917969\n",
      "Train_MaxReturn : 203.36256408691406\n",
      "Train_MinReturn : 169.30104064941406\n",
      "Train_AverageEpLen : 88.3859649122807\n",
      "Train_EnvstepsSoFar : 933628\n",
      "TimeSinceStart : 552.0092451572418\n",
      "Training Loss : 152.88534545898438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10030 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 179.24046325683594\n",
      "Eval_StdReturn : 4.99050760269165\n",
      "Eval_MaxReturn : 187.5918426513672\n",
      "Eval_MinReturn : 170.03897094726562\n",
      "Eval_AverageEpLen : 87.58333333333333\n",
      "Train_AverageReturn : 179.1298828125\n",
      "Train_StdReturn : 6.3045806884765625\n",
      "Train_MaxReturn : 196.1455535888672\n",
      "Train_MinReturn : 160.17471313476562\n",
      "Train_AverageEpLen : 87.98245614035088\n",
      "Train_EnvstepsSoFar : 943658\n",
      "TimeSinceStart : 557.7144434452057\n",
      "Training Loss : 151.35745239257812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10078 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 180.25645446777344\n",
      "Eval_StdReturn : 6.073582649230957\n",
      "Eval_MaxReturn : 190.68553161621094\n",
      "Eval_MinReturn : 169.34423828125\n",
      "Eval_AverageEpLen : 87.5\n",
      "Train_AverageReturn : 178.97079467773438\n",
      "Train_StdReturn : 6.9139251708984375\n",
      "Train_MaxReturn : 202.78981018066406\n",
      "Train_MinReturn : 159.66647338867188\n",
      "Train_AverageEpLen : 88.40350877192982\n",
      "Train_EnvstepsSoFar : 953736\n",
      "TimeSinceStart : 564.3702237606049\n",
      "Training Loss : 149.6996612548828\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10059 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 178.6687469482422\n",
      "Eval_StdReturn : 6.328131198883057\n",
      "Eval_MaxReturn : 190.0215606689453\n",
      "Eval_MinReturn : 168.31973266601562\n",
      "Eval_AverageEpLen : 89.83333333333333\n",
      "Train_AverageReturn : 178.1121368408203\n",
      "Train_StdReturn : 5.548320293426514\n",
      "Train_MaxReturn : 194.61907958984375\n",
      "Train_MinReturn : 164.8179473876953\n",
      "Train_AverageEpLen : 89.01769911504425\n",
      "Train_EnvstepsSoFar : 963795\n",
      "TimeSinceStart : 570.9876899719238\n",
      "Training Loss : 147.32302856445312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 178.30262756347656\n",
      "Eval_StdReturn : 4.979209899902344\n",
      "Eval_MaxReturn : 186.71978759765625\n",
      "Eval_MinReturn : 168.46072387695312\n",
      "Eval_AverageEpLen : 90.83333333333333\n",
      "Train_AverageReturn : 178.37791442871094\n",
      "Train_StdReturn : 5.875255584716797\n",
      "Train_MaxReturn : 193.62843322753906\n",
      "Train_MinReturn : 165.95118713378906\n",
      "Train_AverageEpLen : 88.88495575221239\n",
      "Train_EnvstepsSoFar : 973839\n",
      "TimeSinceStart : 577.5421028137207\n",
      "Training Loss : 148.681884765625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 175.83203125\n",
      "Eval_StdReturn : 5.677947521209717\n",
      "Eval_MaxReturn : 185.659423828125\n",
      "Eval_MinReturn : 164.8548126220703\n",
      "Eval_AverageEpLen : 88.41666666666667\n",
      "Train_AverageReturn : 177.76397705078125\n",
      "Train_StdReturn : 5.389936923980713\n",
      "Train_MaxReturn : 190.76336669921875\n",
      "Train_MinReturn : 163.76268005371094\n",
      "Train_AverageEpLen : 89.07964601769912\n",
      "Train_EnvstepsSoFar : 983905\n",
      "TimeSinceStart : 584.03435754776\n",
      "Training Loss : 147.46334838867188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10093 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 176.54852294921875\n",
      "Eval_StdReturn : 5.77918004989624\n",
      "Eval_MaxReturn : 185.5818634033203\n",
      "Eval_MinReturn : 168.1362762451172\n",
      "Eval_AverageEpLen : 89.83333333333333\n",
      "Train_AverageReturn : 177.5074005126953\n",
      "Train_StdReturn : 6.460240364074707\n",
      "Train_MaxReturn : 194.25038146972656\n",
      "Train_MinReturn : 162.70718383789062\n",
      "Train_AverageEpLen : 90.11607142857143\n",
      "Train_EnvstepsSoFar : 993998\n",
      "TimeSinceStart : 590.3022241592407\n",
      "Training Loss : 145.00563049316406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10082 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.0444793701172\n",
      "Eval_StdReturn : 10.907169342041016\n",
      "Eval_MaxReturn : 186.12579345703125\n",
      "Eval_MinReturn : 142.66009521484375\n",
      "Eval_AverageEpLen : 89.83333333333333\n",
      "Train_AverageReturn : 175.81578063964844\n",
      "Train_StdReturn : 9.238297462463379\n",
      "Train_MaxReturn : 195.99676513671875\n",
      "Train_MinReturn : 104.51976776123047\n",
      "Train_AverageEpLen : 90.01785714285714\n",
      "Train_EnvstepsSoFar : 1004080\n",
      "TimeSinceStart : 596.1327700614929\n",
      "Training Loss : 143.50621032714844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 9.657980918884277\n",
      "Done logging...\n",
      "\n",
      "\n",
      "Running policy gradient experiment with seed 1\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/return_to_go/seed1\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Collecting train rollouts to be used for saving videos...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "At timestep:     1076 / 1000\n",
      "Collecting video rollouts eval\n",
      "\n",
      "Saving train rollouts as videos...\n",
      "Eval_AverageReturn : 113.01453399658203\n",
      "Eval_StdReturn : 43.42371368408203\n",
      "Eval_MaxReturn : 202.24815368652344\n",
      "Eval_MinReturn : 11.398772239685059\n",
      "Eval_AverageEpLen : 63.294117647058826\n",
      "Train_AverageReturn : 13.049403190612793\n",
      "Train_StdReturn : 8.314800262451172\n",
      "Train_MaxReturn : 61.080562591552734\n",
      "Train_MinReturn : 1.8022055625915527\n",
      "Train_AverageEpLen : 18.924385633270322\n",
      "Train_EnvstepsSoFar : 10011\n",
      "TimeSinceStart : 17.918280363082886\n",
      "Training Loss : 20.93277931213379\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10082 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 155.8422393798828\n",
      "Eval_StdReturn : 62.08246994018555\n",
      "Eval_MaxReturn : 220.54124450683594\n",
      "Eval_MinReturn : 44.967899322509766\n",
      "Eval_AverageEpLen : 76.14285714285714\n",
      "Train_AverageReturn : 114.24850463867188\n",
      "Train_StdReturn : 51.50748062133789\n",
      "Train_MaxReturn : 281.1159973144531\n",
      "Train_MinReturn : 9.878357887268066\n",
      "Train_AverageEpLen : 70.01388888888889\n",
      "Train_EnvstepsSoFar : 20093\n",
      "TimeSinceStart : 26.717829942703247\n",
      "Training Loss : 111.87433624267578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 73.5826187133789\n",
      "Eval_StdReturn : 39.09077072143555\n",
      "Eval_MaxReturn : 184.77566528320312\n",
      "Eval_MinReturn : 15.082818984985352\n",
      "Eval_AverageEpLen : 42.708333333333336\n",
      "Train_AverageReturn : 167.61199951171875\n",
      "Train_StdReturn : 48.480628967285156\n",
      "Train_MaxReturn : 226.8306884765625\n",
      "Train_MinReturn : 17.23403549194336\n",
      "Train_AverageEpLen : 79.86507936507937\n",
      "Train_EnvstepsSoFar : 30156\n",
      "TimeSinceStart : 32.63036060333252\n",
      "Training Loss : 148.36817932128906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 202.0403289794922\n",
      "Eval_StdReturn : 8.688403129577637\n",
      "Eval_MaxReturn : 212.37002563476562\n",
      "Eval_MinReturn : 182.3174591064453\n",
      "Eval_AverageEpLen : 91.0\n",
      "Train_AverageReturn : 88.3284683227539\n",
      "Train_StdReturn : 47.15947341918945\n",
      "Train_MaxReturn : 208.3626708984375\n",
      "Train_MinReturn : 16.52501678466797\n",
      "Train_AverageEpLen : 49.15686274509804\n",
      "Train_EnvstepsSoFar : 40184\n",
      "TimeSinceStart : 38.67982053756714\n",
      "Training Loss : 110.20820617675781\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 208.87890625\n",
      "Eval_StdReturn : 7.037467956542969\n",
      "Eval_MaxReturn : 216.4783172607422\n",
      "Eval_MinReturn : 189.79995727539062\n",
      "Eval_AverageEpLen : 91.63636363636364\n",
      "Train_AverageReturn : 195.40769958496094\n",
      "Train_StdReturn : 28.222314834594727\n",
      "Train_MaxReturn : 221.3123016357422\n",
      "Train_MinReturn : 62.200538635253906\n",
      "Train_AverageEpLen : 87.89473684210526\n",
      "Train_EnvstepsSoFar : 50204\n",
      "TimeSinceStart : 44.50073170661926\n",
      "Training Loss : 160.02676391601562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 161.92535400390625\n",
      "Eval_StdReturn : 35.85017395019531\n",
      "Eval_MaxReturn : 214.67752075195312\n",
      "Eval_MinReturn : 88.3343734741211\n",
      "Eval_AverageEpLen : 77.23076923076923\n",
      "Train_AverageReturn : 196.6973876953125\n",
      "Train_StdReturn : 26.031658172607422\n",
      "Train_MaxReturn : 226.45181274414062\n",
      "Train_MinReturn : 100.04491424560547\n",
      "Train_AverageEpLen : 87.8157894736842\n",
      "Train_EnvstepsSoFar : 60215\n",
      "TimeSinceStart : 50.522629261016846\n",
      "Training Loss : 161.51513671875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.7693634033203\n",
      "Eval_StdReturn : 25.885595321655273\n",
      "Eval_MaxReturn : 202.6265411376953\n",
      "Eval_MinReturn : 118.63114166259766\n",
      "Eval_AverageEpLen : 77.92307692307692\n",
      "Train_AverageReturn : 164.52430725097656\n",
      "Train_StdReturn : 29.232248306274414\n",
      "Train_MaxReturn : 217.0020294189453\n",
      "Train_MinReturn : 83.43070983886719\n",
      "Train_AverageEpLen : 77.14615384615385\n",
      "Train_EnvstepsSoFar : 70244\n",
      "TimeSinceStart : 56.8331618309021\n",
      "Training Loss : 148.95066833496094\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 192.57737731933594\n",
      "Eval_StdReturn : 17.252426147460938\n",
      "Eval_MaxReturn : 212.92564392089844\n",
      "Eval_MinReturn : 165.2661895751953\n",
      "Eval_AverageEpLen : 85.83333333333333\n",
      "Train_AverageReturn : 176.0043182373047\n",
      "Train_StdReturn : 22.381999969482422\n",
      "Train_MaxReturn : 214.0371856689453\n",
      "Train_MinReturn : 107.27181243896484\n",
      "Train_AverageEpLen : 80.83064516129032\n",
      "Train_EnvstepsSoFar : 80267\n",
      "TimeSinceStart : 62.60149312019348\n",
      "Training Loss : 153.87997436523438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 207.35914611816406\n",
      "Eval_StdReturn : 5.407192707061768\n",
      "Eval_MaxReturn : 214.54165649414062\n",
      "Eval_MinReturn : 197.41673278808594\n",
      "Eval_AverageEpLen : 90.9090909090909\n",
      "Train_AverageReturn : 195.59039306640625\n",
      "Train_StdReturn : 16.135589599609375\n",
      "Train_MaxReturn : 217.156005859375\n",
      "Train_MinReturn : 149.7564697265625\n",
      "Train_AverageEpLen : 86.99130434782609\n",
      "Train_EnvstepsSoFar : 90271\n",
      "TimeSinceStart : 68.4111704826355\n",
      "Training Loss : 160.93197631835938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 204.84864807128906\n",
      "Eval_StdReturn : 5.487678527832031\n",
      "Eval_MaxReturn : 213.03561401367188\n",
      "Eval_MinReturn : 195.76943969726562\n",
      "Eval_AverageEpLen : 90.66666666666667\n",
      "Train_AverageReturn : 207.56520080566406\n",
      "Train_StdReturn : 6.629327297210693\n",
      "Train_MaxReturn : 216.98500061035156\n",
      "Train_MinReturn : 177.0287322998047\n",
      "Train_AverageEpLen : 91.12727272727273\n",
      "Train_EnvstepsSoFar : 100295\n",
      "TimeSinceStart : 74.28842997550964\n",
      "Training Loss : 164.36355590820312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 190.16441345214844\n",
      "Eval_StdReturn : 6.234320163726807\n",
      "Eval_MaxReturn : 198.92855834960938\n",
      "Eval_MinReturn : 178.50946044921875\n",
      "Eval_AverageEpLen : 86.33333333333333\n",
      "Train_AverageReturn : 203.1054229736328\n",
      "Train_StdReturn : 11.0076322555542\n",
      "Train_MaxReturn : 212.73419189453125\n",
      "Train_MinReturn : 101.57793426513672\n",
      "Train_AverageEpLen : 90.14414414414415\n",
      "Train_EnvstepsSoFar : 110301\n",
      "TimeSinceStart : 80.4912621974945\n",
      "Training Loss : 162.02174377441406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 178.53570556640625\n",
      "Eval_StdReturn : 25.502357482910156\n",
      "Eval_MaxReturn : 198.35032653808594\n",
      "Eval_MinReturn : 93.97911071777344\n",
      "Eval_AverageEpLen : 82.61538461538461\n",
      "Train_AverageReturn : 189.9555206298828\n",
      "Train_StdReturn : 16.817529678344727\n",
      "Train_MaxReturn : 209.79832458496094\n",
      "Train_MinReturn : 68.77198791503906\n",
      "Train_AverageEpLen : 86.30172413793103\n",
      "Train_EnvstepsSoFar : 120312\n",
      "TimeSinceStart : 86.28597903251648\n",
      "Training Loss : 156.424560546875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 172.6329345703125\n",
      "Eval_StdReturn : 2.8886210918426514\n",
      "Eval_MaxReturn : 177.79624938964844\n",
      "Eval_MinReturn : 168.39956665039062\n",
      "Eval_AverageEpLen : 83.58333333333333\n",
      "Train_AverageReturn : 175.71548461914062\n",
      "Train_StdReturn : 25.553056716918945\n",
      "Train_MaxReturn : 200.97044372558594\n",
      "Train_MinReturn : 56.083065032958984\n",
      "Train_AverageEpLen : 82.1639344262295\n",
      "Train_EnvstepsSoFar : 130336\n",
      "TimeSinceStart : 92.1625292301178\n",
      "Training Loss : 149.0966796875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.48236083984375\n",
      "Eval_StdReturn : 3.2000744342803955\n",
      "Eval_MaxReturn : 180.7721405029297\n",
      "Eval_MinReturn : 168.8376007080078\n",
      "Eval_AverageEpLen : 84.0\n",
      "Train_AverageReturn : 170.32659912109375\n",
      "Train_StdReturn : 18.114774703979492\n",
      "Train_MaxReturn : 186.35089111328125\n",
      "Train_MinReturn : 58.76266098022461\n",
      "Train_AverageEpLen : 81.6829268292683\n",
      "Train_EnvstepsSoFar : 140383\n",
      "TimeSinceStart : 97.99213528633118\n",
      "Training Loss : 143.21372985839844\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.8479461669922\n",
      "Eval_StdReturn : 2.212221145629883\n",
      "Eval_MaxReturn : 175.310791015625\n",
      "Eval_MinReturn : 167.18980407714844\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 168.77012634277344\n",
      "Train_StdReturn : 14.000123023986816\n",
      "Train_MaxReturn : 178.7678680419922\n",
      "Train_MinReturn : 83.90267181396484\n",
      "Train_AverageEpLen : 82.8099173553719\n",
      "Train_EnvstepsSoFar : 150403\n",
      "TimeSinceStart : 103.71726322174072\n",
      "Training Loss : 139.72860717773438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10060 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.27574157714844\n",
      "Eval_StdReturn : 2.3571395874023438\n",
      "Eval_MaxReturn : 174.85552978515625\n",
      "Eval_MinReturn : 166.43515014648438\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 170.8007354736328\n",
      "Train_StdReturn : 2.171535015106201\n",
      "Train_MaxReturn : 175.8897247314453\n",
      "Train_MinReturn : 164.5447235107422\n",
      "Train_AverageEpLen : 84.53781512605042\n",
      "Train_EnvstepsSoFar : 160463\n",
      "TimeSinceStart : 109.71518397331238\n",
      "Training Loss : 138.57470703125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10073 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.8266143798828\n",
      "Eval_StdReturn : 2.4007351398468018\n",
      "Eval_MaxReturn : 174.6426239013672\n",
      "Eval_MinReturn : 165.22805786132812\n",
      "Eval_AverageEpLen : 85.41666666666667\n",
      "Train_AverageReturn : 170.68246459960938\n",
      "Train_StdReturn : 2.281147003173828\n",
      "Train_MaxReturn : 176.26022338867188\n",
      "Train_MinReturn : 164.61048889160156\n",
      "Train_AverageEpLen : 85.36440677966101\n",
      "Train_EnvstepsSoFar : 170536\n",
      "TimeSinceStart : 115.5413806438446\n",
      "Training Loss : 136.49365234375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.26348876953125\n",
      "Eval_StdReturn : 1.498260259628296\n",
      "Eval_MaxReturn : 176.4299774169922\n",
      "Eval_MinReturn : 170.89199829101562\n",
      "Eval_AverageEpLen : 85.41666666666667\n",
      "Train_AverageReturn : 171.06686401367188\n",
      "Train_StdReturn : 2.122377634048462\n",
      "Train_MaxReturn : 176.5039520263672\n",
      "Train_MinReturn : 163.21278381347656\n",
      "Train_AverageEpLen : 85.48717948717949\n",
      "Train_EnvstepsSoFar : 180538\n",
      "TimeSinceStart : 121.79169774055481\n",
      "Training Loss : 136.43826293945312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.4920654296875\n",
      "Eval_StdReturn : 2.4242947101593018\n",
      "Eval_MaxReturn : 174.34423828125\n",
      "Eval_MinReturn : 166.08555603027344\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 171.3169403076172\n",
      "Train_StdReturn : 2.189899444580078\n",
      "Train_MaxReturn : 176.84913635253906\n",
      "Train_MinReturn : 164.57403564453125\n",
      "Train_AverageEpLen : 85.63247863247864\n",
      "Train_EnvstepsSoFar : 190557\n",
      "TimeSinceStart : 127.53075075149536\n",
      "Training Loss : 136.0803985595703\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10073 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.078125\n",
      "Eval_StdReturn : 1.851879358291626\n",
      "Eval_MaxReturn : 176.1124267578125\n",
      "Eval_MinReturn : 168.40567016601562\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 171.71722412109375\n",
      "Train_StdReturn : 2.384735107421875\n",
      "Train_MaxReturn : 179.33595275878906\n",
      "Train_MinReturn : 165.04449462890625\n",
      "Train_AverageEpLen : 85.36440677966101\n",
      "Train_EnvstepsSoFar : 200630\n",
      "TimeSinceStart : 133.71316981315613\n",
      "Training Loss : 136.85043334960938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10076 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.2724151611328\n",
      "Eval_StdReturn : 2.047478199005127\n",
      "Eval_MaxReturn : 176.52919006347656\n",
      "Eval_MinReturn : 168.65042114257812\n",
      "Eval_AverageEpLen : 84.83333333333333\n",
      "Train_AverageReturn : 171.27932739257812\n",
      "Train_StdReturn : 2.5581421852111816\n",
      "Train_MaxReturn : 184.23439025878906\n",
      "Train_MinReturn : 164.2061767578125\n",
      "Train_AverageEpLen : 85.38983050847457\n",
      "Train_EnvstepsSoFar : 210706\n",
      "TimeSinceStart : 139.7904121875763\n",
      "Training Loss : 136.18263244628906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.31903076171875\n",
      "Eval_StdReturn : 4.4017558097839355\n",
      "Eval_MaxReturn : 184.0375213623047\n",
      "Eval_MinReturn : 170.14085388183594\n",
      "Eval_AverageEpLen : 84.08333333333333\n",
      "Train_AverageReturn : 172.62826538085938\n",
      "Train_StdReturn : 2.5981056690216064\n",
      "Train_MaxReturn : 183.02586364746094\n",
      "Train_MinReturn : 166.1747283935547\n",
      "Train_AverageEpLen : 84.89830508474576\n",
      "Train_EnvstepsSoFar : 220724\n",
      "TimeSinceStart : 145.48712682724\n",
      "Training Loss : 138.13282775878906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10031 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.11978149414062\n",
      "Eval_StdReturn : 10.818584442138672\n",
      "Eval_MaxReturn : 180.45472717285156\n",
      "Eval_MinReturn : 142.94126892089844\n",
      "Eval_AverageEpLen : 82.3076923076923\n",
      "Train_AverageReturn : 172.62208557128906\n",
      "Train_StdReturn : 5.2797369956970215\n",
      "Train_MaxReturn : 181.36083984375\n",
      "Train_MinReturn : 133.9557342529297\n",
      "Train_AverageEpLen : 84.29411764705883\n",
      "Train_EnvstepsSoFar : 230755\n",
      "TimeSinceStart : 151.24414730072021\n",
      "Training Loss : 138.57778930664062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.16969299316406\n",
      "Eval_StdReturn : 5.921075344085693\n",
      "Eval_MaxReturn : 182.56260681152344\n",
      "Eval_MinReturn : 162.28440856933594\n",
      "Eval_AverageEpLen : 83.83333333333333\n",
      "Train_AverageReturn : 173.77947998046875\n",
      "Train_StdReturn : 3.683394432067871\n",
      "Train_MaxReturn : 189.2088623046875\n",
      "Train_MinReturn : 157.828125\n",
      "Train_AverageEpLen : 84.10924369747899\n",
      "Train_EnvstepsSoFar : 240764\n",
      "TimeSinceStart : 156.95485305786133\n",
      "Training Loss : 140.1273956298828\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 24 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 176.23370361328125\n",
      "Eval_StdReturn : 4.571224689483643\n",
      "Eval_MaxReturn : 184.5778045654297\n",
      "Eval_MinReturn : 168.44561767578125\n",
      "Eval_AverageEpLen : 83.83333333333333\n",
      "Train_AverageReturn : 174.314697265625\n",
      "Train_StdReturn : 5.413726806640625\n",
      "Train_MaxReturn : 193.98126220703125\n",
      "Train_MinReturn : 143.41078186035156\n",
      "Train_AverageEpLen : 83.8\n",
      "Train_EnvstepsSoFar : 250820\n",
      "TimeSinceStart : 162.6527283191681\n",
      "Training Loss : 141.62887573242188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 25 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 175.05604553222656\n",
      "Eval_StdReturn : 3.9347665309906006\n",
      "Eval_MaxReturn : 182.59800720214844\n",
      "Eval_MinReturn : 169.84426879882812\n",
      "Eval_AverageEpLen : 83.91666666666667\n",
      "Train_AverageReturn : 174.5734100341797\n",
      "Train_StdReturn : 4.246496677398682\n",
      "Train_MaxReturn : 184.93116760253906\n",
      "Train_MinReturn : 159.2462615966797\n",
      "Train_AverageEpLen : 83.64166666666667\n",
      "Train_EnvstepsSoFar : 260857\n",
      "TimeSinceStart : 168.76818466186523\n",
      "Training Loss : 141.39056396484375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 26 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10046 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.50196838378906\n",
      "Eval_StdReturn : 4.867890357971191\n",
      "Eval_MaxReturn : 184.22695922851562\n",
      "Eval_MinReturn : 162.0403594970703\n",
      "Eval_AverageEpLen : 83.0\n",
      "Train_AverageReturn : 175.79405212402344\n",
      "Train_StdReturn : 4.421894550323486\n",
      "Train_MaxReturn : 191.537109375\n",
      "Train_MinReturn : 162.0035400390625\n",
      "Train_AverageEpLen : 83.71666666666667\n",
      "Train_EnvstepsSoFar : 270903\n",
      "TimeSinceStart : 175.12803077697754\n",
      "Training Loss : 143.08421325683594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 27 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.84584045410156\n",
      "Eval_StdReturn : 7.180642604827881\n",
      "Eval_MaxReturn : 179.04559326171875\n",
      "Eval_MinReturn : 150.74462890625\n",
      "Eval_AverageEpLen : 81.84615384615384\n",
      "Train_AverageReturn : 174.59588623046875\n",
      "Train_StdReturn : 6.832632064819336\n",
      "Train_MaxReturn : 187.01058959960938\n",
      "Train_MinReturn : 127.88420867919922\n",
      "Train_AverageEpLen : 83.53333333333333\n",
      "Train_EnvstepsSoFar : 280927\n",
      "TimeSinceStart : 181.36724257469177\n",
      "Training Loss : 141.56048583984375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 28 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.4746856689453\n",
      "Eval_StdReturn : 4.711119174957275\n",
      "Eval_MaxReturn : 182.10618591308594\n",
      "Eval_MinReturn : 165.59425354003906\n",
      "Eval_AverageEpLen : 83.23076923076923\n",
      "Train_AverageReturn : 172.5487823486328\n",
      "Train_StdReturn : 12.751303672790527\n",
      "Train_MaxReturn : 193.38938903808594\n",
      "Train_MinReturn : 74.64309692382812\n",
      "Train_AverageEpLen : 82.72727272727273\n",
      "Train_EnvstepsSoFar : 290937\n",
      "TimeSinceStart : 187.36311531066895\n",
      "Training Loss : 140.44415283203125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 29 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10050 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 172.93943786621094\n",
      "Eval_StdReturn : 4.310829162597656\n",
      "Eval_MaxReturn : 183.156494140625\n",
      "Eval_MinReturn : 168.32638549804688\n",
      "Eval_AverageEpLen : 84.25\n",
      "Train_AverageReturn : 174.44288635253906\n",
      "Train_StdReturn : 4.790919780731201\n",
      "Train_MaxReturn : 194.59112548828125\n",
      "Train_MinReturn : 165.80224609375\n",
      "Train_AverageEpLen : 83.75\n",
      "Train_EnvstepsSoFar : 300987\n",
      "TimeSinceStart : 193.27979588508606\n",
      "Training Loss : 140.59274291992188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 30 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10074 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.9123077392578\n",
      "Eval_StdReturn : 4.67802095413208\n",
      "Eval_MaxReturn : 179.45046997070312\n",
      "Eval_MinReturn : 158.42755126953125\n",
      "Eval_AverageEpLen : 84.41666666666667\n",
      "Train_AverageReturn : 171.68746948242188\n",
      "Train_StdReturn : 4.524069786071777\n",
      "Train_MaxReturn : 191.02947998046875\n",
      "Train_MinReturn : 161.20635986328125\n",
      "Train_AverageEpLen : 83.95\n",
      "Train_EnvstepsSoFar : 311061\n",
      "TimeSinceStart : 199.34025740623474\n",
      "Training Loss : 137.97940063476562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 31 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.5366973876953\n",
      "Eval_StdReturn : 5.268719673156738\n",
      "Eval_MaxReturn : 175.1169891357422\n",
      "Eval_MinReturn : 154.613037109375\n",
      "Eval_AverageEpLen : 84.0\n",
      "Train_AverageReturn : 169.06668090820312\n",
      "Train_StdReturn : 4.133042812347412\n",
      "Train_MaxReturn : 181.92324829101562\n",
      "Train_MinReturn : 156.50836181640625\n",
      "Train_AverageEpLen : 84.38655462184875\n",
      "Train_EnvstepsSoFar : 321103\n",
      "TimeSinceStart : 205.29496216773987\n",
      "Training Loss : 133.96578979492188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 32 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10048 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 155.45033264160156\n",
      "Eval_StdReturn : 13.994037628173828\n",
      "Eval_MaxReturn : 166.685302734375\n",
      "Eval_MinReturn : 123.7869873046875\n",
      "Eval_AverageEpLen : 82.15384615384616\n",
      "Train_AverageReturn : 165.47073364257812\n",
      "Train_StdReturn : 5.150859355926514\n",
      "Train_MaxReturn : 182.98780822753906\n",
      "Train_MinReturn : 147.44834899902344\n",
      "Train_AverageEpLen : 84.43697478991596\n",
      "Train_EnvstepsSoFar : 331151\n",
      "TimeSinceStart : 211.48447060585022\n",
      "Training Loss : 130.3938446044922\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 33 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 149.2161102294922\n",
      "Eval_StdReturn : 18.874473571777344\n",
      "Eval_MaxReturn : 166.43482971191406\n",
      "Eval_MinReturn : 114.08534240722656\n",
      "Eval_AverageEpLen : 79.84615384615384\n",
      "Train_AverageReturn : 159.65867614746094\n",
      "Train_StdReturn : 10.399297714233398\n",
      "Train_MaxReturn : 172.1394500732422\n",
      "Train_MinReturn : 113.56718444824219\n",
      "Train_AverageEpLen : 83.49166666666666\n",
      "Train_EnvstepsSoFar : 341170\n",
      "TimeSinceStart : 217.67667150497437\n",
      "Training Loss : 126.58599853515625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 34 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 165.1236572265625\n",
      "Eval_StdReturn : 2.1303648948669434\n",
      "Eval_MaxReturn : 169.87600708007812\n",
      "Eval_MinReturn : 160.4990234375\n",
      "Eval_AverageEpLen : 85.83333333333333\n",
      "Train_AverageReturn : 155.0398406982422\n",
      "Train_StdReturn : 15.006380081176758\n",
      "Train_MaxReturn : 173.50613403320312\n",
      "Train_MinReturn : 107.71051788330078\n",
      "Train_AverageEpLen : 82.02459016393442\n",
      "Train_EnvstepsSoFar : 351177\n",
      "TimeSinceStart : 224.05552124977112\n",
      "Training Loss : 123.97281646728516\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 35 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10059 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 165.87574768066406\n",
      "Eval_StdReturn : 3.442974328994751\n",
      "Eval_MaxReturn : 170.14089965820312\n",
      "Eval_MinReturn : 158.1830596923828\n",
      "Eval_AverageEpLen : 85.58333333333333\n",
      "Train_AverageReturn : 161.67701721191406\n",
      "Train_StdReturn : 7.322292804718018\n",
      "Train_MaxReturn : 168.98922729492188\n",
      "Train_MinReturn : 118.5385513305664\n",
      "Train_AverageEpLen : 84.52941176470588\n",
      "Train_EnvstepsSoFar : 361236\n",
      "TimeSinceStart : 229.92177414894104\n",
      "Training Loss : 126.46966552734375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 36 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.2953643798828\n",
      "Eval_StdReturn : 2.4557461738586426\n",
      "Eval_MaxReturn : 171.89984130859375\n",
      "Eval_MinReturn : 164.3763427734375\n",
      "Eval_AverageEpLen : 85.66666666666667\n",
      "Train_AverageReturn : 165.75624084472656\n",
      "Train_StdReturn : 2.8281915187835693\n",
      "Train_MaxReturn : 173.44125366210938\n",
      "Train_MinReturn : 154.62176513671875\n",
      "Train_AverageEpLen : 85.54700854700855\n",
      "Train_EnvstepsSoFar : 371245\n",
      "TimeSinceStart : 236.0226809978485\n",
      "Training Loss : 129.23744201660156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 37 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 160.77365112304688\n",
      "Eval_StdReturn : 25.292034149169922\n",
      "Eval_MaxReturn : 172.47085571289062\n",
      "Eval_MinReturn : 77.87059783935547\n",
      "Eval_AverageEpLen : 81.53846153846153\n",
      "Train_AverageReturn : 166.31919860839844\n",
      "Train_StdReturn : 14.8051118850708\n",
      "Train_MaxReturn : 175.0335235595703\n",
      "Train_MinReturn : 63.699546813964844\n",
      "Train_AverageEpLen : 84.60504201680672\n",
      "Train_EnvstepsSoFar : 381313\n",
      "TimeSinceStart : 242.08310747146606\n",
      "Training Loss : 130.58851623535156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 38 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 160.91908264160156\n",
      "Eval_StdReturn : 18.113914489746094\n",
      "Eval_MaxReturn : 173.14987182617188\n",
      "Eval_MinReturn : 102.43212890625\n",
      "Eval_AverageEpLen : 81.84615384615384\n",
      "Train_AverageReturn : 165.2772979736328\n",
      "Train_StdReturn : 16.942142486572266\n",
      "Train_MaxReturn : 175.73379516601562\n",
      "Train_MinReturn : 73.80748748779297\n",
      "Train_AverageEpLen : 83.5\n",
      "Train_EnvstepsSoFar : 391333\n",
      "TimeSinceStart : 247.91856503486633\n",
      "Training Loss : 131.2700653076172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 39 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10046 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 164.62188720703125\n",
      "Eval_StdReturn : 7.993289947509766\n",
      "Eval_MaxReturn : 172.2653045654297\n",
      "Eval_MinReturn : 150.0310821533203\n",
      "Eval_AverageEpLen : 83.66666666666667\n",
      "Train_AverageReturn : 164.36953735351562\n",
      "Train_StdReturn : 15.232812881469727\n",
      "Train_MaxReturn : 175.33938598632812\n",
      "Train_MinReturn : 78.73287963867188\n",
      "Train_AverageEpLen : 83.02479338842976\n",
      "Train_EnvstepsSoFar : 401379\n",
      "TimeSinceStart : 253.88788652420044\n",
      "Training Loss : 131.24526977539062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 40 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10041 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.06317138671875\n",
      "Eval_StdReturn : 5.497228145599365\n",
      "Eval_MaxReturn : 173.75514221191406\n",
      "Eval_MinReturn : 151.63919067382812\n",
      "Eval_AverageEpLen : 85.0\n",
      "Train_AverageReturn : 166.3015899658203\n",
      "Train_StdReturn : 13.968279838562012\n",
      "Train_MaxReturn : 175.7161865234375\n",
      "Train_MinReturn : 77.99628448486328\n",
      "Train_AverageEpLen : 83.675\n",
      "Train_EnvstepsSoFar : 411420\n",
      "TimeSinceStart : 259.799516916275\n",
      "Training Loss : 132.22244262695312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 41 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.69981384277344\n",
      "Eval_StdReturn : 2.650357961654663\n",
      "Eval_MaxReturn : 172.44508361816406\n",
      "Eval_MinReturn : 164.7491912841797\n",
      "Eval_AverageEpLen : 85.41666666666667\n",
      "Train_AverageReturn : 169.64944458007812\n",
      "Train_StdReturn : 3.9854822158813477\n",
      "Train_MaxReturn : 175.3260955810547\n",
      "Train_MinReturn : 139.8365020751953\n",
      "Train_AverageEpLen : 85.5042735042735\n",
      "Train_EnvstepsSoFar : 421424\n",
      "TimeSinceStart : 265.4816155433655\n",
      "Training Loss : 132.64649963378906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 42 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.97633361816406\n",
      "Eval_StdReturn : 2.3719370365142822\n",
      "Eval_MaxReturn : 173.35931396484375\n",
      "Eval_MinReturn : 165.25439453125\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 169.27203369140625\n",
      "Train_StdReturn : 4.4461259841918945\n",
      "Train_MaxReturn : 175.8317413330078\n",
      "Train_MinReturn : 127.15202331542969\n",
      "Train_AverageEpLen : 85.47008547008546\n",
      "Train_EnvstepsSoFar : 431424\n",
      "TimeSinceStart : 271.1099965572357\n",
      "Training Loss : 132.20327758789062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 43 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.38856506347656\n",
      "Eval_StdReturn : 2.079942226409912\n",
      "Eval_MaxReturn : 172.65771484375\n",
      "Eval_MinReturn : 165.43704223632812\n",
      "Eval_AverageEpLen : 85.5\n",
      "Train_AverageReturn : 169.56085205078125\n",
      "Train_StdReturn : 2.1755259037017822\n",
      "Train_MaxReturn : 175.40264892578125\n",
      "Train_MinReturn : 165.31336975097656\n",
      "Train_AverageEpLen : 85.55555555555556\n",
      "Train_EnvstepsSoFar : 441434\n",
      "TimeSinceStart : 276.8269407749176\n",
      "Training Loss : 132.36561584472656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 44 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.8133544921875\n",
      "Eval_StdReturn : 2.246948719024658\n",
      "Eval_MaxReturn : 172.68739318847656\n",
      "Eval_MinReturn : 162.7985382080078\n",
      "Eval_AverageEpLen : 85.16666666666667\n",
      "Train_AverageReturn : 169.54421997070312\n",
      "Train_StdReturn : 2.1260344982147217\n",
      "Train_MaxReturn : 174.8813934326172\n",
      "Train_MinReturn : 164.3472442626953\n",
      "Train_AverageEpLen : 85.52136752136752\n",
      "Train_EnvstepsSoFar : 451440\n",
      "TimeSinceStart : 282.54965019226074\n",
      "Training Loss : 132.712158203125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 45 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.28504943847656\n",
      "Eval_StdReturn : 1.7982536554336548\n",
      "Eval_MaxReturn : 171.34471130371094\n",
      "Eval_MinReturn : 165.7229461669922\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 168.7161865234375\n",
      "Train_StdReturn : 5.584586143493652\n",
      "Train_MaxReturn : 175.221435546875\n",
      "Train_MinReturn : 113.51527404785156\n",
      "Train_AverageEpLen : 85.27966101694915\n",
      "Train_EnvstepsSoFar : 461503\n",
      "TimeSinceStart : 288.19084882736206\n",
      "Training Loss : 132.18809509277344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 46 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10073 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.3614959716797\n",
      "Eval_StdReturn : 2.053342819213867\n",
      "Eval_MaxReturn : 173.20541381835938\n",
      "Eval_MinReturn : 166.34506225585938\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 168.85813903808594\n",
      "Train_StdReturn : 2.1813530921936035\n",
      "Train_MaxReturn : 173.278564453125\n",
      "Train_MinReturn : 160.50563049316406\n",
      "Train_AverageEpLen : 85.36440677966101\n",
      "Train_EnvstepsSoFar : 471576\n",
      "TimeSinceStart : 293.8807427883148\n",
      "Training Loss : 132.20535278320312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 47 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10064 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.15013122558594\n",
      "Eval_StdReturn : 1.4246947765350342\n",
      "Eval_MaxReturn : 172.5282745361328\n",
      "Eval_MinReturn : 166.8134765625\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 169.46775817871094\n",
      "Train_StdReturn : 2.259680986404419\n",
      "Train_MaxReturn : 176.51841735839844\n",
      "Train_MinReturn : 163.6526641845703\n",
      "Train_AverageEpLen : 85.28813559322033\n",
      "Train_EnvstepsSoFar : 481640\n",
      "TimeSinceStart : 299.6253514289856\n",
      "Training Loss : 133.0677490234375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 48 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.11607360839844\n",
      "Eval_StdReturn : 5.202949047088623\n",
      "Eval_MaxReturn : 172.05715942382812\n",
      "Eval_MinReturn : 152.66357421875\n",
      "Eval_AverageEpLen : 84.58333333333333\n",
      "Train_AverageReturn : 169.13487243652344\n",
      "Train_StdReturn : 2.0514028072357178\n",
      "Train_MaxReturn : 174.78001403808594\n",
      "Train_MinReturn : 162.93374633789062\n",
      "Train_AverageEpLen : 85.27966101694915\n",
      "Train_EnvstepsSoFar : 491703\n",
      "TimeSinceStart : 305.2880392074585\n",
      "Training Loss : 132.37005615234375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 49 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10055 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.62969970703125\n",
      "Eval_StdReturn : 1.8558882474899292\n",
      "Eval_MaxReturn : 173.59359741210938\n",
      "Eval_MinReturn : 167.40231323242188\n",
      "Eval_AverageEpLen : 85.08333333333333\n",
      "Train_AverageReturn : 170.3358917236328\n",
      "Train_StdReturn : 2.198801279067993\n",
      "Train_MaxReturn : 176.76121520996094\n",
      "Train_MinReturn : 160.20777893066406\n",
      "Train_AverageEpLen : 85.21186440677967\n",
      "Train_EnvstepsSoFar : 501758\n",
      "TimeSinceStart : 310.93898820877075\n",
      "Training Loss : 133.38449096679688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10045 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 172.2799835205078\n",
      "Eval_StdReturn : 2.0565505027770996\n",
      "Eval_MaxReturn : 176.43190002441406\n",
      "Eval_MinReturn : 169.43487548828125\n",
      "Eval_AverageEpLen : 85.08333333333333\n",
      "Train_AverageReturn : 170.39862060546875\n",
      "Train_StdReturn : 1.9064778089523315\n",
      "Train_MaxReturn : 174.84548950195312\n",
      "Train_MinReturn : 166.35130310058594\n",
      "Train_AverageEpLen : 85.12711864406779\n",
      "Train_EnvstepsSoFar : 511803\n",
      "TimeSinceStart : 316.595730304718\n",
      "Training Loss : 134.22457885742188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.86862182617188\n",
      "Eval_StdReturn : 7.798384189605713\n",
      "Eval_MaxReturn : 177.48001098632812\n",
      "Eval_MinReturn : 146.2225341796875\n",
      "Eval_AverageEpLen : 83.38461538461539\n",
      "Train_AverageReturn : 171.09640502929688\n",
      "Train_StdReturn : 2.4032716751098633\n",
      "Train_MaxReturn : 176.4768829345703\n",
      "Train_MinReturn : 158.86500549316406\n",
      "Train_AverageEpLen : 84.99152542372882\n",
      "Train_EnvstepsSoFar : 521832\n",
      "TimeSinceStart : 322.3518850803375\n",
      "Training Loss : 134.63699340820312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10049 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 164.70938110351562\n",
      "Eval_StdReturn : 10.90107250213623\n",
      "Eval_MaxReturn : 173.50132751464844\n",
      "Eval_MinReturn : 136.74090576171875\n",
      "Eval_AverageEpLen : 82.0\n",
      "Train_AverageReturn : 169.4009552001953\n",
      "Train_StdReturn : 5.486394882202148\n",
      "Train_MaxReturn : 175.7725067138672\n",
      "Train_MinReturn : 148.21165466308594\n",
      "Train_AverageEpLen : 83.74166666666666\n",
      "Train_EnvstepsSoFar : 531881\n",
      "TimeSinceStart : 328.1523883342743\n",
      "Training Loss : 134.69497680664062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 155.63426208496094\n",
      "Eval_StdReturn : 14.14038372039795\n",
      "Eval_MaxReturn : 174.63690185546875\n",
      "Eval_MinReturn : 131.00877380371094\n",
      "Eval_AverageEpLen : 78.38461538461539\n",
      "Train_AverageReturn : 161.47032165527344\n",
      "Train_StdReturn : 13.626359939575195\n",
      "Train_MaxReturn : 239.2991943359375\n",
      "Train_MinReturn : 126.91974639892578\n",
      "Train_AverageEpLen : 80.504\n",
      "Train_EnvstepsSoFar : 541944\n",
      "TimeSinceStart : 333.8193063735962\n",
      "Training Loss : 132.03009033203125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 152.18423461914062\n",
      "Eval_StdReturn : 14.867368698120117\n",
      "Eval_MaxReturn : 176.56077575683594\n",
      "Eval_MinReturn : 122.36766052246094\n",
      "Eval_AverageEpLen : 77.23076923076923\n",
      "Train_AverageReturn : 158.76869201660156\n",
      "Train_StdReturn : 14.523828506469727\n",
      "Train_MaxReturn : 176.31600952148438\n",
      "Train_MinReturn : 60.62776565551758\n",
      "Train_AverageEpLen : 79.39682539682539\n",
      "Train_EnvstepsSoFar : 551948\n",
      "TimeSinceStart : 339.53185653686523\n",
      "Training Loss : 131.46835327148438\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10064 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 161.41163635253906\n",
      "Eval_StdReturn : 9.27861213684082\n",
      "Eval_MaxReturn : 177.4961700439453\n",
      "Eval_MinReturn : 148.83218383789062\n",
      "Eval_AverageEpLen : 79.92307692307692\n",
      "Train_AverageReturn : 154.95309448242188\n",
      "Train_StdReturn : 13.434354782104492\n",
      "Train_MaxReturn : 199.38650512695312\n",
      "Train_MinReturn : 111.76173400878906\n",
      "Train_AverageEpLen : 78.01550387596899\n",
      "Train_EnvstepsSoFar : 562012\n",
      "TimeSinceStart : 345.2471206188202\n",
      "Training Loss : 129.65740966796875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 163.88970947265625\n",
      "Eval_StdReturn : 13.529715538024902\n",
      "Eval_MaxReturn : 193.13404846191406\n",
      "Eval_MinReturn : 140.4620361328125\n",
      "Eval_AverageEpLen : 82.38461538461539\n",
      "Train_AverageReturn : 157.9945068359375\n",
      "Train_StdReturn : 15.705986976623535\n",
      "Train_MaxReturn : 186.649658203125\n",
      "Train_MinReturn : 62.86819076538086\n",
      "Train_AverageEpLen : 79.02362204724409\n",
      "Train_EnvstepsSoFar : 572048\n",
      "TimeSinceStart : 350.960631608963\n",
      "Training Loss : 129.8374786376953\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10017 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 159.9091033935547\n",
      "Eval_StdReturn : 25.460113525390625\n",
      "Eval_MaxReturn : 174.99928283691406\n",
      "Eval_MinReturn : 76.00358581542969\n",
      "Eval_AverageEpLen : 79.92307692307692\n",
      "Train_AverageReturn : 162.9720001220703\n",
      "Train_StdReturn : 11.115151405334473\n",
      "Train_MaxReturn : 180.0061492919922\n",
      "Train_MinReturn : 129.19873046875\n",
      "Train_AverageEpLen : 80.78225806451613\n",
      "Train_EnvstepsSoFar : 582065\n",
      "TimeSinceStart : 356.7977764606476\n",
      "Training Loss : 133.13279724121094\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10027 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 162.57398986816406\n",
      "Eval_StdReturn : 30.36417007446289\n",
      "Eval_MaxReturn : 185.3849334716797\n",
      "Eval_MinReturn : 61.792266845703125\n",
      "Eval_AverageEpLen : 80.3076923076923\n",
      "Train_AverageReturn : 170.75576782226562\n",
      "Train_StdReturn : 19.658706665039062\n",
      "Train_MaxReturn : 249.2590789794922\n",
      "Train_MinReturn : 66.08201599121094\n",
      "Train_AverageEpLen : 83.55833333333334\n",
      "Train_EnvstepsSoFar : 592092\n",
      "TimeSinceStart : 362.44121384620667\n",
      "Training Loss : 136.01971435546875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.5216522216797\n",
      "Eval_StdReturn : 4.480551242828369\n",
      "Eval_MaxReturn : 178.55441284179688\n",
      "Eval_MinReturn : 161.24310302734375\n",
      "Eval_AverageEpLen : 84.0\n",
      "Train_AverageReturn : 168.14083862304688\n",
      "Train_StdReturn : 29.32646942138672\n",
      "Train_MaxReturn : 287.81317138671875\n",
      "Train_MinReturn : 53.04377746582031\n",
      "Train_AverageEpLen : 82.09016393442623\n",
      "Train_EnvstepsSoFar : 602107\n",
      "TimeSinceStart : 368.10301995277405\n",
      "Training Loss : 136.02169799804688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10060 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 175.78619384765625\n",
      "Eval_StdReturn : 2.6926252841949463\n",
      "Eval_MaxReturn : 181.8583984375\n",
      "Eval_MinReturn : 172.85760498046875\n",
      "Eval_AverageEpLen : 84.16666666666667\n",
      "Train_AverageReturn : 174.18675231933594\n",
      "Train_StdReturn : 23.864290237426758\n",
      "Train_MaxReturn : 289.1669921875\n",
      "Train_MinReturn : 64.8857650756836\n",
      "Train_AverageEpLen : 84.53781512605042\n",
      "Train_EnvstepsSoFar : 612167\n",
      "TimeSinceStart : 373.70632100105286\n",
      "Training Loss : 138.0719451904297\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.25588989257812\n",
      "Eval_StdReturn : 28.235309600830078\n",
      "Eval_MaxReturn : 177.65345764160156\n",
      "Eval_MinReturn : 69.6171646118164\n",
      "Eval_AverageEpLen : 80.23076923076923\n",
      "Train_AverageReturn : 173.99269104003906\n",
      "Train_StdReturn : 17.1213321685791\n",
      "Train_MaxReturn : 225.3726806640625\n",
      "Train_MinReturn : 69.9136962890625\n",
      "Train_AverageEpLen : 83.88333333333334\n",
      "Train_EnvstepsSoFar : 622233\n",
      "TimeSinceStart : 379.57967734336853\n",
      "Training Loss : 138.4528350830078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 175.9845733642578\n",
      "Eval_StdReturn : 3.16841983795166\n",
      "Eval_MaxReturn : 183.59217834472656\n",
      "Eval_MinReturn : 171.4659423828125\n",
      "Eval_AverageEpLen : 83.41666666666667\n",
      "Train_AverageReturn : 175.37237548828125\n",
      "Train_StdReturn : 13.456055641174316\n",
      "Train_MaxReturn : 280.66259765625\n",
      "Train_MinReturn : 80.67457580566406\n",
      "Train_AverageEpLen : 84.10084033613445\n",
      "Train_EnvstepsSoFar : 632241\n",
      "TimeSinceStart : 385.23959517478943\n",
      "Training Loss : 140.2495574951172\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 162.75816345214844\n",
      "Eval_StdReturn : 39.79380416870117\n",
      "Eval_MaxReturn : 178.9059600830078\n",
      "Eval_MinReturn : 25.120750427246094\n",
      "Eval_AverageEpLen : 78.92307692307692\n",
      "Train_AverageReturn : 168.77276611328125\n",
      "Train_StdReturn : 25.172239303588867\n",
      "Train_MaxReturn : 190.9952850341797\n",
      "Train_MinReturn : 66.29108428955078\n",
      "Train_AverageEpLen : 81.79674796747967\n",
      "Train_EnvstepsSoFar : 642302\n",
      "TimeSinceStart : 390.925546169281\n",
      "Training Loss : 137.36097717285156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10050 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 84.51592254638672\n",
      "Eval_StdReturn : 74.18576049804688\n",
      "Eval_MaxReturn : 176.49917602539062\n",
      "Eval_MinReturn : 18.586973190307617\n",
      "Eval_AverageEpLen : 44.333333333333336\n",
      "Train_AverageReturn : 165.6236572265625\n",
      "Train_StdReturn : 32.86145782470703\n",
      "Train_MaxReturn : 217.22372436523438\n",
      "Train_MinReturn : 19.917266845703125\n",
      "Train_AverageEpLen : 81.04838709677419\n",
      "Train_EnvstepsSoFar : 652352\n",
      "TimeSinceStart : 396.7267780303955\n",
      "Training Loss : 136.2914581298828\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 84.88462829589844\n",
      "Eval_StdReturn : 72.48085021972656\n",
      "Eval_MaxReturn : 173.8159942626953\n",
      "Eval_MinReturn : 16.505802154541016\n",
      "Eval_AverageEpLen : 45.041666666666664\n",
      "Train_AverageReturn : 95.7093734741211\n",
      "Train_StdReturn : 74.58486938476562\n",
      "Train_MaxReturn : 208.94778442382812\n",
      "Train_MinReturn : 18.316686630249023\n",
      "Train_AverageEpLen : 49.539603960396036\n",
      "Train_EnvstepsSoFar : 662359\n",
      "TimeSinceStart : 402.42799043655396\n",
      "Training Loss : 120.53871154785156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 123.9310302734375\n",
      "Eval_StdReturn : 68.45992279052734\n",
      "Eval_MaxReturn : 173.3714599609375\n",
      "Eval_MinReturn : 20.94069480895996\n",
      "Eval_AverageEpLen : 63.375\n",
      "Train_AverageReturn : 69.76397705078125\n",
      "Train_StdReturn : 70.1481704711914\n",
      "Train_MaxReturn : 183.1931610107422\n",
      "Train_MinReturn : 16.4043025970459\n",
      "Train_AverageEpLen : 37.739622641509435\n",
      "Train_EnvstepsSoFar : 672360\n",
      "TimeSinceStart : 408.31191992759705\n",
      "Training Loss : 109.79457092285156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.9467010498047\n",
      "Eval_StdReturn : 3.6755733489990234\n",
      "Eval_MaxReturn : 172.79705810546875\n",
      "Eval_MinReturn : 159.7516632080078\n",
      "Eval_AverageEpLen : 83.92307692307692\n",
      "Train_AverageReturn : 118.8699722290039\n",
      "Train_StdReturn : 70.1457748413086\n",
      "Train_MaxReturn : 183.26084899902344\n",
      "Train_MinReturn : 16.738380432128906\n",
      "Train_AverageEpLen : 60.63855421686747\n",
      "Train_EnvstepsSoFar : 682426\n",
      "TimeSinceStart : 414.29371547698975\n",
      "Training Loss : 126.49459075927734\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 157.11434936523438\n",
      "Eval_StdReturn : 40.99954605102539\n",
      "Eval_MaxReturn : 178.12535095214844\n",
      "Eval_MinReturn : 16.287506103515625\n",
      "Eval_AverageEpLen : 77.46153846153847\n",
      "Train_AverageReturn : 159.92654418945312\n",
      "Train_StdReturn : 37.018348693847656\n",
      "Train_MaxReturn : 187.44700622558594\n",
      "Train_MinReturn : 11.76245403289795\n",
      "Train_AverageEpLen : 79.25984251968504\n",
      "Train_EnvstepsSoFar : 692492\n",
      "TimeSinceStart : 419.96515583992004\n",
      "Training Loss : 133.48629760742188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 150.9308624267578\n",
      "Eval_StdReturn : 55.273433685302734\n",
      "Eval_MaxReturn : 187.31468200683594\n",
      "Eval_MinReturn : 15.04283618927002\n",
      "Eval_AverageEpLen : 73.78571428571429\n",
      "Train_AverageReturn : 151.02212524414062\n",
      "Train_StdReturn : 49.44624328613281\n",
      "Train_MaxReturn : 194.89402770996094\n",
      "Train_MinReturn : 11.065784454345703\n",
      "Train_AverageEpLen : 75.09701492537313\n",
      "Train_EnvstepsSoFar : 702555\n",
      "TimeSinceStart : 425.6307444572449\n",
      "Training Loss : 133.59408569335938\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 114.18919372558594\n",
      "Eval_StdReturn : 78.34744262695312\n",
      "Eval_MaxReturn : 197.31944274902344\n",
      "Eval_MinReturn : 14.582315444946289\n",
      "Eval_AverageEpLen : 57.77777777777778\n",
      "Train_AverageReturn : 137.9264678955078\n",
      "Train_StdReturn : 65.90470886230469\n",
      "Train_MaxReturn : 199.08688354492188\n",
      "Train_MinReturn : 13.267868995666504\n",
      "Train_AverageEpLen : 68.02702702702703\n",
      "Train_EnvstepsSoFar : 712623\n",
      "TimeSinceStart : 431.38328075408936\n",
      "Training Loss : 134.15049743652344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 162.18157958984375\n",
      "Eval_StdReturn : 48.08872985839844\n",
      "Eval_MaxReturn : 201.3494873046875\n",
      "Eval_MinReturn : 21.430007934570312\n",
      "Eval_AverageEpLen : 77.61538461538461\n",
      "Train_AverageReturn : 133.98207092285156\n",
      "Train_StdReturn : 73.61038970947266\n",
      "Train_MaxReturn : 207.6295623779297\n",
      "Train_MinReturn : 9.883172035217285\n",
      "Train_AverageEpLen : 65.47712418300654\n",
      "Train_EnvstepsSoFar : 722641\n",
      "TimeSinceStart : 437.1372582912445\n",
      "Training Loss : 136.34353637695312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 150.63894653320312\n",
      "Eval_StdReturn : 67.17387390136719\n",
      "Eval_MaxReturn : 205.39698791503906\n",
      "Eval_MinReturn : 13.360664367675781\n",
      "Eval_AverageEpLen : 71.78571428571429\n",
      "Train_AverageReturn : 141.96255493164062\n",
      "Train_StdReturn : 69.17623901367188\n",
      "Train_MaxReturn : 207.06080627441406\n",
      "Train_MinReturn : 12.263286590576172\n",
      "Train_AverageEpLen : 68.66438356164383\n",
      "Train_EnvstepsSoFar : 732666\n",
      "TimeSinceStart : 442.8920464515686\n",
      "Training Loss : 138.36209106445312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 177.48435974121094\n",
      "Eval_StdReturn : 11.034379005432129\n",
      "Eval_MaxReturn : 196.7305908203125\n",
      "Eval_MinReturn : 155.91522216796875\n",
      "Eval_AverageEpLen : 84.33333333333333\n",
      "Train_AverageReturn : 172.47769165039062\n",
      "Train_StdReturn : 42.335208892822266\n",
      "Train_MaxReturn : 207.38108825683594\n",
      "Train_MinReturn : 15.787713050842285\n",
      "Train_AverageEpLen : 81.39837398373983\n",
      "Train_EnvstepsSoFar : 742678\n",
      "TimeSinceStart : 448.5580081939697\n",
      "Training Loss : 144.5662384033203\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.51393127441406\n",
      "Eval_StdReturn : 13.293137550354004\n",
      "Eval_MaxReturn : 212.7675018310547\n",
      "Eval_MinReturn : 168.26673889160156\n",
      "Eval_AverageEpLen : 86.5\n",
      "Train_AverageReturn : 179.44874572753906\n",
      "Train_StdReturn : 23.67145538330078\n",
      "Train_MaxReturn : 212.54360961914062\n",
      "Train_MinReturn : 32.26323699951172\n",
      "Train_AverageEpLen : 84.56302521008404\n",
      "Train_EnvstepsSoFar : 752741\n",
      "TimeSinceStart : 454.27926111221313\n",
      "Training Loss : 144.99386596679688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 179.32334899902344\n",
      "Eval_StdReturn : 8.2662992477417\n",
      "Eval_MaxReturn : 192.389404296875\n",
      "Eval_MinReturn : 167.04823303222656\n",
      "Eval_AverageEpLen : 88.25\n",
      "Train_AverageReturn : 176.62808227539062\n",
      "Train_StdReturn : 18.762893676757812\n",
      "Train_MaxReturn : 210.2182159423828\n",
      "Train_MinReturn : 32.886199951171875\n",
      "Train_AverageEpLen : 85.45762711864407\n",
      "Train_EnvstepsSoFar : 762825\n",
      "TimeSinceStart : 460.0183308124542\n",
      "Training Loss : 140.59498596191406\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 178.572265625\n",
      "Eval_StdReturn : 5.237421989440918\n",
      "Eval_MaxReturn : 186.048828125\n",
      "Eval_MinReturn : 168.5174560546875\n",
      "Eval_AverageEpLen : 87.25\n",
      "Train_AverageReturn : 178.01779174804688\n",
      "Train_StdReturn : 10.829992294311523\n",
      "Train_MaxReturn : 213.0257568359375\n",
      "Train_MinReturn : 160.49269104003906\n",
      "Train_AverageEpLen : 86.21551724137932\n",
      "Train_EnvstepsSoFar : 772826\n",
      "TimeSinceStart : 465.68307304382324\n",
      "Training Loss : 139.80947875976562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.2847137451172\n",
      "Eval_StdReturn : 8.048995971679688\n",
      "Eval_MaxReturn : 191.26454162597656\n",
      "Eval_MinReturn : 165.35679626464844\n",
      "Eval_AverageEpLen : 86.83333333333333\n",
      "Train_AverageReturn : 177.16615295410156\n",
      "Train_StdReturn : 9.592423439025879\n",
      "Train_MaxReturn : 206.35635375976562\n",
      "Train_MinReturn : 162.38723754882812\n",
      "Train_AverageEpLen : 86.30172413793103\n",
      "Train_EnvstepsSoFar : 782837\n",
      "TimeSinceStart : 471.3869972229004\n",
      "Training Loss : 139.43528747558594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 177.3267059326172\n",
      "Eval_StdReturn : 8.581645965576172\n",
      "Eval_MaxReturn : 193.08529663085938\n",
      "Eval_MinReturn : 165.877197265625\n",
      "Eval_AverageEpLen : 85.66666666666667\n",
      "Train_AverageReturn : 175.09927368164062\n",
      "Train_StdReturn : 9.065170288085938\n",
      "Train_MaxReturn : 202.2394256591797\n",
      "Train_MinReturn : 158.9519805908203\n",
      "Train_AverageEpLen : 86.80172413793103\n",
      "Train_EnvstepsSoFar : 792906\n",
      "TimeSinceStart : 477.12299728393555\n",
      "Training Loss : 136.50958251953125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 176.5389404296875\n",
      "Eval_StdReturn : 17.769960403442383\n",
      "Eval_MaxReturn : 220.2903594970703\n",
      "Eval_MinReturn : 160.50363159179688\n",
      "Eval_AverageEpLen : 89.25\n",
      "Train_AverageReturn : 174.7278289794922\n",
      "Train_StdReturn : 11.74676513671875\n",
      "Train_MaxReturn : 239.12705993652344\n",
      "Train_MinReturn : 148.6160125732422\n",
      "Train_AverageEpLen : 86.88793103448276\n",
      "Train_EnvstepsSoFar : 802985\n",
      "TimeSinceStart : 482.8216550350189\n",
      "Training Loss : 136.0819854736328\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.06092834472656\n",
      "Eval_StdReturn : 6.671674728393555\n",
      "Eval_MaxReturn : 180.58091735839844\n",
      "Eval_MinReturn : 150.1975860595703\n",
      "Eval_AverageEpLen : 84.33333333333333\n",
      "Train_AverageReturn : 170.52066040039062\n",
      "Train_StdReturn : 9.415693283081055\n",
      "Train_MaxReturn : 194.64987182617188\n",
      "Train_MinReturn : 125.88101196289062\n",
      "Train_AverageEpLen : 86.61206896551724\n",
      "Train_EnvstepsSoFar : 813032\n",
      "TimeSinceStart : 488.54391837120056\n",
      "Training Loss : 132.528564453125\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.427978515625\n",
      "Eval_StdReturn : 5.094456195831299\n",
      "Eval_MaxReturn : 176.46629333496094\n",
      "Eval_MinReturn : 158.96629333496094\n",
      "Eval_AverageEpLen : 85.58333333333333\n",
      "Train_AverageReturn : 168.74014282226562\n",
      "Train_StdReturn : 11.728833198547363\n",
      "Train_MaxReturn : 214.34031677246094\n",
      "Train_MinReturn : 109.49378967285156\n",
      "Train_AverageEpLen : 86.75\n",
      "Train_EnvstepsSoFar : 823095\n",
      "TimeSinceStart : 494.3386437892914\n",
      "Training Loss : 130.50680541992188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 159.4279022216797\n",
      "Eval_StdReturn : 18.55144500732422\n",
      "Eval_MaxReturn : 175.2556915283203\n",
      "Eval_MinReturn : 116.17756652832031\n",
      "Eval_AverageEpLen : 83.58333333333333\n",
      "Train_AverageReturn : 168.58038330078125\n",
      "Train_StdReturn : 10.13805866241455\n",
      "Train_MaxReturn : 219.28831481933594\n",
      "Train_MinReturn : 136.11170959472656\n",
      "Train_AverageEpLen : 86.85344827586206\n",
      "Train_EnvstepsSoFar : 833170\n",
      "TimeSinceStart : 499.9242970943451\n",
      "Training Loss : 130.2653350830078\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 165.7614288330078\n",
      "Eval_StdReturn : 8.724007606506348\n",
      "Eval_MaxReturn : 178.4000244140625\n",
      "Eval_MinReturn : 142.36293029785156\n",
      "Eval_AverageEpLen : 87.58333333333333\n",
      "Train_AverageReturn : 164.54978942871094\n",
      "Train_StdReturn : 14.077279090881348\n",
      "Train_MaxReturn : 190.51661682128906\n",
      "Train_MinReturn : 87.75203704833984\n",
      "Train_AverageEpLen : 85.54700854700855\n",
      "Train_EnvstepsSoFar : 843179\n",
      "TimeSinceStart : 505.65341305732727\n",
      "Training Loss : 128.1779327392578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10059 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 165.72450256347656\n",
      "Eval_StdReturn : 8.529096603393555\n",
      "Eval_MaxReturn : 181.34429931640625\n",
      "Eval_MinReturn : 145.29638671875\n",
      "Eval_AverageEpLen : 85.33333333333333\n",
      "Train_AverageReturn : 168.42962646484375\n",
      "Train_StdReturn : 10.80667781829834\n",
      "Train_MaxReturn : 220.89122009277344\n",
      "Train_MinReturn : 135.10951232910156\n",
      "Train_AverageEpLen : 86.71551724137932\n",
      "Train_EnvstepsSoFar : 853238\n",
      "TimeSinceStart : 511.3644366264343\n",
      "Training Loss : 130.3617706298828\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.4767608642578\n",
      "Eval_StdReturn : 9.984367370605469\n",
      "Eval_MaxReturn : 198.45111083984375\n",
      "Eval_MinReturn : 157.2470245361328\n",
      "Eval_AverageEpLen : 88.41666666666667\n",
      "Train_AverageReturn : 170.90316772460938\n",
      "Train_StdReturn : 10.94259262084961\n",
      "Train_MaxReturn : 228.2410125732422\n",
      "Train_MinReturn : 146.2556915283203\n",
      "Train_AverageEpLen : 87.71929824561404\n",
      "Train_EnvstepsSoFar : 863238\n",
      "TimeSinceStart : 516.9561448097229\n",
      "Training Loss : 130.258056640625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10038 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.38819885253906\n",
      "Eval_StdReturn : 9.625587463378906\n",
      "Eval_MaxReturn : 192.71592712402344\n",
      "Eval_MinReturn : 154.27291870117188\n",
      "Eval_AverageEpLen : 86.83333333333333\n",
      "Train_AverageReturn : 170.19924926757812\n",
      "Train_StdReturn : 13.36087417602539\n",
      "Train_MaxReturn : 243.24609375\n",
      "Train_MinReturn : 141.76441955566406\n",
      "Train_AverageEpLen : 88.05263157894737\n",
      "Train_EnvstepsSoFar : 873276\n",
      "TimeSinceStart : 522.6706759929657\n",
      "Training Loss : 128.88450622558594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10051 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.90750122070312\n",
      "Eval_StdReturn : 4.726613998413086\n",
      "Eval_MaxReturn : 178.51162719726562\n",
      "Eval_MinReturn : 163.78228759765625\n",
      "Eval_AverageEpLen : 87.16666666666667\n",
      "Train_AverageReturn : 170.18087768554688\n",
      "Train_StdReturn : 9.687918663024902\n",
      "Train_MaxReturn : 225.06979370117188\n",
      "Train_MinReturn : 148.0545654296875\n",
      "Train_AverageEpLen : 87.4\n",
      "Train_EnvstepsSoFar : 883327\n",
      "TimeSinceStart : 528.3275530338287\n",
      "Training Loss : 130.4805145263672\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.30995178222656\n",
      "Eval_StdReturn : 5.221345901489258\n",
      "Eval_MaxReturn : 179.43728637695312\n",
      "Eval_MinReturn : 159.10009765625\n",
      "Eval_AverageEpLen : 87.75\n",
      "Train_AverageReturn : 168.78684997558594\n",
      "Train_StdReturn : 11.313005447387695\n",
      "Train_MaxReturn : 218.14805603027344\n",
      "Train_MinReturn : 99.8935775756836\n",
      "Train_AverageEpLen : 87.13913043478261\n",
      "Train_EnvstepsSoFar : 893348\n",
      "TimeSinceStart : 533.951473236084\n",
      "Training Loss : 128.91848754882812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10040 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.67832946777344\n",
      "Eval_StdReturn : 6.713964462280273\n",
      "Eval_MaxReturn : 187.33816528320312\n",
      "Eval_MinReturn : 161.02871704101562\n",
      "Eval_AverageEpLen : 86.66666666666667\n",
      "Train_AverageReturn : 170.50970458984375\n",
      "Train_StdReturn : 7.080097198486328\n",
      "Train_MaxReturn : 219.9825439453125\n",
      "Train_MinReturn : 155.3981170654297\n",
      "Train_AverageEpLen : 87.30434782608695\n",
      "Train_EnvstepsSoFar : 903388\n",
      "TimeSinceStart : 539.5587913990021\n",
      "Training Loss : 129.73605346679688\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.33116149902344\n",
      "Eval_StdReturn : 9.8281888961792\n",
      "Eval_MaxReturn : 182.0627899169922\n",
      "Eval_MinReturn : 146.0417022705078\n",
      "Eval_AverageEpLen : 87.58333333333333\n",
      "Train_AverageReturn : 170.1514129638672\n",
      "Train_StdReturn : 7.8221869468688965\n",
      "Train_MaxReturn : 197.67425537109375\n",
      "Train_MinReturn : 149.76193237304688\n",
      "Train_AverageEpLen : 87.16521739130435\n",
      "Train_EnvstepsSoFar : 913412\n",
      "TimeSinceStart : 545.2471470832825\n",
      "Training Loss : 129.3548583984375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10054 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.23086547851562\n",
      "Eval_StdReturn : 7.7726850509643555\n",
      "Eval_MaxReturn : 184.44480895996094\n",
      "Eval_MinReturn : 154.1837615966797\n",
      "Eval_AverageEpLen : 87.08333333333333\n",
      "Train_AverageReturn : 172.03396606445312\n",
      "Train_StdReturn : 6.213495254516602\n",
      "Train_MaxReturn : 187.48135375976562\n",
      "Train_MinReturn : 153.76275634765625\n",
      "Train_AverageEpLen : 87.42608695652174\n",
      "Train_EnvstepsSoFar : 923466\n",
      "TimeSinceStart : 550.9794473648071\n",
      "Training Loss : 131.70068359375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.5608367919922\n",
      "Eval_StdReturn : 4.266324520111084\n",
      "Eval_MaxReturn : 185.03549194335938\n",
      "Eval_MinReturn : 168.91969299316406\n",
      "Eval_AverageEpLen : 88.08333333333333\n",
      "Train_AverageReturn : 170.63392639160156\n",
      "Train_StdReturn : 15.262617111206055\n",
      "Train_MaxReturn : 187.38348388671875\n",
      "Train_MinReturn : 66.48094940185547\n",
      "Train_AverageEpLen : 86.1880341880342\n",
      "Train_EnvstepsSoFar : 933550\n",
      "TimeSinceStart : 556.8019797801971\n",
      "Training Loss : 130.64524841308594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.8146514892578\n",
      "Eval_StdReturn : 7.498448371887207\n",
      "Eval_MaxReturn : 179.8898162841797\n",
      "Eval_MinReturn : 152.6529083251953\n",
      "Eval_AverageEpLen : 86.5\n",
      "Train_AverageReturn : 157.1127471923828\n",
      "Train_StdReturn : 37.15257263183594\n",
      "Train_MaxReturn : 223.3992919921875\n",
      "Train_MinReturn : 60.34830093383789\n",
      "Train_AverageEpLen : 80.056\n",
      "Train_EnvstepsSoFar : 943557\n",
      "TimeSinceStart : 562.5963571071625\n",
      "Training Loss : 128.2938690185547\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10014 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 161.24346923828125\n",
      "Eval_StdReturn : 26.72695541381836\n",
      "Eval_MaxReturn : 176.37879943847656\n",
      "Eval_MinReturn : 85.59099578857422\n",
      "Eval_AverageEpLen : 82.07692307692308\n",
      "Train_AverageReturn : 160.89102172851562\n",
      "Train_StdReturn : 35.19837188720703\n",
      "Train_MaxReturn : 215.52151489257812\n",
      "Train_MinReturn : 56.82850646972656\n",
      "Train_AverageEpLen : 81.41463414634147\n",
      "Train_EnvstepsSoFar : 953571\n",
      "TimeSinceStart : 568.2493121623993\n",
      "Training Loss : 129.32241821289062\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.7202606201172\n",
      "Eval_StdReturn : 7.020456790924072\n",
      "Eval_MaxReturn : 178.86851501464844\n",
      "Eval_MinReturn : 157.3807830810547\n",
      "Eval_AverageEpLen : 87.08333333333333\n",
      "Train_AverageReturn : 167.222412109375\n",
      "Train_StdReturn : 25.31302833557129\n",
      "Train_MaxReturn : 189.62135314941406\n",
      "Train_MinReturn : 63.12539291381836\n",
      "Train_AverageEpLen : 84.67226890756302\n",
      "Train_EnvstepsSoFar : 963647\n",
      "TimeSinceStart : 573.9086441993713\n",
      "Training Loss : 130.41603088378906\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 172.41290283203125\n",
      "Eval_StdReturn : 6.431640625\n",
      "Eval_MaxReturn : 186.70433044433594\n",
      "Eval_MinReturn : 162.40231323242188\n",
      "Eval_AverageEpLen : 87.41666666666667\n",
      "Train_AverageReturn : 171.09132385253906\n",
      "Train_StdReturn : 12.746264457702637\n",
      "Train_MaxReturn : 200.84991455078125\n",
      "Train_MinReturn : 72.96185302734375\n",
      "Train_AverageEpLen : 87.02608695652174\n",
      "Train_EnvstepsSoFar : 973655\n",
      "TimeSinceStart : 579.5223472118378\n",
      "Training Loss : 129.84127807617188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10067 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.2518310546875\n",
      "Eval_StdReturn : 3.9375619888305664\n",
      "Eval_MaxReturn : 180.3975372314453\n",
      "Eval_MinReturn : 165.1454315185547\n",
      "Eval_AverageEpLen : 89.41666666666667\n",
      "Train_AverageReturn : 173.43048095703125\n",
      "Train_StdReturn : 9.525286674499512\n",
      "Train_MaxReturn : 214.4967041015625\n",
      "Train_MinReturn : 152.33255004882812\n",
      "Train_AverageEpLen : 88.30701754385964\n",
      "Train_EnvstepsSoFar : 983722\n",
      "TimeSinceStart : 585.1047096252441\n",
      "Training Loss : 129.64199829101562\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10081 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 164.2411651611328\n",
      "Eval_StdReturn : 32.0625114440918\n",
      "Eval_MaxReturn : 188.5782012939453\n",
      "Eval_MinReturn : 59.859642028808594\n",
      "Eval_AverageEpLen : 85.58333333333333\n",
      "Train_AverageReturn : 172.93247985839844\n",
      "Train_StdReturn : 12.490872383117676\n",
      "Train_MaxReturn : 208.2769317626953\n",
      "Train_MinReturn : 110.0961685180664\n",
      "Train_AverageEpLen : 88.4298245614035\n",
      "Train_EnvstepsSoFar : 993803\n",
      "TimeSinceStart : 590.6395359039307\n",
      "Training Loss : 129.96725463867188\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.11297607421875\n",
      "Eval_StdReturn : 15.241437911987305\n",
      "Eval_MaxReturn : 193.5977020263672\n",
      "Eval_MinReturn : 127.21876525878906\n",
      "Eval_AverageEpLen : 86.08333333333333\n",
      "Train_AverageReturn : 171.4427032470703\n",
      "Train_StdReturn : 13.220757484436035\n",
      "Train_MaxReturn : 201.2313232421875\n",
      "Train_MinReturn : 98.3519287109375\n",
      "Train_AverageEpLen : 88.57522123893806\n",
      "Train_EnvstepsSoFar : 1003812\n",
      "TimeSinceStart : 596.1354293823242\n",
      "Training Loss : 127.91580200195312\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 13.049403190612793\n",
      "Done logging...\n",
      "\n",
      "\n",
      "Running policy gradient experiment with seed 2\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/return_to_go/seed2\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Collecting train rollouts to be used for saving videos...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "At timestep:     1023 / 1000\n",
      "Collecting video rollouts eval\n",
      "\n",
      "Saving train rollouts as videos...\n",
      "Eval_AverageReturn : 70.17424011230469\n",
      "Eval_StdReturn : 26.798738479614258\n",
      "Eval_MaxReturn : 165.48922729492188\n",
      "Eval_MinReturn : 9.21133041381836\n",
      "Eval_AverageEpLen : 44.47826086956522\n",
      "Train_AverageReturn : 18.039928436279297\n",
      "Train_StdReturn : 17.921995162963867\n",
      "Train_MaxReturn : 141.83033752441406\n",
      "Train_MinReturn : 3.2006664276123047\n",
      "Train_AverageEpLen : 21.3\n",
      "Train_EnvstepsSoFar : 10011\n",
      "TimeSinceStart : 14.319205522537231\n",
      "Training Loss : 32.90594482421875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10049 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 63.387081146240234\n",
      "Eval_StdReturn : 11.397832870483398\n",
      "Eval_MaxReturn : 93.93512725830078\n",
      "Eval_MinReturn : 50.510986328125\n",
      "Eval_AverageEpLen : 37.42857142857143\n",
      "Train_AverageReturn : 75.36470794677734\n",
      "Train_StdReturn : 23.286054611206055\n",
      "Train_MaxReturn : 167.83522033691406\n",
      "Train_MinReturn : 5.729321002960205\n",
      "Train_AverageEpLen : 47.40094339622642\n",
      "Train_EnvstepsSoFar : 20060\n",
      "TimeSinceStart : 21.523367166519165\n",
      "Training Loss : 94.0568618774414\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 105.31471252441406\n",
      "Eval_StdReturn : 46.982913970947266\n",
      "Eval_MaxReturn : 208.39141845703125\n",
      "Eval_MinReturn : 42.804420471191406\n",
      "Eval_AverageEpLen : 56.0\n",
      "Train_AverageReturn : 64.8066635131836\n",
      "Train_StdReturn : 17.052515029907227\n",
      "Train_MaxReturn : 146.58041381835938\n",
      "Train_MinReturn : 44.6534538269043\n",
      "Train_AverageEpLen : 37.83018867924528\n",
      "Train_EnvstepsSoFar : 30085\n",
      "TimeSinceStart : 27.220346212387085\n",
      "Training Loss : 91.12016296386719\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 88.50762939453125\n",
      "Eval_StdReturn : 62.84705352783203\n",
      "Eval_MaxReturn : 202.6788330078125\n",
      "Eval_MinReturn : 31.335607528686523\n",
      "Eval_AverageEpLen : 50.1\n",
      "Train_AverageReturn : 113.67326354980469\n",
      "Train_StdReturn : 46.9121208190918\n",
      "Train_MaxReturn : 244.636962890625\n",
      "Train_MinReturn : 36.99093246459961\n",
      "Train_AverageEpLen : 60.265060240963855\n",
      "Train_EnvstepsSoFar : 40089\n",
      "TimeSinceStart : 32.82691526412964\n",
      "Training Loss : 120.86847686767578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 127.72429656982422\n",
      "Eval_StdReturn : 40.45026397705078\n",
      "Eval_MaxReturn : 187.22451782226562\n",
      "Eval_MinReturn : 52.944252014160156\n",
      "Eval_AverageEpLen : 68.53333333333333\n",
      "Train_AverageReturn : 94.8331298828125\n",
      "Train_StdReturn : 61.81793212890625\n",
      "Train_MaxReturn : 209.32225036621094\n",
      "Train_MinReturn : 17.5417537689209\n",
      "Train_AverageEpLen : 52.742105263157896\n",
      "Train_EnvstepsSoFar : 50110\n",
      "TimeSinceStart : 38.54987335205078\n",
      "Training Loss : 113.4051513671875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10053 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.70167541503906\n",
      "Eval_StdReturn : 34.80609893798828\n",
      "Eval_MaxReturn : 197.06333923339844\n",
      "Eval_MinReturn : 62.03025817871094\n",
      "Eval_AverageEpLen : 81.07692307692308\n",
      "Train_AverageReturn : 121.99761199951172\n",
      "Train_StdReturn : 50.06731414794922\n",
      "Train_MaxReturn : 205.9213104248047\n",
      "Train_MinReturn : 25.432525634765625\n",
      "Train_AverageEpLen : 65.27922077922078\n",
      "Train_EnvstepsSoFar : 60163\n",
      "TimeSinceStart : 44.12711310386658\n",
      "Training Loss : 122.08629608154297\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.34568786621094\n",
      "Eval_StdReturn : 20.449745178222656\n",
      "Eval_MaxReturn : 183.90274047851562\n",
      "Eval_MinReturn : 103.84944152832031\n",
      "Eval_AverageEpLen : 82.23076923076923\n",
      "Train_AverageReturn : 181.46153259277344\n",
      "Train_StdReturn : 18.80909538269043\n",
      "Train_MaxReturn : 206.4469451904297\n",
      "Train_MinReturn : 56.87861633300781\n",
      "Train_AverageEpLen : 85.58119658119658\n",
      "Train_EnvstepsSoFar : 70176\n",
      "TimeSinceStart : 49.773481607437134\n",
      "Training Loss : 148.0381622314453\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10066 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 150.62380981445312\n",
      "Eval_StdReturn : 28.98554229736328\n",
      "Eval_MaxReturn : 179.75637817382812\n",
      "Eval_MinReturn : 95.93925476074219\n",
      "Eval_AverageEpLen : 75.42857142857143\n",
      "Train_AverageReturn : 176.80397033691406\n",
      "Train_StdReturn : 15.14346981048584\n",
      "Train_MaxReturn : 203.4510955810547\n",
      "Train_MinReturn : 91.11959075927734\n",
      "Train_AverageEpLen : 83.88333333333334\n",
      "Train_EnvstepsSoFar : 80242\n",
      "TimeSinceStart : 55.47231101989746\n",
      "Training Loss : 145.94293212890625\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10080 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 135.35247802734375\n",
      "Eval_StdReturn : 34.8894157409668\n",
      "Eval_MaxReturn : 177.20938110351562\n",
      "Eval_MinReturn : 55.89530944824219\n",
      "Eval_AverageEpLen : 69.66666666666667\n",
      "Train_AverageReturn : 141.20849609375\n",
      "Train_StdReturn : 35.957542419433594\n",
      "Train_MaxReturn : 185.22958374023438\n",
      "Train_MinReturn : 58.824398040771484\n",
      "Train_AverageEpLen : 70.98591549295774\n",
      "Train_EnvstepsSoFar : 90322\n",
      "TimeSinceStart : 61.14305567741394\n",
      "Training Loss : 129.98448181152344\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10006 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 164.19058227539062\n",
      "Eval_StdReturn : 23.03472137451172\n",
      "Eval_MaxReturn : 177.3474578857422\n",
      "Eval_MinReturn : 87.27470397949219\n",
      "Eval_AverageEpLen : 82.61538461538461\n",
      "Train_AverageReturn : 150.47671508789062\n",
      "Train_StdReturn : 31.28547477722168\n",
      "Train_MaxReturn : 187.53289794921875\n",
      "Train_MinReturn : 57.56748580932617\n",
      "Train_AverageEpLen : 75.8030303030303\n",
      "Train_EnvstepsSoFar : 100328\n",
      "TimeSinceStart : 66.79944586753845\n",
      "Training Loss : 131.46780395507812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 159.75376892089844\n",
      "Eval_StdReturn : 26.491504669189453\n",
      "Eval_MaxReturn : 174.22918701171875\n",
      "Eval_MinReturn : 71.7400894165039\n",
      "Eval_AverageEpLen : 81.23076923076923\n",
      "Train_AverageReturn : 159.8450164794922\n",
      "Train_StdReturn : 25.308643341064453\n",
      "Train_MaxReturn : 180.61953735351562\n",
      "Train_MinReturn : 62.407562255859375\n",
      "Train_AverageEpLen : 80.70161290322581\n",
      "Train_EnvstepsSoFar : 110335\n",
      "TimeSinceStart : 72.44912147521973\n",
      "Training Loss : 132.82069396972656\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 164.0614471435547\n",
      "Eval_StdReturn : 22.912267684936523\n",
      "Eval_MaxReturn : 176.04061889648438\n",
      "Eval_MinReturn : 85.17654418945312\n",
      "Eval_AverageEpLen : 83.38461538461539\n",
      "Train_AverageReturn : 167.73805236816406\n",
      "Train_StdReturn : 12.042668342590332\n",
      "Train_MaxReturn : 177.34080505371094\n",
      "Train_MinReturn : 86.0126953125\n",
      "Train_AverageEpLen : 84.89830508474576\n",
      "Train_EnvstepsSoFar : 120353\n",
      "TimeSinceStart : 78.1939218044281\n",
      "Training Loss : 133.8129425048828\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10060 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.06004333496094\n",
      "Eval_StdReturn : 4.562432289123535\n",
      "Eval_MaxReturn : 177.47801208496094\n",
      "Eval_MinReturn : 159.7913360595703\n",
      "Eval_AverageEpLen : 86.0\n",
      "Train_AverageReturn : 166.4338836669922\n",
      "Train_StdReturn : 16.101158142089844\n",
      "Train_MaxReturn : 174.9598846435547\n",
      "Train_MinReturn : 52.56058120727539\n",
      "Train_AverageEpLen : 84.53781512605042\n",
      "Train_EnvstepsSoFar : 130413\n",
      "TimeSinceStart : 83.93788409233093\n",
      "Training Loss : 132.0695037841797\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.33306884765625\n",
      "Eval_StdReturn : 2.062307119369507\n",
      "Eval_MaxReturn : 172.22743225097656\n",
      "Eval_MinReturn : 164.2970733642578\n",
      "Eval_AverageEpLen : 86.58333333333333\n",
      "Train_AverageReturn : 167.52896118164062\n",
      "Train_StdReturn : 9.740731239318848\n",
      "Train_MaxReturn : 176.6740264892578\n",
      "Train_MinReturn : 73.91024780273438\n",
      "Train_AverageEpLen : 85.55555555555556\n",
      "Train_EnvstepsSoFar : 140423\n",
      "TimeSinceStart : 89.58808779716492\n",
      "Training Loss : 132.27297973632812\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.26376342773438\n",
      "Eval_StdReturn : 2.2817165851593018\n",
      "Eval_MaxReturn : 170.9625244140625\n",
      "Eval_MinReturn : 162.6380157470703\n",
      "Eval_AverageEpLen : 86.33333333333333\n",
      "Train_AverageReturn : 167.5997772216797\n",
      "Train_StdReturn : 3.140472173690796\n",
      "Train_MaxReturn : 173.07363891601562\n",
      "Train_MinReturn : 154.1611328125\n",
      "Train_AverageEpLen : 86.20689655172414\n",
      "Train_EnvstepsSoFar : 150423\n",
      "TimeSinceStart : 95.22859144210815\n",
      "Training Loss : 130.69309997558594\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 167.7216339111328\n",
      "Eval_StdReturn : 3.7987120151519775\n",
      "Eval_MaxReturn : 171.88491821289062\n",
      "Eval_MinReturn : 159.66380310058594\n",
      "Eval_AverageEpLen : 86.0\n",
      "Train_AverageReturn : 167.8849639892578\n",
      "Train_StdReturn : 2.780242681503296\n",
      "Train_MaxReturn : 175.5303192138672\n",
      "Train_MinReturn : 159.63607788085938\n",
      "Train_AverageEpLen : 86.24137931034483\n",
      "Train_EnvstepsSoFar : 160427\n",
      "TimeSinceStart : 100.89285802841187\n",
      "Training Loss : 130.5246124267578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 169.2869873046875\n",
      "Eval_StdReturn : 1.8574392795562744\n",
      "Eval_MaxReturn : 171.9683380126953\n",
      "Eval_MinReturn : 166.4282684326172\n",
      "Eval_AverageEpLen : 86.25\n",
      "Train_AverageReturn : 167.8396759033203\n",
      "Train_StdReturn : 2.617633104324341\n",
      "Train_MaxReturn : 172.39161682128906\n",
      "Train_MinReturn : 161.90367126464844\n",
      "Train_AverageEpLen : 86.29310344827586\n",
      "Train_EnvstepsSoFar : 170437\n",
      "TimeSinceStart : 106.49961423873901\n",
      "Training Loss : 131.0335693359375\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10064 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 168.72877502441406\n",
      "Eval_StdReturn : 2.273703098297119\n",
      "Eval_MaxReturn : 170.91171264648438\n",
      "Eval_MinReturn : 162.70045471191406\n",
      "Eval_AverageEpLen : 86.16666666666667\n",
      "Train_AverageReturn : 168.13937377929688\n",
      "Train_StdReturn : 5.817441940307617\n",
      "Train_MaxReturn : 173.98583984375\n",
      "Train_MinReturn : 112.09795379638672\n",
      "Train_AverageEpLen : 86.01709401709402\n",
      "Train_EnvstepsSoFar : 180501\n",
      "TimeSinceStart : 112.2338445186615\n",
      "Training Loss : 131.4904327392578\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 158.66073608398438\n",
      "Eval_StdReturn : 27.503822326660156\n",
      "Eval_MaxReturn : 170.43089294433594\n",
      "Eval_MinReturn : 66.28203582763672\n",
      "Eval_AverageEpLen : 81.61538461538461\n",
      "Train_AverageReturn : 167.7633819580078\n",
      "Train_StdReturn : 8.565732955932617\n",
      "Train_MaxReturn : 173.9300079345703\n",
      "Train_MinReturn : 80.97825622558594\n",
      "Train_AverageEpLen : 85.78632478632478\n",
      "Train_EnvstepsSoFar : 190538\n",
      "TimeSinceStart : 118.22818112373352\n",
      "Training Loss : 130.70819091796875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 163.50355529785156\n",
      "Eval_StdReturn : 7.160808563232422\n",
      "Eval_MaxReturn : 171.83489990234375\n",
      "Eval_MinReturn : 150.54425048828125\n",
      "Eval_AverageEpLen : 83.41666666666667\n",
      "Train_AverageReturn : 164.0123748779297\n",
      "Train_StdReturn : 20.686771392822266\n",
      "Train_MaxReturn : 174.490966796875\n",
      "Train_MinReturn : 55.86983108520508\n",
      "Train_AverageEpLen : 83.7\n",
      "Train_EnvstepsSoFar : 200582\n",
      "TimeSinceStart : 123.94795370101929\n",
      "Training Loss : 131.1385955810547\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 149.5720977783203\n",
      "Eval_StdReturn : 30.822751998901367\n",
      "Eval_MaxReturn : 172.4967041015625\n",
      "Eval_MinReturn : 76.2659683227539\n",
      "Eval_AverageEpLen : 77.0\n",
      "Train_AverageReturn : 140.8077392578125\n",
      "Train_StdReturn : 38.15953826904297\n",
      "Train_MaxReturn : 174.0888214111328\n",
      "Train_MinReturn : 60.429283142089844\n",
      "Train_AverageEpLen : 72.80434782608695\n",
      "Train_EnvstepsSoFar : 210629\n",
      "TimeSinceStart : 130.17801523208618\n",
      "Training Loss : 124.5705337524414\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 150.63929748535156\n",
      "Eval_StdReturn : 34.82469177246094\n",
      "Eval_MaxReturn : 172.35989379882812\n",
      "Eval_MinReturn : 65.68507385253906\n",
      "Eval_AverageEpLen : 76.92857142857143\n",
      "Train_AverageReturn : 145.62615966796875\n",
      "Train_StdReturn : 36.39701843261719\n",
      "Train_MaxReturn : 174.20436096191406\n",
      "Train_MinReturn : 53.40550994873047\n",
      "Train_AverageEpLen : 74.90298507462687\n",
      "Train_EnvstepsSoFar : 220666\n",
      "TimeSinceStart : 136.27684211730957\n",
      "Training Loss : 126.73260498046875\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 166.58143615722656\n",
      "Eval_StdReturn : 4.063745498657227\n",
      "Eval_MaxReturn : 171.5167236328125\n",
      "Eval_MinReturn : 156.93853759765625\n",
      "Eval_AverageEpLen : 85.16666666666667\n",
      "Train_AverageReturn : 155.16368103027344\n",
      "Train_StdReturn : 29.903114318847656\n",
      "Train_MaxReturn : 176.1729278564453\n",
      "Train_MinReturn : 59.03245544433594\n",
      "Train_AverageEpLen : 79.36507936507937\n",
      "Train_EnvstepsSoFar : 230666\n",
      "TimeSinceStart : 142.12996172904968\n",
      "Training Loss : 128.72914123535156\n",
      "Baseline Loss : 0\n",
      "Initial_DataCollection_AverageReturn : 18.039928436279297\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-90d6ad092175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpg_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logdir'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'logs/policy_gradient/{}/return_to_go/seed{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpgtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPG_Trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpgtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/repositorios/cs182/hw4/deeprl/infrastructure/trainers.py\u001b[0m in \u001b[0;36mrun_training_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         self.rl_trainer.run_training_loop(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mcollect_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositorios/cs182/hw4/deeprl/infrastructure/rl_trainer.py\u001b[0m in \u001b[0;36mrun_training_loop\u001b[0;34m(self, n_iter, collect_policy, eval_policy, initial_expertdata, relabel_with_expert, start_relabel_with_expert, expert_policy)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_dqn_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_video_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositorios/cs182/hw4/deeprl/infrastructure/rl_trainer.py\u001b[0m in \u001b[0;36mperform_logging\u001b[0;34m(self, itr, paths, eval_policy, train_video_paths, all_logs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# collect eval trajectories, for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCollecting data for eval...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0meval_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_envsteps_this_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_trajectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ep_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# save eval rollouts as videos in tensorboard event file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositorios/cs182/hw4/deeprl/infrastructure/utils.py\u001b[0m in \u001b[0;36msample_trajectories\u001b[0;34m(env, policy, min_timesteps_per_batch, max_path_length, render, render_mode)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtimesteps_this_batch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_timesteps_per_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m#collect rollout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_path_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositorios/cs182/hw4/deeprl/infrastructure/utils.py\u001b[0m in \u001b[0;36msample_trajectory\u001b[0;34m(env, policy, max_path_length, render, render_mode)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositorios/cs182/hw4/deeprl/policies/MLP_policy.py\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# action = self(observation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0maction_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# don't bother with rsample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mptu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw4/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repositorios/cs182/hw4/deeprl/policies/MLP_policy.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mbatch_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mlogstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mscale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw4/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw4/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw4/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw4/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hw4/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "### Visualize Policy Gradient results on Hopper\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/policy_gradient/Hopper"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a8cd990e4fd4e41d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a8cd990e4fd4e41d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variance Reduction with a Value Function Baseline\n",
    "We can further reduce the policy gradient variance by including state-dependent baselines. In this section, we will train a value function network to predict the value of the policy at a state, then use the value function as a baseline by subtracting it from our reward-to-go estimate.\n",
    "\n",
    "Implement the value function baseline loss in the update method of the MLPPolicyPG class in <code>policies/MLP_policy.py</code>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Test value function gradient\n",
    "torch.manual_seed(0)\n",
    "ac_dim = 2\n",
    "ob_dim = 3\n",
    "batch_size = 5\n",
    "\n",
    "policy = MLPPolicyPG(\n",
    "            ac_dim=ac_dim,\n",
    "            ob_dim=ob_dim,\n",
    "            n_layers=1,\n",
    "            size=2,\n",
    "            learning_rate=0.25,\n",
    "            nn_baseline=True)\n",
    "\n",
    "np.random.seed(0)\n",
    "obs = np.random.normal(size=(batch_size, ob_dim))\n",
    "acts = np.random.normal(size=(batch_size, ac_dim))\n",
    "advs = 1000 * np.random.normal(size=(batch_size,))\n",
    "qvals = advs\n",
    "\n",
    "first_weight_before = np.array(ptu.to_numpy(next(policy.baseline.parameters())))\n",
    "print(\"Weight before update\", first_weight_before)\n",
    "\n",
    "for i in range(5):\n",
    "    loss = policy.update(obs, acts, advs, qvals=qvals)['Baseline Loss']\n",
    "\n",
    "print(loss)\n",
    "expected_loss = 0.925361\n",
    "loss_error = rel_error(loss, expected_loss)\n",
    "print(\"Loss Error\", loss_error, \"should be on the order of 1e-6 or lower\")\n",
    "\n",
    "first_weight_after = ptu.to_numpy(next(policy.baseline.parameters()))\n",
    "print('Weight after update', first_weight_after)\n",
    "\n",
    "weight_change = first_weight_after - first_weight_before\n",
    "print(\"Change in weights\", weight_change)\n",
    "\n",
    "expected_change = np.array([[ 0.38988823,  0.70297027,  0.2609921 ],\n",
    "                            [-1.0340402,  -0.84166795,  0.7254925 ]])\n",
    "updated_weight_error = rel_error(weight_change, expected_change)\n",
    "print(\"Weight Update Error\", updated_weight_error, \"should be on the order of 1e-6 or lower\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Weight before update [[-0.23799711  0.02138712  0.22824688]\n",
      " [ 0.34642333 -0.39140946 -0.25141457]]\n",
      "0.925361\n",
      "Loss Error 1.2076536367060315e-08 should be on the order of 1e-6 or lower\n",
      "Weight after update [[ 0.15189111  0.72435737  0.489239  ]\n",
      " [-0.68761694 -1.2330774   0.47407794]]\n",
      "Change in weights [[ 0.38988823  0.70297027  0.2609921 ]\n",
      " [-1.0340402  -0.84166795  0.7254925 ]]\n",
      "Weight Update Error 1.8727660770522845e-08 should be on the order of 1e-6 or lower\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the estimate_advantage function in <code>agents/pg_agent.py</code>, fill out the advantage estimate using the baseline and test your implementation below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "### Test return computation\n",
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'CartPole'\n",
    "pg_args['env_name'] = '{}-v0'.format(env_str)\n",
    "pg_args['nn_baseline'] = True\n",
    "pgtrainer = PG_Trainer(pg_args)\n",
    "pgagent = pgtrainer.rl_trainer.agent\n",
    "\n",
    "obs_dim = 4\n",
    "N = 10\n",
    "np.random.seed(0)\n",
    "obs = np.random.normal(size=(N, obs_dim))\n",
    "qs = np.random.normal(size=N)\n",
    "\n",
    "baseline_advantages = pgagent.estimate_advantage(obs, qs)\n",
    "expected_advantages = np.array([-0.44662586, -0.89629588, -1.14574752,  2.43957172, -0.06601728,\n",
    "       -0.00501807, -0.74720337,  1.27468092, -1.20184486,  0.25312274])\n",
    "\n",
    "advantage_error = rel_error(expected_advantages, baseline_advantages)\n",
    "print(\"Advantage error\", advantage_error, \"should be on the order of 1e-6 or lower\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "########################\n",
      "logging outputs to  test\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "CartPole-v0\n",
      "Advantage error 3.6888988344448045e-07 should be on the order of 1e-6 or lower\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train your policies!\n",
    "In this section, we will train our policies using the reward-to-go estimator and learning a value function baseline. On Hopper, you should see your methods get over 300 rewards consistently, and sometimes over 400. Returns will tend to oscillate during training. You should also see that using a value function baseline greatly improves performance over our earlier experiments without it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pg_args = dict(pg_base_args_dict)\n",
    "\n",
    "env_str = 'Hopper'\n",
    "pg_args['env_name'] = '{}-v2'.format(env_str)\n",
    "pg_args['learning_rate'] = 0.01\n",
    "pg_args['reward_to_go'] = True\n",
    "pg_args['nn_baseline'] = True\n",
    "pg_args['batch_size'] = 10000\n",
    "pg_args['train_batch_size'] = 10000\n",
    "pg_args['n_iter'] = 100\n",
    "\n",
    "# Delete all previous logs\n",
    "remove_folder('logs/policy_gradient/{}/with_baseline/'.format(env_str))\n",
    "\n",
    "for seed in range(3):\n",
    "    print(\"Running policy gradient experiment with seed\", seed)\n",
    "    pg_args['seed'] = seed\n",
    "    pg_args['logdir'] = 'logs/policy_gradient/{}/with_baseline/seed{}'.format(env_str, seed)\n",
    "    pgtrainer = PG_Trainer(pg_args)\n",
    "    pgtrainer.run_training_loop()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Folder logs/policy_gradient/Hopper/with_baseline/ does not exist yet. No old results to delete\n",
      "Running policy gradient experiment with seed 0\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/with_baseline/seed0\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 89.84849548339844\n",
      "Eval_StdReturn : 33.547855377197266\n",
      "Eval_MaxReturn : 155.4940185546875\n",
      "Eval_MinReturn : 29.384666442871094\n",
      "Eval_AverageEpLen : 58.5\n",
      "Train_AverageReturn : 9.403343200683594\n",
      "Train_StdReturn : 4.718483924865723\n",
      "Train_MaxReturn : 46.106727600097656\n",
      "Train_MinReturn : 2.846346378326416\n",
      "Train_AverageEpLen : 12.939276485788113\n",
      "Train_EnvstepsSoFar : 10015\n",
      "TimeSinceStart : 6.139279842376709\n",
      "Training Loss : 3.9577796459198\n",
      "Baseline Loss : 1.0592422485351562\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10034 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 110.52185821533203\n",
      "Eval_StdReturn : 52.784881591796875\n",
      "Eval_MaxReturn : 207.3875732421875\n",
      "Eval_MinReturn : 49.420433044433594\n",
      "Eval_AverageEpLen : 59.111111111111114\n",
      "Train_AverageReturn : 97.38761138916016\n",
      "Train_StdReturn : 51.84263610839844\n",
      "Train_MaxReturn : 263.6323547363281\n",
      "Train_MinReturn : 5.455582141876221\n",
      "Train_AverageEpLen : 60.44578313253012\n",
      "Train_EnvstepsSoFar : 20049\n",
      "TimeSinceStart : 11.740157842636108\n",
      "Training Loss : -14.395066261291504\n",
      "Baseline Loss : 1.2495510578155518\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 154.86862182617188\n",
      "Eval_StdReturn : 59.431907653808594\n",
      "Eval_MaxReturn : 214.60768127441406\n",
      "Eval_MinReturn : 57.70475387573242\n",
      "Eval_AverageEpLen : 73.57142857142857\n",
      "Train_AverageReturn : 109.16539764404297\n",
      "Train_StdReturn : 44.80699920654297\n",
      "Train_MaxReturn : 247.84918212890625\n",
      "Train_MinReturn : 54.69504165649414\n",
      "Train_AverageEpLen : 57.94219653179191\n",
      "Train_EnvstepsSoFar : 30073\n",
      "TimeSinceStart : 17.352051258087158\n",
      "Training Loss : -8.466608047485352\n",
      "Baseline Loss : 1.0519475936889648\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 190.2843017578125\n",
      "Eval_StdReturn : 16.108144760131836\n",
      "Eval_MaxReturn : 207.78521728515625\n",
      "Eval_MinReturn : 144.90432739257812\n",
      "Eval_AverageEpLen : 85.91666666666667\n",
      "Train_AverageReturn : 138.61468505859375\n",
      "Train_StdReturn : 58.83147430419922\n",
      "Train_MaxReturn : 219.96075439453125\n",
      "Train_MinReturn : 20.248825073242188\n",
      "Train_AverageEpLen : 68.21768707482993\n",
      "Train_EnvstepsSoFar : 40101\n",
      "TimeSinceStart : 22.942802667617798\n",
      "Training Loss : 0.04974046349525452\n",
      "Baseline Loss : 1.0686315298080444\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10081 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.00526428222656\n",
      "Eval_StdReturn : 21.687156677246094\n",
      "Eval_MaxReturn : 207.7041015625\n",
      "Eval_MinReturn : 136.44358825683594\n",
      "Eval_AverageEpLen : 82.6923076923077\n",
      "Train_AverageReturn : 186.64569091796875\n",
      "Train_StdReturn : 29.183874130249023\n",
      "Train_MaxReturn : 214.93048095703125\n",
      "Train_MinReturn : 45.535240173339844\n",
      "Train_AverageEpLen : 84.71428571428571\n",
      "Train_EnvstepsSoFar : 50182\n",
      "TimeSinceStart : 28.54701519012451\n",
      "Training Loss : 8.81011962890625\n",
      "Baseline Loss : 1.0044747591018677\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10022 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 177.49363708496094\n",
      "Eval_StdReturn : 18.7716007232666\n",
      "Eval_MaxReturn : 210.1418914794922\n",
      "Eval_MinReturn : 144.29176330566406\n",
      "Eval_AverageEpLen : 81.0\n",
      "Train_AverageReturn : 188.60247802734375\n",
      "Train_StdReturn : 17.28499984741211\n",
      "Train_MaxReturn : 213.0032958984375\n",
      "Train_MinReturn : 127.2325439453125\n",
      "Train_AverageEpLen : 84.9322033898305\n",
      "Train_EnvstepsSoFar : 60204\n",
      "TimeSinceStart : 34.12814927101135\n",
      "Training Loss : 7.44644832611084\n",
      "Baseline Loss : 0.9286070466041565\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 185.8250274658203\n",
      "Eval_StdReturn : 18.03797721862793\n",
      "Eval_MaxReturn : 208.41139221191406\n",
      "Eval_MinReturn : 150.87249755859375\n",
      "Eval_AverageEpLen : 83.66666666666667\n",
      "Train_AverageReturn : 182.4478759765625\n",
      "Train_StdReturn : 26.729183197021484\n",
      "Train_MaxReturn : 221.315185546875\n",
      "Train_MinReturn : 22.284727096557617\n",
      "Train_AverageEpLen : 82.66115702479338\n",
      "Train_EnvstepsSoFar : 70206\n",
      "TimeSinceStart : 39.51136016845703\n",
      "Training Loss : 2.8451266288757324\n",
      "Baseline Loss : 0.8878705501556396\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10031 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 195.0240936279297\n",
      "Eval_StdReturn : 8.21087646484375\n",
      "Eval_MaxReturn : 205.46986389160156\n",
      "Eval_MinReturn : 181.4990234375\n",
      "Eval_AverageEpLen : 87.16666666666667\n",
      "Train_AverageReturn : 186.92764282226562\n",
      "Train_StdReturn : 20.2882137298584\n",
      "Train_MaxReturn : 215.34487915039062\n",
      "Train_MinReturn : 101.64033508300781\n",
      "Train_AverageEpLen : 84.29411764705883\n",
      "Train_EnvstepsSoFar : 80237\n",
      "TimeSinceStart : 44.97991895675659\n",
      "Training Loss : 0.009693296626210213\n",
      "Baseline Loss : 0.8594197630882263\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 190.72564697265625\n",
      "Eval_StdReturn : 7.469963550567627\n",
      "Eval_MaxReturn : 201.56939697265625\n",
      "Eval_MinReturn : 176.16087341308594\n",
      "Eval_AverageEpLen : 86.25\n",
      "Train_AverageReturn : 191.70248413085938\n",
      "Train_StdReturn : 8.85874080657959\n",
      "Train_MaxReturn : 210.21084594726562\n",
      "Train_MinReturn : 173.30128479003906\n",
      "Train_AverageEpLen : 86.34482758620689\n",
      "Train_EnvstepsSoFar : 90253\n",
      "TimeSinceStart : 50.435343503952026\n",
      "Training Loss : -0.8511726260185242\n",
      "Baseline Loss : 0.8118973970413208\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 186.87164306640625\n",
      "Eval_StdReturn : 6.4619927406311035\n",
      "Eval_MaxReturn : 202.28199768066406\n",
      "Eval_MinReturn : 177.33547973632812\n",
      "Eval_AverageEpLen : 84.91666666666667\n",
      "Train_AverageReturn : 190.4232635498047\n",
      "Train_StdReturn : 9.88088607788086\n",
      "Train_MaxReturn : 212.63160705566406\n",
      "Train_MinReturn : 144.91021728515625\n",
      "Train_AverageEpLen : 86.1880341880342\n",
      "Train_EnvstepsSoFar : 100337\n",
      "TimeSinceStart : 55.95553493499756\n",
      "Training Loss : 1.376468300819397\n",
      "Baseline Loss : 0.7493181824684143\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10062 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 184.7636260986328\n",
      "Eval_StdReturn : 8.390830039978027\n",
      "Eval_MaxReturn : 201.6374053955078\n",
      "Eval_MinReturn : 174.5752410888672\n",
      "Eval_AverageEpLen : 85.58333333333333\n",
      "Train_AverageReturn : 187.32424926757812\n",
      "Train_StdReturn : 7.658655166625977\n",
      "Train_MaxReturn : 209.7080535888672\n",
      "Train_MinReturn : 170.9979248046875\n",
      "Train_AverageEpLen : 85.27118644067797\n",
      "Train_EnvstepsSoFar : 110399\n",
      "TimeSinceStart : 61.42437028884888\n",
      "Training Loss : 3.740938186645508\n",
      "Baseline Loss : 0.6973869800567627\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10060 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.8006134033203\n",
      "Eval_StdReturn : 7.565256595611572\n",
      "Eval_MaxReturn : 201.2373504638672\n",
      "Eval_MinReturn : 172.0930633544922\n",
      "Eval_AverageEpLen : 83.83333333333333\n",
      "Train_AverageReturn : 183.13316345214844\n",
      "Train_StdReturn : 8.623274803161621\n",
      "Train_MaxReturn : 206.40496826171875\n",
      "Train_MinReturn : 138.16502380371094\n",
      "Train_AverageEpLen : 84.53781512605042\n",
      "Train_EnvstepsSoFar : 120459\n",
      "TimeSinceStart : 66.91307616233826\n",
      "Training Loss : 2.9437527656555176\n",
      "Baseline Loss : 0.6505021452903748\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 181.5042266845703\n",
      "Eval_StdReturn : 7.163308620452881\n",
      "Eval_MaxReturn : 199.7478485107422\n",
      "Eval_MinReturn : 169.6597442626953\n",
      "Eval_AverageEpLen : 86.0\n",
      "Train_AverageReturn : 181.02059936523438\n",
      "Train_StdReturn : 7.069530487060547\n",
      "Train_MaxReturn : 200.19369506835938\n",
      "Train_MinReturn : 152.54791259765625\n",
      "Train_AverageEpLen : 84.42857142857143\n",
      "Train_EnvstepsSoFar : 130506\n",
      "TimeSinceStart : 72.43085813522339\n",
      "Training Loss : 0.20566338300704956\n",
      "Baseline Loss : 0.6199626326560974\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 173.2017059326172\n",
      "Eval_StdReturn : 21.47154426574707\n",
      "Eval_MaxReturn : 192.6562957763672\n",
      "Eval_MinReturn : 106.59678649902344\n",
      "Eval_AverageEpLen : 84.41666666666667\n",
      "Train_AverageReturn : 180.1875457763672\n",
      "Train_StdReturn : 8.431635856628418\n",
      "Train_MaxReturn : 210.32281494140625\n",
      "Train_MinReturn : 146.91043090820312\n",
      "Train_AverageEpLen : 85.07627118644068\n",
      "Train_EnvstepsSoFar : 140545\n",
      "TimeSinceStart : 77.91362285614014\n",
      "Training Loss : -2.3897995948791504\n",
      "Baseline Loss : 0.5769874453544617\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.28282165527344\n",
      "Eval_StdReturn : 24.775327682495117\n",
      "Eval_MaxReturn : 198.001220703125\n",
      "Eval_MinReturn : 121.16426849365234\n",
      "Eval_AverageEpLen : 84.91666666666667\n",
      "Train_AverageReturn : 175.403076171875\n",
      "Train_StdReturn : 20.779632568359375\n",
      "Train_MaxReturn : 213.4224853515625\n",
      "Train_MinReturn : 91.77891540527344\n",
      "Train_AverageEpLen : 84.52941176470588\n",
      "Train_EnvstepsSoFar : 150604\n",
      "TimeSinceStart : 83.37504005432129\n",
      "Training Loss : -4.266645908355713\n",
      "Baseline Loss : 0.6180883049964905\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 187.17709350585938\n",
      "Eval_StdReturn : 31.85967254638672\n",
      "Eval_MaxReturn : 273.0079650878906\n",
      "Eval_MinReturn : 143.00233459472656\n",
      "Eval_AverageEpLen : 91.0909090909091\n",
      "Train_AverageReturn : 175.6009521484375\n",
      "Train_StdReturn : 22.53838348388672\n",
      "Train_MaxReturn : 220.09930419921875\n",
      "Train_MinReturn : 102.0642318725586\n",
      "Train_AverageEpLen : 85.51282051282051\n",
      "Train_EnvstepsSoFar : 160609\n",
      "TimeSinceStart : 88.82511067390442\n",
      "Training Loss : -0.9736151695251465\n",
      "Baseline Loss : 0.6129235625267029\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10025 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 186.7889404296875\n",
      "Eval_StdReturn : 58.540828704833984\n",
      "Eval_MaxReturn : 271.00421142578125\n",
      "Eval_MinReturn : 67.38524627685547\n",
      "Eval_AverageEpLen : 90.91666666666667\n",
      "Train_AverageReturn : 191.78065490722656\n",
      "Train_StdReturn : 28.711193084716797\n",
      "Train_MaxReturn : 290.71112060546875\n",
      "Train_MinReturn : 106.84400177001953\n",
      "Train_AverageEpLen : 93.69158878504673\n",
      "Train_EnvstepsSoFar : 170634\n",
      "TimeSinceStart : 94.20127511024475\n",
      "Training Loss : 2.292072296142578\n",
      "Baseline Loss : 0.7775329947471619\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10099 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 203.1758270263672\n",
      "Eval_StdReturn : 64.67821502685547\n",
      "Eval_MaxReturn : 317.70526123046875\n",
      "Eval_MinReturn : 78.78457641601562\n",
      "Eval_AverageEpLen : 98.18181818181819\n",
      "Train_AverageReturn : 193.056884765625\n",
      "Train_StdReturn : 62.691287994384766\n",
      "Train_MaxReturn : 295.3216247558594\n",
      "Train_MinReturn : 56.88196563720703\n",
      "Train_AverageEpLen : 95.27358490566037\n",
      "Train_EnvstepsSoFar : 180733\n",
      "TimeSinceStart : 99.6123640537262\n",
      "Training Loss : -1.4998352527618408\n",
      "Baseline Loss : 1.0376415252685547\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10034 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 271.99005126953125\n",
      "Eval_StdReturn : 74.24333190917969\n",
      "Eval_MaxReturn : 380.23968505859375\n",
      "Eval_MinReturn : 115.19783020019531\n",
      "Eval_AverageEpLen : 119.11111111111111\n",
      "Train_AverageReturn : 210.38156127929688\n",
      "Train_StdReturn : 72.63740539550781\n",
      "Train_MaxReturn : 367.880615234375\n",
      "Train_MinReturn : 55.43694305419922\n",
      "Train_AverageEpLen : 100.34\n",
      "Train_EnvstepsSoFar : 190767\n",
      "TimeSinceStart : 104.94617533683777\n",
      "Training Loss : -5.440622329711914\n",
      "Baseline Loss : 1.225388526916504\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 322.52630615234375\n",
      "Eval_StdReturn : 58.264068603515625\n",
      "Eval_MaxReturn : 404.23779296875\n",
      "Eval_MinReturn : 213.19216918945312\n",
      "Eval_AverageEpLen : 141.25\n",
      "Train_AverageReturn : 274.63525390625\n",
      "Train_StdReturn : 67.07733154296875\n",
      "Train_MaxReturn : 387.4461669921875\n",
      "Train_MinReturn : 77.56938934326172\n",
      "Train_AverageEpLen : 125.35\n",
      "Train_EnvstepsSoFar : 200795\n",
      "TimeSinceStart : 110.32786083221436\n",
      "Training Loss : -5.1857147216796875\n",
      "Baseline Loss : 1.27937912940979\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 235.7635955810547\n",
      "Eval_StdReturn : 73.35696411132812\n",
      "Eval_MaxReturn : 339.32061767578125\n",
      "Eval_MinReturn : 126.02181243896484\n",
      "Eval_AverageEpLen : 111.66666666666667\n",
      "Train_AverageReturn : 308.69158935546875\n",
      "Train_StdReturn : 61.11882019042969\n",
      "Train_MaxReturn : 467.26068115234375\n",
      "Train_MinReturn : 116.10678100585938\n",
      "Train_AverageEpLen : 137.3835616438356\n",
      "Train_EnvstepsSoFar : 210824\n",
      "TimeSinceStart : 115.62992835044861\n",
      "Training Loss : -3.515509605407715\n",
      "Baseline Loss : 1.142944574356079\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 415.3388366699219\n",
      "Eval_StdReturn : 87.38005065917969\n",
      "Eval_MaxReturn : 546.50439453125\n",
      "Eval_MinReturn : 312.89447021484375\n",
      "Eval_AverageEpLen : 173.0\n",
      "Train_AverageReturn : 286.395263671875\n",
      "Train_StdReturn : 62.02177429199219\n",
      "Train_MaxReturn : 394.706787109375\n",
      "Train_MinReturn : 161.39590454101562\n",
      "Train_AverageEpLen : 130.66233766233765\n",
      "Train_EnvstepsSoFar : 220885\n",
      "TimeSinceStart : 121.00817537307739\n",
      "Training Loss : -6.589756965637207\n",
      "Baseline Loss : 1.126600742340088\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10177 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 335.204345703125\n",
      "Eval_StdReturn : 94.29281616210938\n",
      "Eval_MaxReturn : 481.1731872558594\n",
      "Eval_MinReturn : 236.79666137695312\n",
      "Eval_AverageEpLen : 177.66666666666666\n",
      "Train_AverageReturn : 306.9898986816406\n",
      "Train_StdReturn : 101.3265609741211\n",
      "Train_MaxReturn : 530.7459106445312\n",
      "Train_MinReturn : 134.78091430664062\n",
      "Train_AverageEpLen : 149.66176470588235\n",
      "Train_EnvstepsSoFar : 231062\n",
      "TimeSinceStart : 126.44523525238037\n",
      "Training Loss : -5.773602485656738\n",
      "Baseline Loss : 1.209254503250122\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 334.5563659667969\n",
      "Eval_StdReturn : 57.1640625\n",
      "Eval_MaxReturn : 426.6816711425781\n",
      "Eval_MinReturn : 231.916015625\n",
      "Eval_AverageEpLen : 164.85714285714286\n",
      "Train_AverageReturn : 317.2225036621094\n",
      "Train_StdReturn : 102.5794448852539\n",
      "Train_MaxReturn : 593.1279907226562\n",
      "Train_MinReturn : 121.98162841796875\n",
      "Train_AverageEpLen : 166.93333333333334\n",
      "Train_EnvstepsSoFar : 241078\n",
      "TimeSinceStart : 131.85558581352234\n",
      "Training Loss : -2.2069852352142334\n",
      "Baseline Loss : 1.1431699991226196\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 24 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 335.3497619628906\n",
      "Eval_StdReturn : 116.34750366210938\n",
      "Eval_MaxReturn : 485.532958984375\n",
      "Eval_MinReturn : 145.59970092773438\n",
      "Eval_AverageEpLen : 149.57142857142858\n",
      "Train_AverageReturn : 331.5821838378906\n",
      "Train_StdReturn : 92.09762573242188\n",
      "Train_MaxReturn : 521.1707763671875\n",
      "Train_MinReturn : 103.63835906982422\n",
      "Train_AverageEpLen : 164.9344262295082\n",
      "Train_EnvstepsSoFar : 251139\n",
      "TimeSinceStart : 137.224995136261\n",
      "Training Loss : 3.477299451828003\n",
      "Baseline Loss : 1.0247390270233154\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 25 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 341.2503967285156\n",
      "Eval_StdReturn : 38.79001235961914\n",
      "Eval_MaxReturn : 401.52825927734375\n",
      "Eval_MinReturn : 283.6888732910156\n",
      "Eval_AverageEpLen : 182.83333333333334\n",
      "Train_AverageReturn : 346.9765930175781\n",
      "Train_StdReturn : 72.17117309570312\n",
      "Train_MaxReturn : 513.353271484375\n",
      "Train_MinReturn : 106.89972686767578\n",
      "Train_AverageEpLen : 167.4\n",
      "Train_EnvstepsSoFar : 261183\n",
      "TimeSinceStart : 142.57938313484192\n",
      "Training Loss : 5.811610221862793\n",
      "Baseline Loss : 1.0386475324630737\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 26 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10064 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 312.9922790527344\n",
      "Eval_StdReturn : 68.93708038330078\n",
      "Eval_MaxReturn : 385.8204345703125\n",
      "Eval_MinReturn : 158.86807250976562\n",
      "Eval_AverageEpLen : 144.75\n",
      "Train_AverageReturn : 353.1994323730469\n",
      "Train_StdReturn : 67.44646453857422\n",
      "Train_MaxReturn : 525.603759765625\n",
      "Train_MinReturn : 150.83761596679688\n",
      "Train_AverageEpLen : 170.57627118644066\n",
      "Train_EnvstepsSoFar : 271247\n",
      "TimeSinceStart : 147.99460887908936\n",
      "Training Loss : 5.2293219566345215\n",
      "Baseline Loss : 0.9446970224380493\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 27 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10053 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 355.6050720214844\n",
      "Eval_StdReturn : 62.130821228027344\n",
      "Eval_MaxReturn : 479.0294494628906\n",
      "Eval_MinReturn : 296.06500244140625\n",
      "Eval_AverageEpLen : 158.42857142857142\n",
      "Train_AverageReturn : 332.30230712890625\n",
      "Train_StdReturn : 54.643035888671875\n",
      "Train_MaxReturn : 518.0242919921875\n",
      "Train_MinReturn : 157.59750366210938\n",
      "Train_AverageEpLen : 157.078125\n",
      "Train_EnvstepsSoFar : 281300\n",
      "TimeSinceStart : 153.44024515151978\n",
      "Training Loss : 3.733698606491089\n",
      "Baseline Loss : 0.8031468391418457\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 28 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 321.06292724609375\n",
      "Eval_StdReturn : 18.763973236083984\n",
      "Eval_MaxReturn : 342.9349365234375\n",
      "Eval_MinReturn : 291.6817626953125\n",
      "Eval_AverageEpLen : 153.71428571428572\n",
      "Train_AverageReturn : 326.0046691894531\n",
      "Train_StdReturn : 39.30336380004883\n",
      "Train_MaxReturn : 497.013671875\n",
      "Train_MinReturn : 246.56048583984375\n",
      "Train_AverageEpLen : 152.1060606060606\n",
      "Train_EnvstepsSoFar : 291339\n",
      "TimeSinceStart : 158.85890698432922\n",
      "Training Loss : 1.3088871240615845\n",
      "Baseline Loss : 0.7266815900802612\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 29 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10124 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 314.25531005859375\n",
      "Eval_StdReturn : 35.86334228515625\n",
      "Eval_MaxReturn : 395.5001220703125\n",
      "Eval_MinReturn : 278.1604309082031\n",
      "Eval_AverageEpLen : 148.42857142857142\n",
      "Train_AverageReturn : 318.686279296875\n",
      "Train_StdReturn : 32.01703643798828\n",
      "Train_MaxReturn : 396.80572509765625\n",
      "Train_MinReturn : 201.2987060546875\n",
      "Train_AverageEpLen : 151.1044776119403\n",
      "Train_EnvstepsSoFar : 301463\n",
      "TimeSinceStart : 164.29454350471497\n",
      "Training Loss : -0.9085433483123779\n",
      "Baseline Loss : 0.6875593066215515\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 30 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 308.2164611816406\n",
      "Eval_StdReturn : 11.269250869750977\n",
      "Eval_MaxReturn : 330.94854736328125\n",
      "Eval_MinReturn : 293.71533203125\n",
      "Eval_AverageEpLen : 146.14285714285714\n",
      "Train_AverageReturn : 324.1322326660156\n",
      "Train_StdReturn : 27.2138729095459\n",
      "Train_MaxReturn : 382.70916748046875\n",
      "Train_MinReturn : 262.26043701171875\n",
      "Train_AverageEpLen : 154.12307692307692\n",
      "Train_EnvstepsSoFar : 311481\n",
      "TimeSinceStart : 169.6488606929779\n",
      "Training Loss : -1.4115800857543945\n",
      "Baseline Loss : 0.6683959364891052\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 31 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 322.00726318359375\n",
      "Eval_StdReturn : 25.139436721801758\n",
      "Eval_MaxReturn : 353.1358337402344\n",
      "Eval_MinReturn : 273.2731018066406\n",
      "Eval_AverageEpLen : 153.57142857142858\n",
      "Train_AverageReturn : 322.2619323730469\n",
      "Train_StdReturn : 30.91805648803711\n",
      "Train_MaxReturn : 393.4593200683594\n",
      "Train_MinReturn : 209.409423828125\n",
      "Train_AverageEpLen : 154.7076923076923\n",
      "Train_EnvstepsSoFar : 321537\n",
      "TimeSinceStart : 175.06584191322327\n",
      "Training Loss : -1.7865253686904907\n",
      "Baseline Loss : 0.6185401082038879\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 32 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 318.8457336425781\n",
      "Eval_StdReturn : 49.894893646240234\n",
      "Eval_MaxReturn : 392.7906494140625\n",
      "Eval_MinReturn : 265.739501953125\n",
      "Eval_AverageEpLen : 143.28571428571428\n",
      "Train_AverageReturn : 312.18426513671875\n",
      "Train_StdReturn : 35.89979553222656\n",
      "Train_MaxReturn : 398.45440673828125\n",
      "Train_MinReturn : 203.4994659423828\n",
      "Train_AverageEpLen : 147.6764705882353\n",
      "Train_EnvstepsSoFar : 331579\n",
      "TimeSinceStart : 180.44014716148376\n",
      "Training Loss : -0.49792513251304626\n",
      "Baseline Loss : 0.5863867402076721\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 33 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10117 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 310.7181396484375\n",
      "Eval_StdReturn : 83.7505111694336\n",
      "Eval_MaxReturn : 516.5263061523438\n",
      "Eval_MinReturn : 251.60580444335938\n",
      "Eval_AverageEpLen : 138.0\n",
      "Train_AverageReturn : 311.7032775878906\n",
      "Train_StdReturn : 47.010009765625\n",
      "Train_MaxReturn : 522.4906616210938\n",
      "Train_MinReturn : 234.59378051757812\n",
      "Train_AverageEpLen : 144.52857142857144\n",
      "Train_EnvstepsSoFar : 341696\n",
      "TimeSinceStart : 185.92818212509155\n",
      "Training Loss : 0.6885281205177307\n",
      "Baseline Loss : 0.5817671418190002\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 34 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10080 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 305.3652648925781\n",
      "Eval_StdReturn : 64.18553924560547\n",
      "Eval_MaxReturn : 411.6390075683594\n",
      "Eval_MinReturn : 240.50660705566406\n",
      "Eval_AverageEpLen : 136.75\n",
      "Train_AverageReturn : 306.3110656738281\n",
      "Train_StdReturn : 55.13050079345703\n",
      "Train_MaxReturn : 526.67724609375\n",
      "Train_MinReturn : 155.1400604248047\n",
      "Train_AverageEpLen : 141.9718309859155\n",
      "Train_EnvstepsSoFar : 351776\n",
      "TimeSinceStart : 191.3333432674408\n",
      "Training Loss : 2.2910594940185547\n",
      "Baseline Loss : 0.5621342062950134\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 35 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 323.1725158691406\n",
      "Eval_StdReturn : 36.0604133605957\n",
      "Eval_MaxReturn : 368.3192138671875\n",
      "Eval_MinReturn : 263.5083923339844\n",
      "Eval_AverageEpLen : 140.875\n",
      "Train_AverageReturn : 306.2188720703125\n",
      "Train_StdReturn : 64.7972640991211\n",
      "Train_MaxReturn : 520.0917358398438\n",
      "Train_MinReturn : 236.71478271484375\n",
      "Train_AverageEpLen : 137.08219178082192\n",
      "Train_EnvstepsSoFar : 361783\n",
      "TimeSinceStart : 196.71072220802307\n",
      "Training Loss : 1.5265103578567505\n",
      "Baseline Loss : 0.5755065083503723\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 36 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10106 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 274.6171875\n",
      "Eval_StdReturn : 43.911739349365234\n",
      "Eval_MaxReturn : 373.7208557128906\n",
      "Eval_MinReturn : 238.71923828125\n",
      "Eval_AverageEpLen : 120.11111111111111\n",
      "Train_AverageReturn : 316.3329162597656\n",
      "Train_StdReturn : 68.63176727294922\n",
      "Train_MaxReturn : 523.8038330078125\n",
      "Train_MinReturn : 199.0860137939453\n",
      "Train_AverageEpLen : 136.56756756756758\n",
      "Train_EnvstepsSoFar : 371889\n",
      "TimeSinceStart : 202.15160751342773\n",
      "Training Loss : -2.5236523151397705\n",
      "Baseline Loss : 0.6192798018455505\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 37 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 272.0242919921875\n",
      "Eval_StdReturn : 84.82015228271484\n",
      "Eval_MaxReturn : 370.39593505859375\n",
      "Eval_MinReturn : 121.24134063720703\n",
      "Eval_AverageEpLen : 116.77777777777777\n",
      "Train_AverageReturn : 305.94268798828125\n",
      "Train_StdReturn : 63.50410461425781\n",
      "Train_MaxReturn : 482.7937927246094\n",
      "Train_MinReturn : 132.86131286621094\n",
      "Train_AverageEpLen : 130.41558441558442\n",
      "Train_EnvstepsSoFar : 381931\n",
      "TimeSinceStart : 207.48587346076965\n",
      "Training Loss : -4.484245777130127\n",
      "Baseline Loss : 0.6683422923088074\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 38 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 376.16680908203125\n",
      "Eval_StdReturn : 79.66122436523438\n",
      "Eval_MaxReturn : 512.760498046875\n",
      "Eval_MinReturn : 227.42288208007812\n",
      "Eval_AverageEpLen : 138.5\n",
      "Train_AverageReturn : 306.08404541015625\n",
      "Train_StdReturn : 86.71709442138672\n",
      "Train_MaxReturn : 556.5418701171875\n",
      "Train_MinReturn : 105.85303497314453\n",
      "Train_AverageEpLen : 125.45\n",
      "Train_EnvstepsSoFar : 391967\n",
      "TimeSinceStart : 212.91858339309692\n",
      "Training Loss : -9.664329528808594\n",
      "Baseline Loss : 0.7820253372192383\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 39 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10132 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 274.38507080078125\n",
      "Eval_StdReturn : 125.83836364746094\n",
      "Eval_MaxReturn : 477.988037109375\n",
      "Eval_MinReturn : 110.90985107421875\n",
      "Eval_AverageEpLen : 109.5\n",
      "Train_AverageReturn : 291.7118835449219\n",
      "Train_StdReturn : 88.64189910888672\n",
      "Train_MaxReturn : 497.36993408203125\n",
      "Train_MinReturn : 108.80774688720703\n",
      "Train_AverageEpLen : 119.2\n",
      "Train_EnvstepsSoFar : 402099\n",
      "TimeSinceStart : 218.3325638771057\n",
      "Training Loss : -9.450987815856934\n",
      "Baseline Loss : 0.9025610685348511\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 40 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10116 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 234.7569580078125\n",
      "Eval_StdReturn : 93.48007202148438\n",
      "Eval_MaxReturn : 399.4351501464844\n",
      "Eval_MinReturn : 110.68479919433594\n",
      "Eval_AverageEpLen : 101.7\n",
      "Train_AverageReturn : 306.330322265625\n",
      "Train_StdReturn : 102.50334930419922\n",
      "Train_MaxReturn : 494.57489013671875\n",
      "Train_MinReturn : 108.6594467163086\n",
      "Train_AverageEpLen : 120.42857142857143\n",
      "Train_EnvstepsSoFar : 412215\n",
      "TimeSinceStart : 223.74902248382568\n",
      "Training Loss : -7.186313629150391\n",
      "Baseline Loss : 0.8419914245605469\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 41 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10145 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 319.8511962890625\n",
      "Eval_StdReturn : 86.5077896118164\n",
      "Eval_MaxReturn : 508.1746826171875\n",
      "Eval_MinReturn : 216.2078399658203\n",
      "Eval_AverageEpLen : 124.11111111111111\n",
      "Train_AverageReturn : 304.0230407714844\n",
      "Train_StdReturn : 72.38182830810547\n",
      "Train_MaxReturn : 493.6741638183594\n",
      "Train_MinReturn : 100.60983276367188\n",
      "Train_AverageEpLen : 120.77380952380952\n",
      "Train_EnvstepsSoFar : 422360\n",
      "TimeSinceStart : 229.23513412475586\n",
      "Training Loss : 1.431032657623291\n",
      "Baseline Loss : 0.8820124268531799\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 42 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 332.8041076660156\n",
      "Eval_StdReturn : 31.559724807739258\n",
      "Eval_MaxReturn : 412.8039855957031\n",
      "Eval_MinReturn : 307.6473083496094\n",
      "Eval_AverageEpLen : 126.125\n",
      "Train_AverageReturn : 316.7742614746094\n",
      "Train_StdReturn : 70.40830993652344\n",
      "Train_MaxReturn : 462.8369140625\n",
      "Train_MinReturn : 110.93331909179688\n",
      "Train_AverageEpLen : 122.52439024390245\n",
      "Train_EnvstepsSoFar : 432407\n",
      "TimeSinceStart : 234.61776041984558\n",
      "Training Loss : 5.582462787628174\n",
      "Baseline Loss : 0.8429166078567505\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 43 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10017 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 332.6631774902344\n",
      "Eval_StdReturn : 25.483631134033203\n",
      "Eval_MaxReturn : 365.0325012207031\n",
      "Eval_MinReturn : 268.1255187988281\n",
      "Eval_AverageEpLen : 125.11111111111111\n",
      "Train_AverageReturn : 319.86871337890625\n",
      "Train_StdReturn : 48.65732955932617\n",
      "Train_MaxReturn : 451.32708740234375\n",
      "Train_MinReturn : 162.78256225585938\n",
      "Train_AverageEpLen : 123.66666666666667\n",
      "Train_EnvstepsSoFar : 442424\n",
      "TimeSinceStart : 240.04263067245483\n",
      "Training Loss : 8.48666763305664\n",
      "Baseline Loss : 0.853803813457489\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 44 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 367.171630859375\n",
      "Eval_StdReturn : 88.44232940673828\n",
      "Eval_MaxReturn : 537.8522338867188\n",
      "Eval_MinReturn : 262.7798156738281\n",
      "Eval_AverageEpLen : 146.14285714285714\n",
      "Train_AverageReturn : 322.1885681152344\n",
      "Train_StdReturn : 63.969120025634766\n",
      "Train_MaxReturn : 475.5986633300781\n",
      "Train_MinReturn : 140.20631408691406\n",
      "Train_AverageEpLen : 125.0\n",
      "Train_EnvstepsSoFar : 452424\n",
      "TimeSinceStart : 245.34446382522583\n",
      "Training Loss : 9.812546730041504\n",
      "Baseline Loss : 0.8209685683250427\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 45 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10139 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 441.5738220214844\n",
      "Eval_StdReturn : 78.77046203613281\n",
      "Eval_MaxReturn : 536.6802368164062\n",
      "Eval_MinReturn : 307.67364501953125\n",
      "Eval_AverageEpLen : 167.0\n",
      "Train_AverageReturn : 375.3280029296875\n",
      "Train_StdReturn : 74.43212127685547\n",
      "Train_MaxReturn : 534.44287109375\n",
      "Train_MinReturn : 149.14996337890625\n",
      "Train_AverageEpLen : 138.8904109589041\n",
      "Train_EnvstepsSoFar : 462563\n",
      "TimeSinceStart : 250.76125073432922\n",
      "Training Loss : 10.092544555664062\n",
      "Baseline Loss : 0.7222468256950378\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 46 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10118 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 431.655029296875\n",
      "Eval_StdReturn : 58.814449310302734\n",
      "Eval_MaxReturn : 547.6201171875\n",
      "Eval_MinReturn : 373.12896728515625\n",
      "Eval_AverageEpLen : 167.0\n",
      "Train_AverageReturn : 408.0883483886719\n",
      "Train_StdReturn : 64.43700408935547\n",
      "Train_MaxReturn : 538.8997802734375\n",
      "Train_MinReturn : 220.58285522460938\n",
      "Train_AverageEpLen : 153.3030303030303\n",
      "Train_EnvstepsSoFar : 472681\n",
      "TimeSinceStart : 256.1358563899994\n",
      "Training Loss : 6.567860126495361\n",
      "Baseline Loss : 0.7742206454277039\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 47 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10153 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 403.6874084472656\n",
      "Eval_StdReturn : 126.70540618896484\n",
      "Eval_MaxReturn : 572.1986083984375\n",
      "Eval_MinReturn : 175.64178466796875\n",
      "Eval_AverageEpLen : 171.33333333333334\n",
      "Train_AverageReturn : 419.29559326171875\n",
      "Train_StdReturn : 96.61959075927734\n",
      "Train_MaxReturn : 595.9776611328125\n",
      "Train_MinReturn : 158.47381591796875\n",
      "Train_AverageEpLen : 166.44262295081967\n",
      "Train_EnvstepsSoFar : 482834\n",
      "TimeSinceStart : 261.55564856529236\n",
      "Training Loss : 2.8207380771636963\n",
      "Baseline Loss : 0.8328686356544495\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 48 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10200 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 422.4424133300781\n",
      "Eval_StdReturn : 99.06166076660156\n",
      "Eval_MaxReturn : 511.8377990722656\n",
      "Eval_MinReturn : 234.6488037109375\n",
      "Eval_AverageEpLen : 186.16666666666666\n",
      "Train_AverageReturn : 401.8524169921875\n",
      "Train_StdReturn : 113.58015441894531\n",
      "Train_MaxReturn : 578.87255859375\n",
      "Train_MinReturn : 155.3983917236328\n",
      "Train_AverageEpLen : 172.88135593220338\n",
      "Train_EnvstepsSoFar : 493034\n",
      "TimeSinceStart : 267.078560590744\n",
      "Training Loss : 2.522111654281616\n",
      "Baseline Loss : 0.858530580997467\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 49 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10111 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 344.3554992675781\n",
      "Eval_StdReturn : 106.13922882080078\n",
      "Eval_MaxReturn : 449.66400146484375\n",
      "Eval_MinReturn : 114.88845825195312\n",
      "Eval_AverageEpLen : 162.57142857142858\n",
      "Train_AverageReturn : 332.4182434082031\n",
      "Train_StdReturn : 135.20567321777344\n",
      "Train_MaxReturn : 569.6663818359375\n",
      "Train_MinReturn : 63.59092330932617\n",
      "Train_AverageEpLen : 168.51666666666668\n",
      "Train_EnvstepsSoFar : 503145\n",
      "TimeSinceStart : 272.467933177948\n",
      "Training Loss : 2.551177740097046\n",
      "Baseline Loss : 0.8679448962211609\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10070 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 419.4911804199219\n",
      "Eval_StdReturn : 87.09473419189453\n",
      "Eval_MaxReturn : 605.06005859375\n",
      "Eval_MinReturn : 335.172119140625\n",
      "Eval_AverageEpLen : 190.16666666666666\n",
      "Train_AverageReturn : 328.0338134765625\n",
      "Train_StdReturn : 96.91079711914062\n",
      "Train_MaxReturn : 557.7784423828125\n",
      "Train_MinReturn : 80.76495361328125\n",
      "Train_AverageEpLen : 167.83333333333334\n",
      "Train_EnvstepsSoFar : 513215\n",
      "TimeSinceStart : 277.7855830192566\n",
      "Training Loss : 0.7056861519813538\n",
      "Baseline Loss : 0.8648421764373779\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10159 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 509.5135498046875\n",
      "Eval_StdReturn : 104.1866683959961\n",
      "Eval_MaxReturn : 623.319091796875\n",
      "Eval_MinReturn : 346.7140197753906\n",
      "Eval_AverageEpLen : 188.66666666666666\n",
      "Train_AverageReturn : 384.924560546875\n",
      "Train_StdReturn : 104.32969665527344\n",
      "Train_MaxReturn : 608.5115966796875\n",
      "Train_MinReturn : 171.3522186279297\n",
      "Train_AverageEpLen : 178.2280701754386\n",
      "Train_EnvstepsSoFar : 523374\n",
      "TimeSinceStart : 283.1979293823242\n",
      "Training Loss : -5.882318496704102\n",
      "Baseline Loss : 0.8013703227043152\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10127 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 315.8541259765625\n",
      "Eval_StdReturn : 47.79174041748047\n",
      "Eval_MaxReturn : 375.04742431640625\n",
      "Eval_MinReturn : 238.10086059570312\n",
      "Eval_AverageEpLen : 125.5\n",
      "Train_AverageReturn : 355.13873291015625\n",
      "Train_StdReturn : 109.79523468017578\n",
      "Train_MaxReturn : 590.4385986328125\n",
      "Train_MinReturn : 151.4324188232422\n",
      "Train_AverageEpLen : 155.8\n",
      "Train_EnvstepsSoFar : 533501\n",
      "TimeSinceStart : 288.54406547546387\n",
      "Training Loss : -9.300066947937012\n",
      "Baseline Loss : 0.871322751045227\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10125 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 273.3210144042969\n",
      "Eval_StdReturn : 55.34762191772461\n",
      "Eval_MaxReturn : 347.788818359375\n",
      "Eval_MinReturn : 178.25784301757812\n",
      "Eval_AverageEpLen : 112.77777777777777\n",
      "Train_AverageReturn : 309.9907531738281\n",
      "Train_StdReturn : 90.93773651123047\n",
      "Train_MaxReturn : 600.1387939453125\n",
      "Train_MinReturn : 172.25108337402344\n",
      "Train_AverageEpLen : 123.47560975609755\n",
      "Train_EnvstepsSoFar : 543626\n",
      "TimeSinceStart : 293.9493658542633\n",
      "Training Loss : -9.196205139160156\n",
      "Baseline Loss : 1.0432236194610596\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10109 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 339.04608154296875\n",
      "Eval_StdReturn : 97.38607788085938\n",
      "Eval_MaxReturn : 544.873291015625\n",
      "Eval_MinReturn : 200.5859832763672\n",
      "Eval_AverageEpLen : 134.125\n",
      "Train_AverageReturn : 320.71923828125\n",
      "Train_StdReturn : 86.18955993652344\n",
      "Train_MaxReturn : 608.0303344726562\n",
      "Train_MinReturn : 166.65480041503906\n",
      "Train_AverageEpLen : 124.80246913580247\n",
      "Train_EnvstepsSoFar : 553735\n",
      "TimeSinceStart : 299.4399905204773\n",
      "Training Loss : -12.926828384399414\n",
      "Baseline Loss : 1.03199303150177\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 454.49786376953125\n",
      "Eval_StdReturn : 110.3853530883789\n",
      "Eval_MaxReturn : 579.3756713867188\n",
      "Eval_MinReturn : 270.51019287109375\n",
      "Eval_AverageEpLen : 169.0\n",
      "Train_AverageReturn : 381.859130859375\n",
      "Train_StdReturn : 106.68876647949219\n",
      "Train_MaxReturn : 620.6075439453125\n",
      "Train_MinReturn : 166.464599609375\n",
      "Train_AverageEpLen : 145.6086956521739\n",
      "Train_EnvstepsSoFar : 563782\n",
      "TimeSinceStart : 304.9552171230316\n",
      "Training Loss : -17.633085250854492\n",
      "Baseline Loss : 0.8350135087966919\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 384.4674377441406\n",
      "Eval_StdReturn : 45.409820556640625\n",
      "Eval_MaxReturn : 446.0567626953125\n",
      "Eval_MinReturn : 314.9161071777344\n",
      "Eval_AverageEpLen : 153.14285714285714\n",
      "Train_AverageReturn : 387.999755859375\n",
      "Train_StdReturn : 87.7841567993164\n",
      "Train_MaxReturn : 632.9932861328125\n",
      "Train_MinReturn : 218.91470336914062\n",
      "Train_AverageEpLen : 156.3125\n",
      "Train_EnvstepsSoFar : 573786\n",
      "TimeSinceStart : 310.38677763938904\n",
      "Training Loss : -10.843135833740234\n",
      "Baseline Loss : 0.7632951140403748\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 319.92333984375\n",
      "Eval_StdReturn : 43.49525451660156\n",
      "Eval_MaxReturn : 390.8439025878906\n",
      "Eval_MinReturn : 260.2223205566406\n",
      "Eval_AverageEpLen : 142.25\n",
      "Train_AverageReturn : 341.650146484375\n",
      "Train_StdReturn : 67.60879516601562\n",
      "Train_MaxReturn : 585.115234375\n",
      "Train_MinReturn : 243.70486450195312\n",
      "Train_AverageEpLen : 147.75\n",
      "Train_EnvstepsSoFar : 583833\n",
      "TimeSinceStart : 315.8031551837921\n",
      "Training Loss : 0.4027204215526581\n",
      "Baseline Loss : 0.7640056610107422\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 304.700927734375\n",
      "Eval_StdReturn : 61.713287353515625\n",
      "Eval_MaxReturn : 368.41314697265625\n",
      "Eval_MinReturn : 174.37466430664062\n",
      "Eval_AverageEpLen : 139.875\n",
      "Train_AverageReturn : 320.33099365234375\n",
      "Train_StdReturn : 69.52006530761719\n",
      "Train_MaxReturn : 537.4251098632812\n",
      "Train_MinReturn : 198.57870483398438\n",
      "Train_AverageEpLen : 145.04347826086956\n",
      "Train_EnvstepsSoFar : 593841\n",
      "TimeSinceStart : 321.1693539619446\n",
      "Training Loss : 8.057397842407227\n",
      "Baseline Loss : 0.779459536075592\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10091 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 250.9959259033203\n",
      "Eval_StdReturn : 18.486648559570312\n",
      "Eval_MaxReturn : 280.7129821777344\n",
      "Eval_MinReturn : 220.87100219726562\n",
      "Eval_AverageEpLen : 133.875\n",
      "Train_AverageReturn : 294.3490295410156\n",
      "Train_StdReturn : 77.40287780761719\n",
      "Train_MaxReturn : 518.27392578125\n",
      "Train_MinReturn : 140.2345428466797\n",
      "Train_AverageEpLen : 142.1267605633803\n",
      "Train_EnvstepsSoFar : 603932\n",
      "TimeSinceStart : 326.4760353565216\n",
      "Training Loss : 13.660396575927734\n",
      "Baseline Loss : 0.8742960691452026\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10064 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 283.0547790527344\n",
      "Eval_StdReturn : 19.409523010253906\n",
      "Eval_MaxReturn : 317.7894592285156\n",
      "Eval_MinReturn : 253.007568359375\n",
      "Eval_AverageEpLen : 141.375\n",
      "Train_AverageReturn : 292.63824462890625\n",
      "Train_StdReturn : 74.8813247680664\n",
      "Train_MaxReturn : 579.1808471679688\n",
      "Train_MinReturn : 150.74412536621094\n",
      "Train_AverageEpLen : 141.74647887323943\n",
      "Train_EnvstepsSoFar : 613996\n",
      "TimeSinceStart : 331.9046359062195\n",
      "Training Loss : 12.831153869628906\n",
      "Baseline Loss : 0.897100567817688\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10095 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 523.26904296875\n",
      "Eval_StdReturn : 49.73405456542969\n",
      "Eval_MaxReturn : 568.5153198242188\n",
      "Eval_MinReturn : 436.97503662109375\n",
      "Eval_AverageEpLen : 194.83333333333334\n",
      "Train_AverageReturn : 346.13067626953125\n",
      "Train_StdReturn : 107.59819793701172\n",
      "Train_MaxReturn : 551.4577026367188\n",
      "Train_MinReturn : 193.03854370117188\n",
      "Train_AverageEpLen : 155.30769230769232\n",
      "Train_EnvstepsSoFar : 624091\n",
      "TimeSinceStart : 337.276841878891\n",
      "Training Loss : 9.530287742614746\n",
      "Baseline Loss : 0.7621293067932129\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10082 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 480.6356201171875\n",
      "Eval_StdReturn : 31.68170928955078\n",
      "Eval_MaxReturn : 521.3775024414062\n",
      "Eval_MinReturn : 419.8076171875\n",
      "Eval_AverageEpLen : 188.66666666666666\n",
      "Train_AverageReturn : 443.59283447265625\n",
      "Train_StdReturn : 99.48593139648438\n",
      "Train_MaxReturn : 603.1441650390625\n",
      "Train_MinReturn : 242.5718994140625\n",
      "Train_AverageEpLen : 183.3090909090909\n",
      "Train_EnvstepsSoFar : 634173\n",
      "TimeSinceStart : 342.7280602455139\n",
      "Training Loss : 1.4986460208892822\n",
      "Baseline Loss : 0.785774827003479\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10135 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 460.7151794433594\n",
      "Eval_StdReturn : 60.02047348022461\n",
      "Eval_MaxReturn : 515.435302734375\n",
      "Eval_MinReturn : 347.0312194824219\n",
      "Eval_AverageEpLen : 178.5\n",
      "Train_AverageReturn : 473.884765625\n",
      "Train_StdReturn : 68.59235382080078\n",
      "Train_MaxReturn : 574.1538696289062\n",
      "Train_MinReturn : 278.95556640625\n",
      "Train_AverageEpLen : 187.6851851851852\n",
      "Train_EnvstepsSoFar : 644308\n",
      "TimeSinceStart : 348.10763692855835\n",
      "Training Loss : -5.0309882164001465\n",
      "Baseline Loss : 0.7976818680763245\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10113 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 477.5003356933594\n",
      "Eval_StdReturn : 77.83031463623047\n",
      "Eval_MaxReturn : 566.1925048828125\n",
      "Eval_MinReturn : 380.0848388671875\n",
      "Eval_AverageEpLen : 176.0\n",
      "Train_AverageReturn : 471.7472839355469\n",
      "Train_StdReturn : 76.02986145019531\n",
      "Train_MaxReturn : 660.7645874023438\n",
      "Train_MinReturn : 288.70318603515625\n",
      "Train_AverageEpLen : 180.58928571428572\n",
      "Train_EnvstepsSoFar : 654421\n",
      "TimeSinceStart : 353.4586329460144\n",
      "Training Loss : -9.011427879333496\n",
      "Baseline Loss : 0.7238978147506714\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10123 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 450.0320129394531\n",
      "Eval_StdReturn : 80.44889068603516\n",
      "Eval_MaxReturn : 601.87646484375\n",
      "Eval_MinReturn : 372.24530029296875\n",
      "Eval_AverageEpLen : 167.85714285714286\n",
      "Train_AverageReturn : 472.8191223144531\n",
      "Train_StdReturn : 67.1240005493164\n",
      "Train_MaxReturn : 594.2022094726562\n",
      "Train_MinReturn : 335.2936096191406\n",
      "Train_AverageEpLen : 180.76785714285714\n",
      "Train_EnvstepsSoFar : 664544\n",
      "TimeSinceStart : 358.9274191856384\n",
      "Training Loss : -10.332722663879395\n",
      "Baseline Loss : 0.7518677711486816\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 441.25970458984375\n",
      "Eval_StdReturn : 63.900970458984375\n",
      "Eval_MaxReturn : 572.3829956054688\n",
      "Eval_MinReturn : 371.1849365234375\n",
      "Eval_AverageEpLen : 161.71428571428572\n",
      "Train_AverageReturn : 460.5530700683594\n",
      "Train_StdReturn : 74.48211669921875\n",
      "Train_MaxReturn : 604.9286499023438\n",
      "Train_MinReturn : 355.4225158691406\n",
      "Train_AverageEpLen : 169.79661016949152\n",
      "Train_EnvstepsSoFar : 674562\n",
      "TimeSinceStart : 364.3000292778015\n",
      "Training Loss : -10.620894432067871\n",
      "Baseline Loss : 0.6042729616165161\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10079 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 491.7599792480469\n",
      "Eval_StdReturn : 89.28531646728516\n",
      "Eval_MaxReturn : 601.9107666015625\n",
      "Eval_MinReturn : 336.9657287597656\n",
      "Eval_AverageEpLen : 168.16666666666666\n",
      "Train_AverageReturn : 446.1686096191406\n",
      "Train_StdReturn : 86.06871795654297\n",
      "Train_MaxReturn : 597.0030517578125\n",
      "Train_MinReturn : 102.69266510009766\n",
      "Train_AverageEpLen : 162.56451612903226\n",
      "Train_EnvstepsSoFar : 684641\n",
      "TimeSinceStart : 369.62782073020935\n",
      "Training Loss : -8.029091835021973\n",
      "Baseline Loss : 0.5057961344718933\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 516.2662963867188\n",
      "Eval_StdReturn : 76.68468475341797\n",
      "Eval_MaxReturn : 625.6895751953125\n",
      "Eval_MinReturn : 428.6911315917969\n",
      "Eval_AverageEpLen : 181.5\n",
      "Train_AverageReturn : 449.9934387207031\n",
      "Train_StdReturn : 93.19525146484375\n",
      "Train_MaxReturn : 645.7154541015625\n",
      "Train_MinReturn : 103.53323364257812\n",
      "Train_AverageEpLen : 162.30645161290323\n",
      "Train_EnvstepsSoFar : 694704\n",
      "TimeSinceStart : 374.9821209907532\n",
      "Training Loss : -5.388340473175049\n",
      "Baseline Loss : 0.44707661867141724\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 386.248779296875\n",
      "Eval_StdReturn : 158.86856079101562\n",
      "Eval_MaxReturn : 601.9379272460938\n",
      "Eval_MinReturn : 97.4408950805664\n",
      "Eval_AverageEpLen : 148.85714285714286\n",
      "Train_AverageReturn : 422.95440673828125\n",
      "Train_StdReturn : 150.8429718017578\n",
      "Train_MaxReturn : 622.6634521484375\n",
      "Train_MinReturn : 100.28392791748047\n",
      "Train_AverageEpLen : 156.8125\n",
      "Train_EnvstepsSoFar : 704740\n",
      "TimeSinceStart : 380.2933249473572\n",
      "Training Loss : 0.2188367247581482\n",
      "Baseline Loss : 0.4783309996128082\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 316.1002197265625\n",
      "Eval_StdReturn : 163.4898681640625\n",
      "Eval_MaxReturn : 574.1878662109375\n",
      "Eval_MinReturn : 104.63053894042969\n",
      "Eval_AverageEpLen : 131.44444444444446\n",
      "Train_AverageReturn : 380.2359619140625\n",
      "Train_StdReturn : 161.96849060058594\n",
      "Train_MaxReturn : 614.3360595703125\n",
      "Train_MinReturn : 96.11432647705078\n",
      "Train_AverageEpLen : 151.75757575757575\n",
      "Train_EnvstepsSoFar : 714756\n",
      "TimeSinceStart : 385.6908288002014\n",
      "Training Loss : 4.484635353088379\n",
      "Baseline Loss : 0.5429602265357971\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10132 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 268.31219482421875\n",
      "Eval_StdReturn : 147.95802307128906\n",
      "Eval_MaxReturn : 550.035400390625\n",
      "Eval_MinReturn : 107.0662612915039\n",
      "Eval_AverageEpLen : 129.875\n",
      "Train_AverageReturn : 326.2142639160156\n",
      "Train_StdReturn : 177.96615600585938\n",
      "Train_MaxReturn : 615.779296875\n",
      "Train_MinReturn : 96.600830078125\n",
      "Train_AverageEpLen : 138.7945205479452\n",
      "Train_EnvstepsSoFar : 724888\n",
      "TimeSinceStart : 391.11095356941223\n",
      "Training Loss : 9.295402526855469\n",
      "Baseline Loss : 0.5849368572235107\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10049 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 306.1207580566406\n",
      "Eval_StdReturn : 130.1287078857422\n",
      "Eval_MaxReturn : 431.326904296875\n",
      "Eval_MinReturn : 109.08977508544922\n",
      "Eval_AverageEpLen : 144.625\n",
      "Train_AverageReturn : 321.1170959472656\n",
      "Train_StdReturn : 155.61514282226562\n",
      "Train_MaxReturn : 571.2828369140625\n",
      "Train_MinReturn : 88.53939819335938\n",
      "Train_AverageEpLen : 143.55714285714285\n",
      "Train_EnvstepsSoFar : 734937\n",
      "TimeSinceStart : 396.4896786212921\n",
      "Training Loss : 10.290360450744629\n",
      "Baseline Loss : 0.6400632858276367\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 384.5752868652344\n",
      "Eval_StdReturn : 135.71124267578125\n",
      "Eval_MaxReturn : 540.9153442382812\n",
      "Eval_MinReturn : 101.74534606933594\n",
      "Eval_AverageEpLen : 177.16666666666666\n",
      "Train_AverageReturn : 327.4766540527344\n",
      "Train_StdReturn : 133.93421936035156\n",
      "Train_MaxReturn : 556.0247802734375\n",
      "Train_MinReturn : 101.97035217285156\n",
      "Train_AverageEpLen : 151.57575757575756\n",
      "Train_EnvstepsSoFar : 744941\n",
      "TimeSinceStart : 401.82959055900574\n",
      "Training Loss : 8.109075546264648\n",
      "Baseline Loss : 0.777651846408844\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 373.9238586425781\n",
      "Eval_StdReturn : 78.54579162597656\n",
      "Eval_MaxReturn : 458.22296142578125\n",
      "Eval_MinReturn : 223.7337646484375\n",
      "Eval_AverageEpLen : 170.0\n",
      "Train_AverageReturn : 332.0777587890625\n",
      "Train_StdReturn : 117.62632751464844\n",
      "Train_MaxReturn : 604.0830688476562\n",
      "Train_MinReturn : 97.8667984008789\n",
      "Train_AverageEpLen : 156.6875\n",
      "Train_EnvstepsSoFar : 754969\n",
      "TimeSinceStart : 407.227961063385\n",
      "Training Loss : 8.126989364624023\n",
      "Baseline Loss : 0.7712383270263672\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10099 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 382.3511047363281\n",
      "Eval_StdReturn : 60.76966094970703\n",
      "Eval_MaxReturn : 464.2524108886719\n",
      "Eval_MinReturn : 292.25592041015625\n",
      "Eval_AverageEpLen : 164.57142857142858\n",
      "Train_AverageReturn : 360.3508605957031\n",
      "Train_StdReturn : 102.76309967041016\n",
      "Train_MaxReturn : 561.0072021484375\n",
      "Train_MinReturn : 116.3062973022461\n",
      "Train_AverageEpLen : 171.16949152542372\n",
      "Train_EnvstepsSoFar : 765068\n",
      "TimeSinceStart : 412.6731207370758\n",
      "Training Loss : 1.1452975273132324\n",
      "Baseline Loss : 0.7160164713859558\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10057 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 369.7059631347656\n",
      "Eval_StdReturn : 49.52723693847656\n",
      "Eval_MaxReturn : 422.6859130859375\n",
      "Eval_MinReturn : 287.58026123046875\n",
      "Eval_AverageEpLen : 170.16666666666666\n",
      "Train_AverageReturn : 372.1679382324219\n",
      "Train_StdReturn : 90.98649597167969\n",
      "Train_MaxReturn : 554.4844970703125\n",
      "Train_MinReturn : 147.30491638183594\n",
      "Train_AverageEpLen : 170.45762711864407\n",
      "Train_EnvstepsSoFar : 775125\n",
      "TimeSinceStart : 418.08309531211853\n",
      "Training Loss : -6.660450458526611\n",
      "Baseline Loss : 0.7458674907684326\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 440.369140625\n",
      "Eval_StdReturn : 31.01679039001465\n",
      "Eval_MaxReturn : 504.82012939453125\n",
      "Eval_MinReturn : 405.9334716796875\n",
      "Eval_AverageEpLen : 185.66666666666666\n",
      "Train_AverageReturn : 383.93743896484375\n",
      "Train_StdReturn : 100.91642761230469\n",
      "Train_MaxReturn : 543.5714111328125\n",
      "Train_MinReturn : 110.91445922851562\n",
      "Train_AverageEpLen : 168.06666666666666\n",
      "Train_EnvstepsSoFar : 785209\n",
      "TimeSinceStart : 423.52058005332947\n",
      "Training Loss : -12.780714988708496\n",
      "Baseline Loss : 0.6445138454437256\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10010 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 404.0666809082031\n",
      "Eval_StdReturn : 57.465538024902344\n",
      "Eval_MaxReturn : 504.5284118652344\n",
      "Eval_MinReturn : 314.56890869140625\n",
      "Eval_AverageEpLen : 164.28571428571428\n",
      "Train_AverageReturn : 427.4690246582031\n",
      "Train_StdReturn : 65.9157943725586\n",
      "Train_MaxReturn : 605.2976684570312\n",
      "Train_MinReturn : 174.0999755859375\n",
      "Train_AverageEpLen : 172.58620689655172\n",
      "Train_EnvstepsSoFar : 795219\n",
      "TimeSinceStart : 429.00774931907654\n",
      "Training Loss : -19.725568771362305\n",
      "Baseline Loss : 0.5907595157623291\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10173 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 446.07916259765625\n",
      "Eval_StdReturn : 58.08156967163086\n",
      "Eval_MaxReturn : 561.2324829101562\n",
      "Eval_MinReturn : 370.6702880859375\n",
      "Eval_AverageEpLen : 170.28571428571428\n",
      "Train_AverageReturn : 386.5331726074219\n",
      "Train_StdReturn : 79.30870056152344\n",
      "Train_MaxReturn : 517.8246459960938\n",
      "Train_MinReturn : 134.16976928710938\n",
      "Train_AverageEpLen : 158.953125\n",
      "Train_EnvstepsSoFar : 805392\n",
      "TimeSinceStart : 434.5242762565613\n",
      "Training Loss : -12.22984504699707\n",
      "Baseline Loss : 0.5678607225418091\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10122 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 366.5179138183594\n",
      "Eval_StdReturn : 35.879940032958984\n",
      "Eval_MaxReturn : 424.1595458984375\n",
      "Eval_MinReturn : 305.49896240234375\n",
      "Eval_AverageEpLen : 148.28571428571428\n",
      "Train_AverageReturn : 383.87176513671875\n",
      "Train_StdReturn : 70.41350555419922\n",
      "Train_MaxReturn : 573.4501342773438\n",
      "Train_MinReturn : 160.54078674316406\n",
      "Train_AverageEpLen : 151.07462686567163\n",
      "Train_EnvstepsSoFar : 815514\n",
      "TimeSinceStart : 439.98513770103455\n",
      "Training Loss : -8.542537689208984\n",
      "Baseline Loss : 0.5165519714355469\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10088 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 433.8641052246094\n",
      "Eval_StdReturn : 85.302734375\n",
      "Eval_MaxReturn : 583.629638671875\n",
      "Eval_MinReturn : 349.89569091796875\n",
      "Eval_AverageEpLen : 160.57142857142858\n",
      "Train_AverageReturn : 379.78192138671875\n",
      "Train_StdReturn : 69.43030548095703\n",
      "Train_MaxReturn : 584.794677734375\n",
      "Train_MinReturn : 207.41065979003906\n",
      "Train_AverageEpLen : 148.35294117647058\n",
      "Train_EnvstepsSoFar : 825602\n",
      "TimeSinceStart : 445.4515895843506\n",
      "Training Loss : 0.4495091140270233\n",
      "Baseline Loss : 0.47676366567611694\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 432.72796630859375\n",
      "Eval_StdReturn : 75.32179260253906\n",
      "Eval_MaxReturn : 561.3751831054688\n",
      "Eval_MinReturn : 353.2620544433594\n",
      "Eval_AverageEpLen : 167.85714285714286\n",
      "Train_AverageReturn : 400.9899597167969\n",
      "Train_StdReturn : 91.11369323730469\n",
      "Train_MaxReturn : 608.2603149414062\n",
      "Train_MinReturn : 138.53265380859375\n",
      "Train_AverageEpLen : 150.26865671641792\n",
      "Train_EnvstepsSoFar : 835670\n",
      "TimeSinceStart : 451.0050172805786\n",
      "Training Loss : 4.488190650939941\n",
      "Baseline Loss : 0.4117659032344818\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10074 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 430.65576171875\n",
      "Eval_StdReturn : 98.80168151855469\n",
      "Eval_MaxReturn : 613.7831420898438\n",
      "Eval_MinReturn : 333.1087646484375\n",
      "Eval_AverageEpLen : 156.0\n",
      "Train_AverageReturn : 397.3557434082031\n",
      "Train_StdReturn : 60.730133056640625\n",
      "Train_MaxReturn : 570.4686279296875\n",
      "Train_MinReturn : 258.5665283203125\n",
      "Train_AverageEpLen : 148.14705882352942\n",
      "Train_EnvstepsSoFar : 845744\n",
      "TimeSinceStart : 456.46836590766907\n",
      "Training Loss : 10.891724586486816\n",
      "Baseline Loss : 0.40620967745780945\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10181 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 378.24090576171875\n",
      "Eval_StdReturn : 15.60535717010498\n",
      "Eval_MaxReturn : 400.28863525390625\n",
      "Eval_MinReturn : 349.34765625\n",
      "Eval_AverageEpLen : 137.625\n",
      "Train_AverageReturn : 387.14581298828125\n",
      "Train_StdReturn : 61.35343551635742\n",
      "Train_MaxReturn : 532.0531005859375\n",
      "Train_MinReturn : 213.43173217773438\n",
      "Train_AverageEpLen : 145.44285714285715\n",
      "Train_EnvstepsSoFar : 855925\n",
      "TimeSinceStart : 461.98389172554016\n",
      "Training Loss : 9.65764331817627\n",
      "Baseline Loss : 0.42822012305259705\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10094 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 387.5897521972656\n",
      "Eval_StdReturn : 26.53624153137207\n",
      "Eval_MaxReturn : 431.5163269042969\n",
      "Eval_MinReturn : 337.4175109863281\n",
      "Eval_AverageEpLen : 139.625\n",
      "Train_AverageReturn : 393.48126220703125\n",
      "Train_StdReturn : 59.109291076660156\n",
      "Train_MaxReturn : 544.0348510742188\n",
      "Train_MinReturn : 172.95677185058594\n",
      "Train_AverageEpLen : 146.28985507246378\n",
      "Train_EnvstepsSoFar : 866019\n",
      "TimeSinceStart : 467.4686131477356\n",
      "Training Loss : 6.79427433013916\n",
      "Baseline Loss : 0.3492266535758972\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 398.0408020019531\n",
      "Eval_StdReturn : 29.340394973754883\n",
      "Eval_MaxReturn : 445.03173828125\n",
      "Eval_MinReturn : 355.97265625\n",
      "Eval_AverageEpLen : 148.0\n",
      "Train_AverageReturn : 398.4215087890625\n",
      "Train_StdReturn : 45.44805908203125\n",
      "Train_MaxReturn : 572.5623168945312\n",
      "Train_MinReturn : 297.71405029296875\n",
      "Train_AverageEpLen : 147.9558823529412\n",
      "Train_EnvstepsSoFar : 876080\n",
      "TimeSinceStart : 472.9570782184601\n",
      "Training Loss : 0.9821467995643616\n",
      "Baseline Loss : 0.2958066761493683\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10121 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 407.0683288574219\n",
      "Eval_StdReturn : 20.945493698120117\n",
      "Eval_MaxReturn : 434.25299072265625\n",
      "Eval_MinReturn : 373.7511291503906\n",
      "Eval_AverageEpLen : 148.42857142857142\n",
      "Train_AverageReturn : 402.00286865234375\n",
      "Train_StdReturn : 31.436485290527344\n",
      "Train_MaxReturn : 510.7706298828125\n",
      "Train_MinReturn : 336.3490905761719\n",
      "Train_AverageEpLen : 148.83823529411765\n",
      "Train_EnvstepsSoFar : 886201\n",
      "TimeSinceStart : 478.4474081993103\n",
      "Training Loss : -5.091577053070068\n",
      "Baseline Loss : 0.24466238915920258\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10096 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 387.0708312988281\n",
      "Eval_StdReturn : 13.077051162719727\n",
      "Eval_MaxReturn : 413.41094970703125\n",
      "Eval_MinReturn : 371.1589660644531\n",
      "Eval_AverageEpLen : 139.25\n",
      "Train_AverageReturn : 395.9182434082031\n",
      "Train_StdReturn : 26.691139221191406\n",
      "Train_MaxReturn : 484.96844482421875\n",
      "Train_MinReturn : 329.5400085449219\n",
      "Train_AverageEpLen : 146.31884057971016\n",
      "Train_EnvstepsSoFar : 896297\n",
      "TimeSinceStart : 483.96290493011475\n",
      "Training Loss : -10.330375671386719\n",
      "Baseline Loss : 0.2474697083234787\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10033 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 383.8437194824219\n",
      "Eval_StdReturn : 13.108085632324219\n",
      "Eval_MaxReturn : 400.6025390625\n",
      "Eval_MinReturn : 363.9485778808594\n",
      "Eval_AverageEpLen : 137.5\n",
      "Train_AverageReturn : 394.02459716796875\n",
      "Train_StdReturn : 29.834074020385742\n",
      "Train_MaxReturn : 463.53021240234375\n",
      "Train_MinReturn : 233.82394409179688\n",
      "Train_AverageEpLen : 143.32857142857142\n",
      "Train_EnvstepsSoFar : 906330\n",
      "TimeSinceStart : 489.48285579681396\n",
      "Training Loss : -11.435381889343262\n",
      "Baseline Loss : 0.21646179258823395\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 404.0341491699219\n",
      "Eval_StdReturn : 29.71974754333496\n",
      "Eval_MaxReturn : 428.2154846191406\n",
      "Eval_MinReturn : 347.8389892578125\n",
      "Eval_AverageEpLen : 143.71428571428572\n",
      "Train_AverageReturn : 392.9889221191406\n",
      "Train_StdReturn : 25.359634399414062\n",
      "Train_MaxReturn : 440.59722900390625\n",
      "Train_MinReturn : 291.2837829589844\n",
      "Train_AverageEpLen : 141.6338028169014\n",
      "Train_EnvstepsSoFar : 916386\n",
      "TimeSinceStart : 494.9792215824127\n",
      "Training Loss : -7.625793933868408\n",
      "Baseline Loss : 0.17872807383537292\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 368.9131774902344\n",
      "Eval_StdReturn : 74.11933898925781\n",
      "Eval_MaxReturn : 435.08563232421875\n",
      "Eval_MinReturn : 187.06668090820312\n",
      "Eval_AverageEpLen : 135.375\n",
      "Train_AverageReturn : 386.2508544921875\n",
      "Train_StdReturn : 43.64365005493164\n",
      "Train_MaxReturn : 438.521240234375\n",
      "Train_MinReturn : 173.00115966796875\n",
      "Train_AverageEpLen : 138.013698630137\n",
      "Train_EnvstepsSoFar : 926461\n",
      "TimeSinceStart : 500.399667263031\n",
      "Training Loss : -2.1124300956726074\n",
      "Baseline Loss : 0.21079787611961365\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 371.2379150390625\n",
      "Eval_StdReturn : 88.26996612548828\n",
      "Eval_MaxReturn : 430.87164306640625\n",
      "Eval_MinReturn : 140.46961975097656\n",
      "Eval_AverageEpLen : 134.625\n",
      "Train_AverageReturn : 392.7950439453125\n",
      "Train_StdReturn : 35.28520202636719\n",
      "Train_MaxReturn : 456.5555419921875\n",
      "Train_MinReturn : 184.7447052001953\n",
      "Train_AverageEpLen : 139.58333333333334\n",
      "Train_EnvstepsSoFar : 936511\n",
      "TimeSinceStart : 505.8183023929596\n",
      "Training Loss : 3.9787628650665283\n",
      "Baseline Loss : 0.1994967758655548\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 360.6431884765625\n",
      "Eval_StdReturn : 81.56836700439453\n",
      "Eval_MaxReturn : 424.4771423339844\n",
      "Eval_MinReturn : 150.52037048339844\n",
      "Eval_AverageEpLen : 129.5\n",
      "Train_AverageReturn : 391.4997253417969\n",
      "Train_StdReturn : 46.26322555541992\n",
      "Train_MaxReturn : 459.68853759765625\n",
      "Train_MinReturn : 147.45501708984375\n",
      "Train_AverageEpLen : 138.36986301369862\n",
      "Train_EnvstepsSoFar : 946612\n",
      "TimeSinceStart : 511.31423711776733\n",
      "Training Loss : 4.015936374664307\n",
      "Baseline Loss : 0.22933684289455414\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 397.2693786621094\n",
      "Eval_StdReturn : 16.350679397583008\n",
      "Eval_MaxReturn : 420.83477783203125\n",
      "Eval_MinReturn : 365.3910827636719\n",
      "Eval_AverageEpLen : 137.125\n",
      "Train_AverageReturn : 371.5501708984375\n",
      "Train_StdReturn : 75.04084014892578\n",
      "Train_MaxReturn : 478.3964538574219\n",
      "Train_MinReturn : 127.9265365600586\n",
      "Train_AverageEpLen : 131.8421052631579\n",
      "Train_EnvstepsSoFar : 956632\n",
      "TimeSinceStart : 516.7805109024048\n",
      "Training Loss : 0.25054359436035156\n",
      "Baseline Loss : 0.2729606628417969\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10101 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 424.9517517089844\n",
      "Eval_StdReturn : 15.61735725402832\n",
      "Eval_MaxReturn : 451.5904541015625\n",
      "Eval_MinReturn : 400.8204345703125\n",
      "Eval_AverageEpLen : 148.85714285714286\n",
      "Train_AverageReturn : 394.8451232910156\n",
      "Train_StdReturn : 56.95151138305664\n",
      "Train_MaxReturn : 450.2992858886719\n",
      "Train_MinReturn : 136.38385009765625\n",
      "Train_AverageEpLen : 138.36986301369862\n",
      "Train_EnvstepsSoFar : 966733\n",
      "TimeSinceStart : 522.2811119556427\n",
      "Training Loss : 0.17728455364704132\n",
      "Baseline Loss : 0.19683067500591278\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10049 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 417.828857421875\n",
      "Eval_StdReturn : 32.59693908691406\n",
      "Eval_MaxReturn : 469.76861572265625\n",
      "Eval_MinReturn : 383.911376953125\n",
      "Eval_AverageEpLen : 145.0\n",
      "Train_AverageReturn : 416.6982116699219\n",
      "Train_StdReturn : 25.60250473022461\n",
      "Train_MaxReturn : 563.9326171875\n",
      "Train_MinReturn : 370.48028564453125\n",
      "Train_AverageEpLen : 145.63768115942028\n",
      "Train_EnvstepsSoFar : 976782\n",
      "TimeSinceStart : 527.690721988678\n",
      "Training Loss : -0.6831972599029541\n",
      "Baseline Loss : 0.16835984587669373\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10076 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 418.316650390625\n",
      "Eval_StdReturn : 47.828895568847656\n",
      "Eval_MaxReturn : 518.82470703125\n",
      "Eval_MinReturn : 366.1069030761719\n",
      "Eval_AverageEpLen : 149.28571428571428\n",
      "Train_AverageReturn : 420.75848388671875\n",
      "Train_StdReturn : 50.34073257446289\n",
      "Train_MaxReturn : 537.3397216796875\n",
      "Train_MinReturn : 126.4856185913086\n",
      "Train_AverageEpLen : 148.1764705882353\n",
      "Train_EnvstepsSoFar : 986858\n",
      "TimeSinceStart : 533.1578712463379\n",
      "Training Loss : -2.2765445709228516\n",
      "Baseline Loss : 0.19075365364551544\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 404.5623779296875\n",
      "Eval_StdReturn : 20.639556884765625\n",
      "Eval_MaxReturn : 444.08294677734375\n",
      "Eval_MinReturn : 380.7357177734375\n",
      "Eval_AverageEpLen : 140.0\n",
      "Train_AverageReturn : 419.77618408203125\n",
      "Train_StdReturn : 29.380895614624023\n",
      "Train_MaxReturn : 526.6571044921875\n",
      "Train_MinReturn : 340.4543762207031\n",
      "Train_AverageEpLen : 147.10294117647058\n",
      "Train_EnvstepsSoFar : 996861\n",
      "TimeSinceStart : 538.6460912227631\n",
      "Training Loss : -5.2910308837890625\n",
      "Baseline Loss : 0.17628931999206543\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10062 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 354.21478271484375\n",
      "Eval_StdReturn : 96.277099609375\n",
      "Eval_MaxReturn : 437.8486633300781\n",
      "Eval_MinReturn : 120.47360229492188\n",
      "Eval_AverageEpLen : 127.875\n",
      "Train_AverageReturn : 409.9430236816406\n",
      "Train_StdReturn : 60.29134750366211\n",
      "Train_MaxReturn : 544.336181640625\n",
      "Train_MinReturn : 97.55168914794922\n",
      "Train_AverageEpLen : 143.74285714285713\n",
      "Train_EnvstepsSoFar : 1006923\n",
      "TimeSinceStart : 544.0635752677917\n",
      "Training Loss : -5.519506454467773\n",
      "Baseline Loss : 0.18028920888900757\n",
      "Initial_DataCollection_AverageReturn : 9.403343200683594\n",
      "Done logging...\n",
      "\n",
      "\n",
      "Running policy gradient experiment with seed 1\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/with_baseline/seed1\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 148.2198028564453\n",
      "Eval_StdReturn : 49.320343017578125\n",
      "Eval_MaxReturn : 282.9284362792969\n",
      "Eval_MinReturn : 91.20127868652344\n",
      "Eval_AverageEpLen : 85.16666666666667\n",
      "Train_AverageReturn : 12.80981159210205\n",
      "Train_StdReturn : 8.916619300842285\n",
      "Train_MaxReturn : 82.16194915771484\n",
      "Train_MinReturn : 3.158935546875\n",
      "Train_AverageEpLen : 18.567717996289424\n",
      "Train_EnvstepsSoFar : 10008\n",
      "TimeSinceStart : 6.247711181640625\n",
      "Training Loss : -3.385798692703247\n",
      "Baseline Loss : 1.002213954925537\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 192.3705596923828\n",
      "Eval_StdReturn : 28.211000442504883\n",
      "Eval_MaxReturn : 224.32205200195312\n",
      "Eval_MinReturn : 119.67744445800781\n",
      "Eval_AverageEpLen : 86.66666666666667\n",
      "Train_AverageReturn : 117.59848022460938\n",
      "Train_StdReturn : 49.94240951538086\n",
      "Train_MaxReturn : 269.623046875\n",
      "Train_MinReturn : 10.443258285522461\n",
      "Train_AverageEpLen : 70.67605633802818\n",
      "Train_EnvstepsSoFar : 20044\n",
      "TimeSinceStart : 11.757558107376099\n",
      "Training Loss : -15.496078491210938\n",
      "Baseline Loss : 1.367226481437683\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10090 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 93.77027893066406\n",
      "Eval_StdReturn : 50.189517974853516\n",
      "Eval_MaxReturn : 210.84178161621094\n",
      "Eval_MinReturn : 24.95073890686035\n",
      "Eval_AverageEpLen : 51.142857142857146\n",
      "Train_AverageReturn : 174.12628173828125\n",
      "Train_StdReturn : 44.263221740722656\n",
      "Train_MaxReturn : 238.38720703125\n",
      "Train_MinReturn : 34.52737808227539\n",
      "Train_AverageEpLen : 81.37096774193549\n",
      "Train_EnvstepsSoFar : 30134\n",
      "TimeSinceStart : 17.352842807769775\n",
      "Training Loss : -4.126166820526123\n",
      "Baseline Loss : 1.1381962299346924\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10003 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 201.5777130126953\n",
      "Eval_StdReturn : 11.739424705505371\n",
      "Eval_MaxReturn : 218.4099884033203\n",
      "Eval_MinReturn : 176.54653930664062\n",
      "Eval_AverageEpLen : 89.5\n",
      "Train_AverageReturn : 106.33145141601562\n",
      "Train_StdReturn : 49.9329833984375\n",
      "Train_MaxReturn : 207.7410888671875\n",
      "Train_MinReturn : 26.239458084106445\n",
      "Train_AverageEpLen : 56.83522727272727\n",
      "Train_EnvstepsSoFar : 40137\n",
      "TimeSinceStart : 23.015756607055664\n",
      "Training Loss : 13.74686050415039\n",
      "Baseline Loss : 1.0407060384750366\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 153.30470275878906\n",
      "Eval_StdReturn : 32.117576599121094\n",
      "Eval_MaxReturn : 210.70123291015625\n",
      "Eval_MinReturn : 91.01847839355469\n",
      "Eval_AverageEpLen : 73.5\n",
      "Train_AverageReturn : 204.3638153076172\n",
      "Train_StdReturn : 19.104246139526367\n",
      "Train_MaxReturn : 221.79241943359375\n",
      "Train_MinReturn : 76.56852722167969\n",
      "Train_AverageEpLen : 90.5945945945946\n",
      "Train_EnvstepsSoFar : 50193\n",
      "TimeSinceStart : 28.58588409423828\n",
      "Training Loss : 10.389582633972168\n",
      "Baseline Loss : 1.029526948928833\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 140.67156982421875\n",
      "Eval_StdReturn : 32.58283996582031\n",
      "Eval_MaxReturn : 202.95782470703125\n",
      "Eval_MinReturn : 88.39884185791016\n",
      "Eval_AverageEpLen : 69.2\n",
      "Train_AverageReturn : 140.92047119140625\n",
      "Train_StdReturn : 34.96498489379883\n",
      "Train_MaxReturn : 214.6111297607422\n",
      "Train_MinReturn : 77.18682098388672\n",
      "Train_AverageEpLen : 69.02758620689656\n",
      "Train_EnvstepsSoFar : 60202\n",
      "TimeSinceStart : 34.17329549789429\n",
      "Training Loss : 0.7759995460510254\n",
      "Baseline Loss : 0.9197289943695068\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 177.4412384033203\n",
      "Eval_StdReturn : 32.644649505615234\n",
      "Eval_MaxReturn : 213.96884155273438\n",
      "Eval_MinReturn : 93.89090728759766\n",
      "Eval_AverageEpLen : 81.46153846153847\n",
      "Train_AverageReturn : 146.18138122558594\n",
      "Train_StdReturn : 31.58548927307129\n",
      "Train_MaxReturn : 212.50155639648438\n",
      "Train_MinReturn : 70.41962432861328\n",
      "Train_AverageEpLen : 71.04964539007092\n",
      "Train_EnvstepsSoFar : 70220\n",
      "TimeSinceStart : 39.717676639556885\n",
      "Training Loss : -3.508605718612671\n",
      "Baseline Loss : 0.8878947496414185\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10009 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 207.7749481201172\n",
      "Eval_StdReturn : 11.230498313903809\n",
      "Eval_MaxReturn : 215.23895263671875\n",
      "Eval_MinReturn : 173.62796020507812\n",
      "Eval_AverageEpLen : 91.36363636363636\n",
      "Train_AverageReturn : 189.51788330078125\n",
      "Train_StdReturn : 24.23662567138672\n",
      "Train_MaxReturn : 222.42279052734375\n",
      "Train_MinReturn : 97.7823715209961\n",
      "Train_AverageEpLen : 85.54700854700855\n",
      "Train_EnvstepsSoFar : 80229\n",
      "TimeSinceStart : 45.26099395751953\n",
      "Training Loss : -3.404606580734253\n",
      "Baseline Loss : 0.9406171441078186\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 205.24307250976562\n",
      "Eval_StdReturn : 7.348015308380127\n",
      "Eval_MaxReturn : 219.80853271484375\n",
      "Eval_MinReturn : 193.1233367919922\n",
      "Eval_AverageEpLen : 91.45454545454545\n",
      "Train_AverageReturn : 209.5861358642578\n",
      "Train_StdReturn : 8.140193939208984\n",
      "Train_MaxReturn : 239.38807678222656\n",
      "Train_MinReturn : 180.95101928710938\n",
      "Train_AverageEpLen : 92.14678899082568\n",
      "Train_EnvstepsSoFar : 90273\n",
      "TimeSinceStart : 50.7843816280365\n",
      "Training Loss : -1.059596300125122\n",
      "Baseline Loss : 0.9309501051902771\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10080 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 203.962158203125\n",
      "Eval_StdReturn : 7.669231414794922\n",
      "Eval_MaxReturn : 219.45169067382812\n",
      "Eval_MinReturn : 190.59388732910156\n",
      "Eval_AverageEpLen : 91.08333333333333\n",
      "Train_AverageReturn : 206.33287048339844\n",
      "Train_StdReturn : 7.614786624908447\n",
      "Train_MaxReturn : 232.18814086914062\n",
      "Train_MinReturn : 186.1775360107422\n",
      "Train_AverageEpLen : 91.63636363636364\n",
      "Train_EnvstepsSoFar : 100353\n",
      "TimeSinceStart : 56.386927127838135\n",
      "Training Loss : 0.7207571864128113\n",
      "Baseline Loss : 0.894548773765564\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 200.7992706298828\n",
      "Eval_StdReturn : 5.2316389083862305\n",
      "Eval_MaxReturn : 211.42201232910156\n",
      "Eval_MinReturn : 191.7964630126953\n",
      "Eval_AverageEpLen : 90.16666666666667\n",
      "Train_AverageReturn : 203.87046813964844\n",
      "Train_StdReturn : 7.8646931648254395\n",
      "Train_MaxReturn : 228.60780334472656\n",
      "Train_MinReturn : 184.09527587890625\n",
      "Train_AverageEpLen : 91.24545454545455\n",
      "Train_EnvstepsSoFar : 110390\n",
      "TimeSinceStart : 61.94400238990784\n",
      "Training Loss : 2.2960150241851807\n",
      "Baseline Loss : 0.8380053639411926\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 201.27503967285156\n",
      "Eval_StdReturn : 13.295849800109863\n",
      "Eval_MaxReturn : 239.94802856445312\n",
      "Eval_MinReturn : 182.407470703125\n",
      "Eval_AverageEpLen : 90.58333333333333\n",
      "Train_AverageReturn : 200.43667602539062\n",
      "Train_StdReturn : 9.774685859680176\n",
      "Train_MaxReturn : 240.99606323242188\n",
      "Train_MinReturn : 163.6046600341797\n",
      "Train_AverageEpLen : 90.4054054054054\n",
      "Train_EnvstepsSoFar : 120425\n",
      "TimeSinceStart : 67.54513239860535\n",
      "Training Loss : 3.1745693683624268\n",
      "Baseline Loss : 0.80019211769104\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10077 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 193.6775360107422\n",
      "Eval_StdReturn : 14.850085258483887\n",
      "Eval_MaxReturn : 230.1378173828125\n",
      "Eval_MinReturn : 162.54074096679688\n",
      "Eval_AverageEpLen : 88.25\n",
      "Train_AverageReturn : 198.78858947753906\n",
      "Train_StdReturn : 8.059844017028809\n",
      "Train_MaxReturn : 220.2805633544922\n",
      "Train_MinReturn : 181.6612548828125\n",
      "Train_AverageEpLen : 89.97321428571429\n",
      "Train_EnvstepsSoFar : 130502\n",
      "TimeSinceStart : 73.09455060958862\n",
      "Training Loss : 2.3689749240875244\n",
      "Baseline Loss : 0.7547551989555359\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10052 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 192.3389892578125\n",
      "Eval_StdReturn : 8.384306907653809\n",
      "Eval_MaxReturn : 207.3627471923828\n",
      "Eval_MinReturn : 178.62844848632812\n",
      "Eval_AverageEpLen : 88.0\n",
      "Train_AverageReturn : 192.99195861816406\n",
      "Train_StdReturn : 10.934684753417969\n",
      "Train_MaxReturn : 219.14309692382812\n",
      "Train_MinReturn : 135.66339111328125\n",
      "Train_AverageEpLen : 88.17543859649123\n",
      "Train_EnvstepsSoFar : 140554\n",
      "TimeSinceStart : 78.62910509109497\n",
      "Training Loss : 0.6659275889396667\n",
      "Baseline Loss : 0.7545562386512756\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10001 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 185.48802185058594\n",
      "Eval_StdReturn : 7.350386142730713\n",
      "Eval_MaxReturn : 196.34254455566406\n",
      "Eval_MinReturn : 168.86441040039062\n",
      "Eval_AverageEpLen : 86.0\n",
      "Train_AverageReturn : 190.61859130859375\n",
      "Train_StdReturn : 10.84511947631836\n",
      "Train_MaxReturn : 230.90615844726562\n",
      "Train_MinReturn : 154.4744110107422\n",
      "Train_AverageEpLen : 87.7280701754386\n",
      "Train_EnvstepsSoFar : 150555\n",
      "TimeSinceStart : 84.1683247089386\n",
      "Training Loss : -0.6692655682563782\n",
      "Baseline Loss : 0.7655131220817566\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10062 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 185.6059112548828\n",
      "Eval_StdReturn : 7.293797492980957\n",
      "Eval_MaxReturn : 198.7980499267578\n",
      "Eval_MinReturn : 173.7424774169922\n",
      "Eval_AverageEpLen : 86.83333333333333\n",
      "Train_AverageReturn : 190.4366455078125\n",
      "Train_StdReturn : 12.832829475402832\n",
      "Train_MaxReturn : 246.89315795898438\n",
      "Train_MinReturn : 169.29638671875\n",
      "Train_AverageEpLen : 88.26315789473684\n",
      "Train_EnvstepsSoFar : 160617\n",
      "TimeSinceStart : 89.70554566383362\n",
      "Training Loss : -1.1543209552764893\n",
      "Baseline Loss : 0.7947995066642761\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10092 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 193.856689453125\n",
      "Eval_StdReturn : 10.423090934753418\n",
      "Eval_MaxReturn : 211.89453125\n",
      "Eval_MinReturn : 175.25900268554688\n",
      "Eval_AverageEpLen : 89.33333333333333\n",
      "Train_AverageReturn : 192.65794372558594\n",
      "Train_StdReturn : 14.87477970123291\n",
      "Train_MaxReturn : 253.34457397460938\n",
      "Train_MinReturn : 162.6968994140625\n",
      "Train_AverageEpLen : 89.30973451327434\n",
      "Train_EnvstepsSoFar : 170709\n",
      "TimeSinceStart : 95.2906928062439\n",
      "Training Loss : -2.406747341156006\n",
      "Baseline Loss : 0.839356541633606\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10033 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 196.21685791015625\n",
      "Eval_StdReturn : 18.644664764404297\n",
      "Eval_MaxReturn : 229.7532196044922\n",
      "Eval_MinReturn : 174.1864776611328\n",
      "Eval_AverageEpLen : 96.45454545454545\n",
      "Train_AverageReturn : 193.18243408203125\n",
      "Train_StdReturn : 14.073458671569824\n",
      "Train_MaxReturn : 236.13754272460938\n",
      "Train_MinReturn : 170.4517364501953\n",
      "Train_AverageEpLen : 90.38738738738739\n",
      "Train_EnvstepsSoFar : 180742\n",
      "TimeSinceStart : 100.74728608131409\n",
      "Training Loss : -3.2457339763641357\n",
      "Baseline Loss : 0.8880482316017151\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 215.79965209960938\n",
      "Eval_StdReturn : 20.729772567749023\n",
      "Eval_MaxReturn : 238.02915954589844\n",
      "Eval_MinReturn : 174.81768798828125\n",
      "Eval_AverageEpLen : 103.5\n",
      "Train_AverageReturn : 197.04379272460938\n",
      "Train_StdReturn : 21.2705020904541\n",
      "Train_MaxReturn : 291.6867980957031\n",
      "Train_MinReturn : 160.69558715820312\n",
      "Train_AverageEpLen : 94.67924528301887\n",
      "Train_EnvstepsSoFar : 190778\n",
      "TimeSinceStart : 106.17778015136719\n",
      "Training Loss : -4.193146228790283\n",
      "Baseline Loss : 0.8506476283073425\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10099 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 240.72900390625\n",
      "Eval_StdReturn : 35.03240966796875\n",
      "Eval_MaxReturn : 304.1693115234375\n",
      "Eval_MinReturn : 198.7412567138672\n",
      "Eval_AverageEpLen : 111.55555555555556\n",
      "Train_AverageReturn : 210.98179626464844\n",
      "Train_StdReturn : 26.7012939453125\n",
      "Train_MaxReturn : 282.41497802734375\n",
      "Train_MinReturn : 158.15811157226562\n",
      "Train_AverageEpLen : 102.01010101010101\n",
      "Train_EnvstepsSoFar : 200877\n",
      "TimeSinceStart : 111.53715372085571\n",
      "Training Loss : -4.21994161605835\n",
      "Baseline Loss : 0.9686933159828186\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10021 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 220.0521240234375\n",
      "Eval_StdReturn : 35.185550689697266\n",
      "Eval_MaxReturn : 289.69989013671875\n",
      "Eval_MinReturn : 184.17408752441406\n",
      "Eval_AverageEpLen : 103.8\n",
      "Train_AverageReturn : 209.51165771484375\n",
      "Train_StdReturn : 37.35564041137695\n",
      "Train_MaxReturn : 294.19403076171875\n",
      "Train_MinReturn : 75.55465698242188\n",
      "Train_AverageEpLen : 102.25510204081633\n",
      "Train_EnvstepsSoFar : 210898\n",
      "TimeSinceStart : 116.89551568031311\n",
      "Training Loss : -5.441038131713867\n",
      "Baseline Loss : 0.9691770076751709\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10002 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 247.21414184570312\n",
      "Eval_StdReturn : 51.25339889526367\n",
      "Eval_MaxReturn : 328.21331787109375\n",
      "Eval_MinReturn : 158.60382080078125\n",
      "Eval_AverageEpLen : 114.88888888888889\n",
      "Train_AverageReturn : 205.82235717773438\n",
      "Train_StdReturn : 51.40532684326172\n",
      "Train_MaxReturn : 323.180908203125\n",
      "Train_MinReturn : 74.20059967041016\n",
      "Train_AverageEpLen : 100.02\n",
      "Train_EnvstepsSoFar : 220900\n",
      "TimeSinceStart : 122.24640560150146\n",
      "Training Loss : -4.81935977935791\n",
      "Baseline Loss : 1.0489637851715088\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10054 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 298.4144287109375\n",
      "Eval_StdReturn : 45.5565299987793\n",
      "Eval_MaxReturn : 364.3872985839844\n",
      "Eval_MinReturn : 236.17416381835938\n",
      "Eval_AverageEpLen : 125.625\n",
      "Train_AverageReturn : 232.7595977783203\n",
      "Train_StdReturn : 52.87023162841797\n",
      "Train_MaxReturn : 404.9229431152344\n",
      "Train_MinReturn : 91.63007354736328\n",
      "Train_AverageEpLen : 108.10752688172043\n",
      "Train_EnvstepsSoFar : 230954\n",
      "TimeSinceStart : 127.58735418319702\n",
      "Training Loss : -0.5798873901367188\n",
      "Baseline Loss : 1.0792566537857056\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 330.14422607421875\n",
      "Eval_StdReturn : 39.67045974731445\n",
      "Eval_MaxReturn : 380.5125732421875\n",
      "Eval_MinReturn : 279.9263610839844\n",
      "Eval_AverageEpLen : 137.875\n",
      "Train_AverageReturn : 278.3938903808594\n",
      "Train_StdReturn : 49.19959259033203\n",
      "Train_MaxReturn : 378.95147705078125\n",
      "Train_MinReturn : 162.88966369628906\n",
      "Train_AverageEpLen : 120.56626506024097\n",
      "Train_EnvstepsSoFar : 240961\n",
      "TimeSinceStart : 132.99659967422485\n",
      "Training Loss : 3.209660291671753\n",
      "Baseline Loss : 1.1298837661743164\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 24 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 324.86273193359375\n",
      "Eval_StdReturn : 53.95351028442383\n",
      "Eval_MaxReturn : 431.27947998046875\n",
      "Eval_MinReturn : 259.559814453125\n",
      "Eval_AverageEpLen : 138.5\n",
      "Train_AverageReturn : 292.7751159667969\n",
      "Train_StdReturn : 49.5229606628418\n",
      "Train_MaxReturn : 480.6692810058594\n",
      "Train_MinReturn : 198.60260009765625\n",
      "Train_AverageEpLen : 126.63291139240506\n",
      "Train_EnvstepsSoFar : 250965\n",
      "TimeSinceStart : 138.2916238307953\n",
      "Training Loss : 3.723325490951538\n",
      "Baseline Loss : 1.0561726093292236\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 25 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 306.768310546875\n",
      "Eval_StdReturn : 53.29528045654297\n",
      "Eval_MaxReturn : 380.08343505859375\n",
      "Eval_MinReturn : 221.0292205810547\n",
      "Eval_AverageEpLen : 136.375\n",
      "Train_AverageReturn : 313.70159912109375\n",
      "Train_StdReturn : 53.334251403808594\n",
      "Train_MaxReturn : 459.77880859375\n",
      "Train_MinReturn : 226.6717987060547\n",
      "Train_AverageEpLen : 135.22972972972974\n",
      "Train_EnvstepsSoFar : 260972\n",
      "TimeSinceStart : 143.67517495155334\n",
      "Training Loss : 1.7801612615585327\n",
      "Baseline Loss : 1.0269205570220947\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 26 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10098 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 356.7971496582031\n",
      "Eval_StdReturn : 33.13847732543945\n",
      "Eval_MaxReturn : 397.3232421875\n",
      "Eval_MinReturn : 296.67071533203125\n",
      "Eval_AverageEpLen : 148.42857142857142\n",
      "Train_AverageReturn : 333.0361328125\n",
      "Train_StdReturn : 52.211204528808594\n",
      "Train_MaxReturn : 467.3381042480469\n",
      "Train_MinReturn : 211.66148376464844\n",
      "Train_AverageEpLen : 142.22535211267606\n",
      "Train_EnvstepsSoFar : 271070\n",
      "TimeSinceStart : 149.0652756690979\n",
      "Training Loss : -0.4663601517677307\n",
      "Baseline Loss : 0.9770398736000061\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 27 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 381.1552734375\n",
      "Eval_StdReturn : 41.567073822021484\n",
      "Eval_MaxReturn : 455.10614013671875\n",
      "Eval_MinReturn : 324.8868408203125\n",
      "Eval_AverageEpLen : 161.57142857142858\n",
      "Train_AverageReturn : 335.2699890136719\n",
      "Train_StdReturn : 63.44383239746094\n",
      "Train_MaxReturn : 560.9439697265625\n",
      "Train_MinReturn : 205.36505126953125\n",
      "Train_AverageEpLen : 146.0144927536232\n",
      "Train_EnvstepsSoFar : 281145\n",
      "TimeSinceStart : 154.50018334388733\n",
      "Training Loss : -0.7497143745422363\n",
      "Baseline Loss : 0.916909396648407\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 28 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 295.07989501953125\n",
      "Eval_StdReturn : 104.85135650634766\n",
      "Eval_MaxReturn : 422.3409729003906\n",
      "Eval_MinReturn : 134.87716674804688\n",
      "Eval_AverageEpLen : 133.875\n",
      "Train_AverageReturn : 343.5094909667969\n",
      "Train_StdReturn : 74.73723602294922\n",
      "Train_MaxReturn : 535.52783203125\n",
      "Train_MinReturn : 144.38714599609375\n",
      "Train_AverageEpLen : 147.2941176470588\n",
      "Train_EnvstepsSoFar : 291161\n",
      "TimeSinceStart : 159.86635279655457\n",
      "Training Loss : -0.2349965125322342\n",
      "Baseline Loss : 0.8795486092567444\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 29 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10070 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 222.82470703125\n",
      "Eval_StdReturn : 96.2956314086914\n",
      "Eval_MaxReturn : 402.02020263671875\n",
      "Eval_MinReturn : 98.20420837402344\n",
      "Eval_AverageEpLen : 103.7\n",
      "Train_AverageReturn : 329.1203308105469\n",
      "Train_StdReturn : 100.66654205322266\n",
      "Train_MaxReturn : 560.6121826171875\n",
      "Train_MinReturn : 160.2576446533203\n",
      "Train_AverageEpLen : 141.83098591549296\n",
      "Train_EnvstepsSoFar : 301231\n",
      "TimeSinceStart : 165.2430112361908\n",
      "Training Loss : -0.7311083078384399\n",
      "Baseline Loss : 0.8803352117538452\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 30 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10062 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 250.80850219726562\n",
      "Eval_StdReturn : 137.6309814453125\n",
      "Eval_MaxReturn : 527.1441040039062\n",
      "Eval_MinReturn : 105.62835693359375\n",
      "Eval_AverageEpLen : 106.7\n",
      "Train_AverageReturn : 245.89697265625\n",
      "Train_StdReturn : 121.88092041015625\n",
      "Train_MaxReturn : 546.2225341796875\n",
      "Train_MinReturn : 107.21366119384766\n",
      "Train_AverageEpLen : 109.3695652173913\n",
      "Train_EnvstepsSoFar : 311293\n",
      "TimeSinceStart : 170.61424231529236\n",
      "Training Loss : -1.9642493724822998\n",
      "Baseline Loss : 0.9329574704170227\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 31 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10111 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 272.67962646484375\n",
      "Eval_StdReturn : 104.16332244873047\n",
      "Eval_MaxReturn : 425.52587890625\n",
      "Eval_MinReturn : 113.28044128417969\n",
      "Eval_AverageEpLen : 110.1\n",
      "Train_AverageReturn : 224.05001831054688\n",
      "Train_StdReturn : 119.56591796875\n",
      "Train_MaxReturn : 611.5105590820312\n",
      "Train_MinReturn : 79.93144989013672\n",
      "Train_AverageEpLen : 99.12745098039215\n",
      "Train_EnvstepsSoFar : 321404\n",
      "TimeSinceStart : 176.1029212474823\n",
      "Training Loss : -2.160853862762451\n",
      "Baseline Loss : 0.9616241455078125\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 32 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10103 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 348.46112060546875\n",
      "Eval_StdReturn : 100.41988372802734\n",
      "Eval_MaxReturn : 429.20281982421875\n",
      "Eval_MinReturn : 90.86669158935547\n",
      "Eval_AverageEpLen : 137.0\n",
      "Train_AverageReturn : 252.30197143554688\n",
      "Train_StdReturn : 126.31291198730469\n",
      "Train_MaxReturn : 524.741943359375\n",
      "Train_MinReturn : 83.7593765258789\n",
      "Train_AverageEpLen : 106.34736842105264\n",
      "Train_EnvstepsSoFar : 331507\n",
      "TimeSinceStart : 181.64981818199158\n",
      "Training Loss : -3.0225746631622314\n",
      "Baseline Loss : 0.9535811543464661\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 33 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 387.6800231933594\n",
      "Eval_StdReturn : 15.978405952453613\n",
      "Eval_MaxReturn : 407.4294128417969\n",
      "Eval_MinReturn : 357.1527099609375\n",
      "Eval_AverageEpLen : 147.85714285714286\n",
      "Train_AverageReturn : 372.5869140625\n",
      "Train_StdReturn : 78.62351989746094\n",
      "Train_MaxReturn : 469.79449462890625\n",
      "Train_MinReturn : 94.54551696777344\n",
      "Train_AverageEpLen : 141.35211267605635\n",
      "Train_EnvstepsSoFar : 341543\n",
      "TimeSinceStart : 187.07774686813354\n",
      "Training Loss : -2.125600576400757\n",
      "Baseline Loss : 0.7907829880714417\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 34 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10051 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 369.25823974609375\n",
      "Eval_StdReturn : 57.35061264038086\n",
      "Eval_MaxReturn : 453.3992919921875\n",
      "Eval_MinReturn : 294.9276123046875\n",
      "Eval_AverageEpLen : 135.75\n",
      "Train_AverageReturn : 382.8944396972656\n",
      "Train_StdReturn : 44.6842041015625\n",
      "Train_MaxReturn : 482.9919738769531\n",
      "Train_MinReturn : 241.36199951171875\n",
      "Train_AverageEpLen : 143.5857142857143\n",
      "Train_EnvstepsSoFar : 351594\n",
      "TimeSinceStart : 192.48236727714539\n",
      "Training Loss : -4.140035152435303\n",
      "Baseline Loss : 0.771686851978302\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 35 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10141 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 383.5171203613281\n",
      "Eval_StdReturn : 45.4070930480957\n",
      "Eval_MaxReturn : 426.69732666015625\n",
      "Eval_MinReturn : 269.1622314453125\n",
      "Eval_AverageEpLen : 142.625\n",
      "Train_AverageReturn : 375.54443359375\n",
      "Train_StdReturn : 52.00928497314453\n",
      "Train_MaxReturn : 515.1961669921875\n",
      "Train_MinReturn : 249.13047790527344\n",
      "Train_AverageEpLen : 140.84722222222223\n",
      "Train_EnvstepsSoFar : 361735\n",
      "TimeSinceStart : 197.94136333465576\n",
      "Training Loss : -5.369295597076416\n",
      "Baseline Loss : 0.801896333694458\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 36 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10022 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 405.97894287109375\n",
      "Eval_StdReturn : 30.383832931518555\n",
      "Eval_MaxReturn : 464.7274169921875\n",
      "Eval_MinReturn : 359.99725341796875\n",
      "Eval_AverageEpLen : 145.14285714285714\n",
      "Train_AverageReturn : 360.6046142578125\n",
      "Train_StdReturn : 50.33871841430664\n",
      "Train_MaxReturn : 500.5562744140625\n",
      "Train_MinReturn : 215.4739532470703\n",
      "Train_AverageEpLen : 137.2876712328767\n",
      "Train_EnvstepsSoFar : 371757\n",
      "TimeSinceStart : 203.30673503875732\n",
      "Training Loss : -5.7605977058410645\n",
      "Baseline Loss : 0.8251815438270569\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 37 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10124 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 369.47381591796875\n",
      "Eval_StdReturn : 40.982948303222656\n",
      "Eval_MaxReturn : 406.739990234375\n",
      "Eval_MinReturn : 288.6739501953125\n",
      "Eval_AverageEpLen : 137.625\n",
      "Train_AverageReturn : 385.0341491699219\n",
      "Train_StdReturn : 45.17082595825195\n",
      "Train_MaxReturn : 546.5181274414062\n",
      "Train_MinReturn : 286.50372314453125\n",
      "Train_AverageEpLen : 142.59154929577466\n",
      "Train_EnvstepsSoFar : 381881\n",
      "TimeSinceStart : 208.75326442718506\n",
      "Training Loss : -4.665491104125977\n",
      "Baseline Loss : 0.7291757464408875\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 38 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10064 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 430.53265380859375\n",
      "Eval_StdReturn : 56.05640411376953\n",
      "Eval_MaxReturn : 553.21337890625\n",
      "Eval_MinReturn : 377.7286071777344\n",
      "Eval_AverageEpLen : 156.85714285714286\n",
      "Train_AverageReturn : 396.7255554199219\n",
      "Train_StdReturn : 46.96284484863281\n",
      "Train_MaxReturn : 529.9349975585938\n",
      "Train_MinReturn : 272.6510009765625\n",
      "Train_AverageEpLen : 145.85507246376812\n",
      "Train_EnvstepsSoFar : 391945\n",
      "TimeSinceStart : 214.17721676826477\n",
      "Training Loss : -3.576626777648926\n",
      "Baseline Loss : 0.6472811102867126\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 39 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10100 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 387.75531005859375\n",
      "Eval_StdReturn : 19.428983688354492\n",
      "Eval_MaxReturn : 430.4531555175781\n",
      "Eval_MinReturn : 369.106201171875\n",
      "Eval_AverageEpLen : 146.14285714285714\n",
      "Train_AverageReturn : 391.9882507324219\n",
      "Train_StdReturn : 68.60411071777344\n",
      "Train_MaxReturn : 606.5450439453125\n",
      "Train_MinReturn : 144.00613403320312\n",
      "Train_AverageEpLen : 144.28571428571428\n",
      "Train_EnvstepsSoFar : 402045\n",
      "TimeSinceStart : 219.59972310066223\n",
      "Training Loss : -2.433779716491699\n",
      "Baseline Loss : 0.6219252943992615\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 40 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10039 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 413.8260192871094\n",
      "Eval_StdReturn : 53.13753890991211\n",
      "Eval_MaxReturn : 521.4610595703125\n",
      "Eval_MinReturn : 346.3841552734375\n",
      "Eval_AverageEpLen : 150.14285714285714\n",
      "Train_AverageReturn : 412.2422180175781\n",
      "Train_StdReturn : 54.09687042236328\n",
      "Train_MaxReturn : 621.3934326171875\n",
      "Train_MinReturn : 312.6532897949219\n",
      "Train_AverageEpLen : 149.83582089552237\n",
      "Train_EnvstepsSoFar : 412084\n",
      "TimeSinceStart : 224.9959921836853\n",
      "Training Loss : -2.1564598083496094\n",
      "Baseline Loss : 0.5684438347816467\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 41 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10129 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 431.6671447753906\n",
      "Eval_StdReturn : 67.79814147949219\n",
      "Eval_MaxReturn : 548.5908203125\n",
      "Eval_MinReturn : 335.6380310058594\n",
      "Eval_AverageEpLen : 157.71428571428572\n",
      "Train_AverageReturn : 397.7194519042969\n",
      "Train_StdReturn : 69.29662322998047\n",
      "Train_MaxReturn : 588.469970703125\n",
      "Train_MinReturn : 167.65536499023438\n",
      "Train_AverageEpLen : 146.79710144927537\n",
      "Train_EnvstepsSoFar : 422213\n",
      "TimeSinceStart : 230.41549801826477\n",
      "Training Loss : -2.5360584259033203\n",
      "Baseline Loss : 0.5892555713653564\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 42 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10113 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 433.34814453125\n",
      "Eval_StdReturn : 47.680213928222656\n",
      "Eval_MaxReturn : 505.7655029296875\n",
      "Eval_MinReturn : 387.97747802734375\n",
      "Eval_AverageEpLen : 155.28571428571428\n",
      "Train_AverageReturn : 418.04803466796875\n",
      "Train_StdReturn : 62.533199310302734\n",
      "Train_MaxReturn : 575.4827880859375\n",
      "Train_MinReturn : 324.9089660644531\n",
      "Train_AverageEpLen : 153.22727272727272\n",
      "Train_EnvstepsSoFar : 432326\n",
      "TimeSinceStart : 235.85372257232666\n",
      "Training Loss : -4.906295299530029\n",
      "Baseline Loss : 0.5654203295707703\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 43 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10070 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 394.9059143066406\n",
      "Eval_StdReturn : 110.18436431884766\n",
      "Eval_MaxReturn : 556.7916259765625\n",
      "Eval_MinReturn : 174.76629638671875\n",
      "Eval_AverageEpLen : 145.71428571428572\n",
      "Train_AverageReturn : 412.3170166015625\n",
      "Train_StdReturn : 68.71626281738281\n",
      "Train_MaxReturn : 619.8800048828125\n",
      "Train_MinReturn : 198.0750732421875\n",
      "Train_AverageEpLen : 152.57575757575756\n",
      "Train_EnvstepsSoFar : 442396\n",
      "TimeSinceStart : 241.27911281585693\n",
      "Training Loss : -3.719097137451172\n",
      "Baseline Loss : 0.5606118440628052\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 44 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10116 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 399.3804626464844\n",
      "Eval_StdReturn : 55.947994232177734\n",
      "Eval_MaxReturn : 489.2431640625\n",
      "Eval_MinReturn : 301.28399658203125\n",
      "Eval_AverageEpLen : 156.71428571428572\n",
      "Train_AverageReturn : 409.9577941894531\n",
      "Train_StdReturn : 79.88523864746094\n",
      "Train_MaxReturn : 585.3804931640625\n",
      "Train_MinReturn : 172.43809509277344\n",
      "Train_AverageEpLen : 150.98507462686567\n",
      "Train_EnvstepsSoFar : 452512\n",
      "TimeSinceStart : 246.69671964645386\n",
      "Training Loss : -3.891188383102417\n",
      "Baseline Loss : 0.5613270998001099\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 45 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 430.4853820800781\n",
      "Eval_StdReturn : 126.34375\n",
      "Eval_MaxReturn : 555.9658203125\n",
      "Eval_MinReturn : 256.18548583984375\n",
      "Eval_AverageEpLen : 168.0\n",
      "Train_AverageReturn : 423.5224609375\n",
      "Train_StdReturn : 87.89659118652344\n",
      "Train_MaxReturn : 603.3383178710938\n",
      "Train_MinReturn : 191.57058715820312\n",
      "Train_AverageEpLen : 157.125\n",
      "Train_EnvstepsSoFar : 462568\n",
      "TimeSinceStart : 252.07453751564026\n",
      "Training Loss : -5.493535995483398\n",
      "Baseline Loss : 0.5879465937614441\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 46 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10030 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 436.34356689453125\n",
      "Eval_StdReturn : 71.56147003173828\n",
      "Eval_MaxReturn : 576.1989135742188\n",
      "Eval_MinReturn : 343.2724609375\n",
      "Eval_AverageEpLen : 171.28571428571428\n",
      "Train_AverageReturn : 415.4955749511719\n",
      "Train_StdReturn : 80.83423614501953\n",
      "Train_MaxReturn : 577.4981689453125\n",
      "Train_MinReturn : 190.6222381591797\n",
      "Train_AverageEpLen : 156.71875\n",
      "Train_EnvstepsSoFar : 472598\n",
      "TimeSinceStart : 257.51767683029175\n",
      "Training Loss : -1.5193400382995605\n",
      "Baseline Loss : 0.5467508435249329\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 47 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 326.7469177246094\n",
      "Eval_StdReturn : 96.07989501953125\n",
      "Eval_MaxReturn : 479.3729553222656\n",
      "Eval_MinReturn : 216.6925811767578\n",
      "Eval_AverageEpLen : 172.0\n",
      "Train_AverageReturn : 413.8086242675781\n",
      "Train_StdReturn : 100.47001647949219\n",
      "Train_MaxReturn : 585.0279541015625\n",
      "Train_MinReturn : 151.95578002929688\n",
      "Train_AverageEpLen : 157.3125\n",
      "Train_EnvstepsSoFar : 482666\n",
      "TimeSinceStart : 262.8280653953552\n",
      "Training Loss : -0.8638045191764832\n",
      "Baseline Loss : 0.625762403011322\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 48 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10110 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 475.6905822753906\n",
      "Eval_StdReturn : 38.731056213378906\n",
      "Eval_MaxReturn : 524.5926513671875\n",
      "Eval_MinReturn : 425.2533874511719\n",
      "Eval_AverageEpLen : 194.5\n",
      "Train_AverageReturn : 428.7249450683594\n",
      "Train_StdReturn : 85.98375701904297\n",
      "Train_MaxReturn : 587.627197265625\n",
      "Train_MinReturn : 167.26547241210938\n",
      "Train_AverageEpLen : 168.5\n",
      "Train_EnvstepsSoFar : 492776\n",
      "TimeSinceStart : 268.2408838272095\n",
      "Training Loss : -0.6594557166099548\n",
      "Baseline Loss : 0.7157893776893616\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 49 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10054 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 463.2579650878906\n",
      "Eval_StdReturn : 62.128089904785156\n",
      "Eval_MaxReturn : 583.1756591796875\n",
      "Eval_MinReturn : 389.29937744140625\n",
      "Eval_AverageEpLen : 197.16666666666666\n",
      "Train_AverageReturn : 440.23455810546875\n",
      "Train_StdReturn : 93.70370483398438\n",
      "Train_MaxReturn : 576.8997802734375\n",
      "Train_MinReturn : 197.1922149658203\n",
      "Train_AverageEpLen : 182.8\n",
      "Train_EnvstepsSoFar : 502830\n",
      "TimeSinceStart : 273.60993123054504\n",
      "Training Loss : 3.054854393005371\n",
      "Baseline Loss : 0.8081347346305847\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10150 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 331.2413330078125\n",
      "Eval_StdReturn : 56.65397262573242\n",
      "Eval_MaxReturn : 393.23419189453125\n",
      "Eval_MinReturn : 247.73876953125\n",
      "Eval_AverageEpLen : 184.16666666666666\n",
      "Train_AverageReturn : 372.7506103515625\n",
      "Train_StdReturn : 124.11154174804688\n",
      "Train_MaxReturn : 592.9384155273438\n",
      "Train_MinReturn : 17.811031341552734\n",
      "Train_AverageEpLen : 175.0\n",
      "Train_EnvstepsSoFar : 512980\n",
      "TimeSinceStart : 278.9889888763428\n",
      "Training Loss : 11.42740249633789\n",
      "Baseline Loss : 0.8317145109176636\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10052 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 418.7419738769531\n",
      "Eval_StdReturn : 79.27312469482422\n",
      "Eval_MaxReturn : 551.1375122070312\n",
      "Eval_MinReturn : 345.46466064453125\n",
      "Eval_AverageEpLen : 175.5\n",
      "Train_AverageReturn : 392.359375\n",
      "Train_StdReturn : 113.45458984375\n",
      "Train_MaxReturn : 569.3033447265625\n",
      "Train_MinReturn : 20.97100830078125\n",
      "Train_AverageEpLen : 179.5\n",
      "Train_EnvstepsSoFar : 523032\n",
      "TimeSinceStart : 284.3516583442688\n",
      "Training Loss : 5.681648254394531\n",
      "Baseline Loss : 0.7486476302146912\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10104 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 460.0655212402344\n",
      "Eval_StdReturn : 39.27249526977539\n",
      "Eval_MaxReturn : 524.9418334960938\n",
      "Eval_MinReturn : 410.98834228515625\n",
      "Eval_AverageEpLen : 186.66666666666666\n",
      "Train_AverageReturn : 418.4809265136719\n",
      "Train_StdReturn : 108.62034606933594\n",
      "Train_MaxReturn : 591.8995361328125\n",
      "Train_MinReturn : 122.60232543945312\n",
      "Train_AverageEpLen : 177.26315789473685\n",
      "Train_EnvstepsSoFar : 533136\n",
      "TimeSinceStart : 289.7731423377991\n",
      "Training Loss : -7.975657939910889\n",
      "Baseline Loss : 0.7302970290184021\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10110 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 390.0285949707031\n",
      "Eval_StdReturn : 67.1295394897461\n",
      "Eval_MaxReturn : 515.0479125976562\n",
      "Eval_MinReturn : 298.0224609375\n",
      "Eval_AverageEpLen : 163.42857142857142\n",
      "Train_AverageReturn : 443.8846130371094\n",
      "Train_StdReturn : 88.06182098388672\n",
      "Train_MaxReturn : 586.69091796875\n",
      "Train_MinReturn : 241.32373046875\n",
      "Train_AverageEpLen : 180.53571428571428\n",
      "Train_EnvstepsSoFar : 543246\n",
      "TimeSinceStart : 295.1893117427826\n",
      "Training Loss : -14.217233657836914\n",
      "Baseline Loss : 0.7837491631507874\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10079 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 433.7098693847656\n",
      "Eval_StdReturn : 70.26831817626953\n",
      "Eval_MaxReturn : 514.7506103515625\n",
      "Eval_MinReturn : 299.56158447265625\n",
      "Eval_AverageEpLen : 185.83333333333334\n",
      "Train_AverageReturn : 395.8273010253906\n",
      "Train_StdReturn : 90.94146728515625\n",
      "Train_MaxReturn : 567.9685668945312\n",
      "Train_MinReturn : 229.98724365234375\n",
      "Train_AverageEpLen : 176.82456140350877\n",
      "Train_EnvstepsSoFar : 553325\n",
      "TimeSinceStart : 300.59642601013184\n",
      "Training Loss : -3.281925916671753\n",
      "Baseline Loss : 0.74002605676651\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10048 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 381.55224609375\n",
      "Eval_StdReturn : 69.46568298339844\n",
      "Eval_MaxReturn : 519.4625854492188\n",
      "Eval_MinReturn : 300.3243408203125\n",
      "Eval_AverageEpLen : 154.28571428571428\n",
      "Train_AverageReturn : 365.6250305175781\n",
      "Train_StdReturn : 76.74067687988281\n",
      "Train_MaxReturn : 527.9339599609375\n",
      "Train_MinReturn : 247.0875244140625\n",
      "Train_AverageEpLen : 162.06451612903226\n",
      "Train_EnvstepsSoFar : 563373\n",
      "TimeSinceStart : 305.96489334106445\n",
      "Training Loss : 1.6496144533157349\n",
      "Baseline Loss : 0.6790104508399963\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 332.53570556640625\n",
      "Eval_StdReturn : 30.449975967407227\n",
      "Eval_MaxReturn : 368.28839111328125\n",
      "Eval_MinReturn : 274.1962890625\n",
      "Eval_AverageEpLen : 147.14285714285714\n",
      "Train_AverageReturn : 377.64251708984375\n",
      "Train_StdReturn : 66.4759750366211\n",
      "Train_MaxReturn : 543.7003784179688\n",
      "Train_MinReturn : 272.2182312011719\n",
      "Train_AverageEpLen : 161.88709677419354\n",
      "Train_EnvstepsSoFar : 573410\n",
      "TimeSinceStart : 311.3138029575348\n",
      "Training Loss : 2.1787893772125244\n",
      "Baseline Loss : 0.7251917123794556\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10040 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 332.3528747558594\n",
      "Eval_StdReturn : 28.60881996154785\n",
      "Eval_MaxReturn : 374.0726318359375\n",
      "Eval_MinReturn : 285.2279052734375\n",
      "Eval_AverageEpLen : 145.28571428571428\n",
      "Train_AverageReturn : 344.0565185546875\n",
      "Train_StdReturn : 65.8134765625\n",
      "Train_MaxReturn : 542.6966552734375\n",
      "Train_MinReturn : 189.13084411621094\n",
      "Train_AverageEpLen : 147.64705882352942\n",
      "Train_EnvstepsSoFar : 583450\n",
      "TimeSinceStart : 316.6693286895752\n",
      "Training Loss : 3.4624178409576416\n",
      "Baseline Loss : 0.6775099039077759\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10132 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 344.21588134765625\n",
      "Eval_StdReturn : 44.323097229003906\n",
      "Eval_MaxReturn : 422.1393127441406\n",
      "Eval_MinReturn : 264.7343444824219\n",
      "Eval_AverageEpLen : 138.625\n",
      "Train_AverageReturn : 336.2435607910156\n",
      "Train_StdReturn : 57.30326461791992\n",
      "Train_MaxReturn : 565.335693359375\n",
      "Train_MinReturn : 194.4734649658203\n",
      "Train_AverageEpLen : 146.84057971014494\n",
      "Train_EnvstepsSoFar : 593582\n",
      "TimeSinceStart : 322.17008924484253\n",
      "Training Loss : 3.8438961505889893\n",
      "Baseline Loss : 0.5815092921257019\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10057 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 377.05999755859375\n",
      "Eval_StdReturn : 80.22991943359375\n",
      "Eval_MaxReturn : 561.4707641601562\n",
      "Eval_MinReturn : 315.8680114746094\n",
      "Eval_AverageEpLen : 155.71428571428572\n",
      "Train_AverageReturn : 339.25701904296875\n",
      "Train_StdReturn : 63.7015266418457\n",
      "Train_MaxReturn : 494.86285400390625\n",
      "Train_MinReturn : 169.04620361328125\n",
      "Train_AverageEpLen : 143.67142857142858\n",
      "Train_EnvstepsSoFar : 603639\n",
      "TimeSinceStart : 327.653178691864\n",
      "Training Loss : -0.028849121183156967\n",
      "Baseline Loss : 0.5722084641456604\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 432.1499938964844\n",
      "Eval_StdReturn : 56.474891662597656\n",
      "Eval_MaxReturn : 492.456787109375\n",
      "Eval_MinReturn : 336.49346923828125\n",
      "Eval_AverageEpLen : 159.71428571428572\n",
      "Train_AverageReturn : 376.7647705078125\n",
      "Train_StdReturn : 72.6322021484375\n",
      "Train_MaxReturn : 577.5540771484375\n",
      "Train_MinReturn : 206.88973999023438\n",
      "Train_AverageEpLen : 152.54545454545453\n",
      "Train_EnvstepsSoFar : 613707\n",
      "TimeSinceStart : 333.2087380886078\n",
      "Training Loss : -0.2517223656177521\n",
      "Baseline Loss : 0.4777480363845825\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10163 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 412.73974609375\n",
      "Eval_StdReturn : 81.12525939941406\n",
      "Eval_MaxReturn : 498.9952697753906\n",
      "Eval_MinReturn : 263.53631591796875\n",
      "Eval_AverageEpLen : 153.0\n",
      "Train_AverageReturn : 426.4024963378906\n",
      "Train_StdReturn : 82.86808013916016\n",
      "Train_MaxReturn : 567.20166015625\n",
      "Train_MinReturn : 133.26797485351562\n",
      "Train_AverageEpLen : 161.31746031746033\n",
      "Train_EnvstepsSoFar : 623870\n",
      "TimeSinceStart : 338.70008754730225\n",
      "Training Loss : -3.0019278526306152\n",
      "Baseline Loss : 0.3996836543083191\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10150 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 485.5712890625\n",
      "Eval_StdReturn : 57.827308654785156\n",
      "Eval_MaxReturn : 573.6256103515625\n",
      "Eval_MinReturn : 403.2515869140625\n",
      "Eval_AverageEpLen : 186.0\n",
      "Train_AverageReturn : 426.32354736328125\n",
      "Train_StdReturn : 74.8071060180664\n",
      "Train_MaxReturn : 588.9711303710938\n",
      "Train_MinReturn : 251.42556762695312\n",
      "Train_AverageEpLen : 161.11111111111111\n",
      "Train_EnvstepsSoFar : 634020\n",
      "TimeSinceStart : 344.2556526660919\n",
      "Training Loss : -2.276691198348999\n",
      "Baseline Loss : 0.4551333487033844\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10100 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 453.4224548339844\n",
      "Eval_StdReturn : 59.18889236450195\n",
      "Eval_MaxReturn : 555.380615234375\n",
      "Eval_MinReturn : 382.194580078125\n",
      "Eval_AverageEpLen : 169.33333333333334\n",
      "Train_AverageReturn : 441.49420166015625\n",
      "Train_StdReturn : 81.98179626464844\n",
      "Train_MaxReturn : 575.4996337890625\n",
      "Train_MinReturn : 155.89988708496094\n",
      "Train_AverageEpLen : 168.33333333333334\n",
      "Train_EnvstepsSoFar : 644120\n",
      "TimeSinceStart : 349.6765224933624\n",
      "Training Loss : -3.6533188819885254\n",
      "Baseline Loss : 0.46691885590553284\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10017 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 501.8897705078125\n",
      "Eval_StdReturn : 65.21061706542969\n",
      "Eval_MaxReturn : 594.6767578125\n",
      "Eval_MinReturn : 399.93768310546875\n",
      "Eval_AverageEpLen : 178.83333333333334\n",
      "Train_AverageReturn : 453.4908752441406\n",
      "Train_StdReturn : 72.01388549804688\n",
      "Train_MaxReturn : 581.0308837890625\n",
      "Train_MinReturn : 301.45355224609375\n",
      "Train_AverageEpLen : 166.95\n",
      "Train_EnvstepsSoFar : 654137\n",
      "TimeSinceStart : 355.10032391548157\n",
      "Training Loss : -8.996776580810547\n",
      "Baseline Loss : 0.4247432053089142\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10038 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 513.6318969726562\n",
      "Eval_StdReturn : 46.1643180847168\n",
      "Eval_MaxReturn : 588.0223388671875\n",
      "Eval_MinReturn : 437.82611083984375\n",
      "Eval_AverageEpLen : 180.83333333333334\n",
      "Train_AverageReturn : 441.92169189453125\n",
      "Train_StdReturn : 77.8536148071289\n",
      "Train_MaxReturn : 566.2996826171875\n",
      "Train_MinReturn : 152.8513641357422\n",
      "Train_AverageEpLen : 167.3\n",
      "Train_EnvstepsSoFar : 664175\n",
      "TimeSinceStart : 360.51840138435364\n",
      "Training Loss : -7.739566802978516\n",
      "Baseline Loss : 0.44242560863494873\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10059 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 418.38330078125\n",
      "Eval_StdReturn : 65.10516357421875\n",
      "Eval_MaxReturn : 547.6837158203125\n",
      "Eval_MinReturn : 336.56658935546875\n",
      "Eval_AverageEpLen : 164.85714285714286\n",
      "Train_AverageReturn : 429.39715576171875\n",
      "Train_StdReturn : 69.82141876220703\n",
      "Train_MaxReturn : 622.9873046875\n",
      "Train_MinReturn : 281.8951416015625\n",
      "Train_AverageEpLen : 164.9016393442623\n",
      "Train_EnvstepsSoFar : 674234\n",
      "TimeSinceStart : 366.0007998943329\n",
      "Training Loss : -5.219786643981934\n",
      "Baseline Loss : 0.4043172299861908\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10050 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 418.06268310546875\n",
      "Eval_StdReturn : 31.879331588745117\n",
      "Eval_MaxReturn : 460.82525634765625\n",
      "Eval_MinReturn : 373.08392333984375\n",
      "Eval_AverageEpLen : 159.57142857142858\n",
      "Train_AverageReturn : 425.9093322753906\n",
      "Train_StdReturn : 67.37601470947266\n",
      "Train_MaxReturn : 602.621337890625\n",
      "Train_MinReturn : 251.17388916015625\n",
      "Train_AverageEpLen : 164.75409836065575\n",
      "Train_EnvstepsSoFar : 684284\n",
      "TimeSinceStart : 371.44674706459045\n",
      "Training Loss : -4.888843059539795\n",
      "Baseline Loss : 0.42067694664001465\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 426.66961669921875\n",
      "Eval_StdReturn : 44.372867584228516\n",
      "Eval_MaxReturn : 512.5795288085938\n",
      "Eval_MinReturn : 353.35443115234375\n",
      "Eval_AverageEpLen : 167.28571428571428\n",
      "Train_AverageReturn : 421.0685729980469\n",
      "Train_StdReturn : 72.54097747802734\n",
      "Train_MaxReturn : 579.8021240234375\n",
      "Train_MinReturn : 254.42608642578125\n",
      "Train_AverageEpLen : 167.91666666666666\n",
      "Train_EnvstepsSoFar : 694359\n",
      "TimeSinceStart : 376.8810935020447\n",
      "Training Loss : -0.1288636475801468\n",
      "Baseline Loss : 0.4961909353733063\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10185 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 482.6861877441406\n",
      "Eval_StdReturn : 100.67215728759766\n",
      "Eval_MaxReturn : 577.7250366210938\n",
      "Eval_MinReturn : 291.1157531738281\n",
      "Eval_AverageEpLen : 178.66666666666666\n",
      "Train_AverageReturn : 424.0852355957031\n",
      "Train_StdReturn : 66.93497467041016\n",
      "Train_MaxReturn : 582.2958984375\n",
      "Train_MinReturn : 270.8839416503906\n",
      "Train_AverageEpLen : 166.9672131147541\n",
      "Train_EnvstepsSoFar : 704544\n",
      "TimeSinceStart : 382.3952167034149\n",
      "Training Loss : 0.3468303680419922\n",
      "Baseline Loss : 0.5141652226448059\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10097 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 463.2290344238281\n",
      "Eval_StdReturn : 69.22561645507812\n",
      "Eval_MaxReturn : 541.494384765625\n",
      "Eval_MinReturn : 317.16485595703125\n",
      "Eval_AverageEpLen : 170.66666666666666\n",
      "Train_AverageReturn : 428.63385009765625\n",
      "Train_StdReturn : 81.55036926269531\n",
      "Train_MaxReturn : 573.437744140625\n",
      "Train_MinReturn : 229.91665649414062\n",
      "Train_AverageEpLen : 165.52459016393442\n",
      "Train_EnvstepsSoFar : 714641\n",
      "TimeSinceStart : 387.84758377075195\n",
      "Training Loss : 1.6333378553390503\n",
      "Baseline Loss : 0.5109933018684387\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10134 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 433.49847412109375\n",
      "Eval_StdReturn : 85.69834899902344\n",
      "Eval_MaxReturn : 567.4090576171875\n",
      "Eval_MinReturn : 266.5991516113281\n",
      "Eval_AverageEpLen : 153.57142857142858\n",
      "Train_AverageReturn : 432.39874267578125\n",
      "Train_StdReturn : 62.49853515625\n",
      "Train_MaxReturn : 581.509033203125\n",
      "Train_MinReturn : 290.20184326171875\n",
      "Train_AverageEpLen : 163.4516129032258\n",
      "Train_EnvstepsSoFar : 724775\n",
      "TimeSinceStart : 393.28818011283875\n",
      "Training Loss : 3.2100257873535156\n",
      "Baseline Loss : 0.5066266655921936\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10079 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 436.4871520996094\n",
      "Eval_StdReturn : 39.666343688964844\n",
      "Eval_MaxReturn : 495.26287841796875\n",
      "Eval_MinReturn : 372.0135803222656\n",
      "Eval_AverageEpLen : 154.71428571428572\n",
      "Train_AverageReturn : 405.06427001953125\n",
      "Train_StdReturn : 83.91708374023438\n",
      "Train_MaxReturn : 571.1136474609375\n",
      "Train_MinReturn : 100.84535217285156\n",
      "Train_AverageEpLen : 152.71212121212122\n",
      "Train_EnvstepsSoFar : 734854\n",
      "TimeSinceStart : 398.703485250473\n",
      "Training Loss : 7.643951892852783\n",
      "Baseline Loss : 0.37220898270606995\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10082 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 405.2350158691406\n",
      "Eval_StdReturn : 127.18896484375\n",
      "Eval_MaxReturn : 523.6884765625\n",
      "Eval_MinReturn : 102.26571655273438\n",
      "Eval_AverageEpLen : 147.28571428571428\n",
      "Train_AverageReturn : 422.3545227050781\n",
      "Train_StdReturn : 95.90847778320312\n",
      "Train_MaxReturn : 559.3155517578125\n",
      "Train_MinReturn : 97.12299346923828\n",
      "Train_AverageEpLen : 155.1076923076923\n",
      "Train_EnvstepsSoFar : 744936\n",
      "TimeSinceStart : 404.19125413894653\n",
      "Training Loss : 4.006438255310059\n",
      "Baseline Loss : 0.30706048011779785\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 326.5373840332031\n",
      "Eval_StdReturn : 159.5492401123047\n",
      "Eval_MaxReturn : 476.9878845214844\n",
      "Eval_MinReturn : 100.58773803710938\n",
      "Eval_AverageEpLen : 122.88888888888889\n",
      "Train_AverageReturn : 380.631591796875\n",
      "Train_StdReturn : 133.92481994628906\n",
      "Train_MaxReturn : 551.270263671875\n",
      "Train_MinReturn : 98.94611358642578\n",
      "Train_AverageEpLen : 137.4931506849315\n",
      "Train_EnvstepsSoFar : 754973\n",
      "TimeSinceStart : 409.671005487442\n",
      "Training Loss : 4.740986347198486\n",
      "Baseline Loss : 0.2649994194507599\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10097 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 276.8647155761719\n",
      "Eval_StdReturn : 176.41683959960938\n",
      "Eval_MaxReturn : 494.473876953125\n",
      "Eval_MinReturn : 95.51727294921875\n",
      "Eval_AverageEpLen : 106.0\n",
      "Train_AverageReturn : 377.0267028808594\n",
      "Train_StdReturn : 130.17376708984375\n",
      "Train_MaxReturn : 597.06982421875\n",
      "Train_MinReturn : 96.3822250366211\n",
      "Train_AverageEpLen : 136.44594594594594\n",
      "Train_EnvstepsSoFar : 765070\n",
      "TimeSinceStart : 415.1607005596161\n",
      "Training Loss : 1.514402985572815\n",
      "Baseline Loss : 0.29869362711906433\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10091 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 327.0953674316406\n",
      "Eval_StdReturn : 160.4622039794922\n",
      "Eval_MaxReturn : 466.63336181640625\n",
      "Eval_MinReturn : 96.41799926757812\n",
      "Eval_AverageEpLen : 120.77777777777777\n",
      "Train_AverageReturn : 328.20660400390625\n",
      "Train_StdReturn : 159.80136108398438\n",
      "Train_MaxReturn : 503.23828125\n",
      "Train_MinReturn : 94.04459381103516\n",
      "Train_AverageEpLen : 121.57831325301204\n",
      "Train_EnvstepsSoFar : 775161\n",
      "TimeSinceStart : 420.63246417045593\n",
      "Training Loss : 3.125375747680664\n",
      "Baseline Loss : 0.34480974078178406\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 372.598388671875\n",
      "Eval_StdReturn : 160.4640350341797\n",
      "Eval_MaxReturn : 546.1839599609375\n",
      "Eval_MinReturn : 99.80513763427734\n",
      "Eval_AverageEpLen : 135.0\n",
      "Train_AverageReturn : 337.35223388671875\n",
      "Train_StdReturn : 153.08642578125\n",
      "Train_MaxReturn : 525.6690063476562\n",
      "Train_MinReturn : 90.9645767211914\n",
      "Train_AverageEpLen : 123.65432098765432\n",
      "Train_EnvstepsSoFar : 785177\n",
      "TimeSinceStart : 426.13265681266785\n",
      "Training Loss : 0.5072922110557556\n",
      "Baseline Loss : 0.28049570322036743\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 378.3668212890625\n",
      "Eval_StdReturn : 163.5054473876953\n",
      "Eval_MaxReturn : 497.27056884765625\n",
      "Eval_MinReturn : 97.33554077148438\n",
      "Eval_AverageEpLen : 131.0\n",
      "Train_AverageReturn : 325.3128662109375\n",
      "Train_StdReturn : 165.91123962402344\n",
      "Train_MaxReturn : 581.08837890625\n",
      "Train_MinReturn : 96.35401153564453\n",
      "Train_AverageEpLen : 119.48809523809524\n",
      "Train_EnvstepsSoFar : 795214\n",
      "TimeSinceStart : 431.58878779411316\n",
      "Training Loss : -3.0002429485321045\n",
      "Baseline Loss : 0.30992645025253296\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10048 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 392.90576171875\n",
      "Eval_StdReturn : 128.7635498046875\n",
      "Eval_MaxReturn : 503.61041259765625\n",
      "Eval_MinReturn : 105.99256896972656\n",
      "Eval_AverageEpLen : 141.375\n",
      "Train_AverageReturn : 327.101806640625\n",
      "Train_StdReturn : 167.50697326660156\n",
      "Train_MaxReturn : 594.22119140625\n",
      "Train_MinReturn : 91.85232543945312\n",
      "Train_AverageEpLen : 119.61904761904762\n",
      "Train_EnvstepsSoFar : 805262\n",
      "TimeSinceStart : 437.0929775238037\n",
      "Training Loss : -6.17432975769043\n",
      "Baseline Loss : 0.3227190673351288\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 410.3811950683594\n",
      "Eval_StdReturn : 106.67556762695312\n",
      "Eval_MaxReturn : 527.6681518554688\n",
      "Eval_MinReturn : 208.168701171875\n",
      "Eval_AverageEpLen : 143.14285714285714\n",
      "Train_AverageReturn : 335.47674560546875\n",
      "Train_StdReturn : 154.79592895507812\n",
      "Train_MaxReturn : 537.9783325195312\n",
      "Train_MinReturn : 89.1534194946289\n",
      "Train_AverageEpLen : 122.26829268292683\n",
      "Train_EnvstepsSoFar : 815288\n",
      "TimeSinceStart : 442.4979329109192\n",
      "Training Loss : -4.074931621551514\n",
      "Baseline Loss : 0.2820477783679962\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10012 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 423.1055603027344\n",
      "Eval_StdReturn : 67.76946258544922\n",
      "Eval_MaxReturn : 495.40057373046875\n",
      "Eval_MinReturn : 282.02032470703125\n",
      "Eval_AverageEpLen : 148.42857142857142\n",
      "Train_AverageReturn : 401.2460021972656\n",
      "Train_StdReturn : 115.47063446044922\n",
      "Train_MaxReturn : 575.1475830078125\n",
      "Train_MinReturn : 96.15403747558594\n",
      "Train_AverageEpLen : 141.01408450704224\n",
      "Train_EnvstepsSoFar : 825300\n",
      "TimeSinceStart : 447.94098138809204\n",
      "Training Loss : -6.259028434753418\n",
      "Baseline Loss : 0.2291693389415741\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10069 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 382.6391906738281\n",
      "Eval_StdReturn : 147.27284240722656\n",
      "Eval_MaxReturn : 537.0015869140625\n",
      "Eval_MinReturn : 122.67191314697266\n",
      "Eval_AverageEpLen : 134.25\n",
      "Train_AverageReturn : 392.58392333984375\n",
      "Train_StdReturn : 117.06480407714844\n",
      "Train_MaxReturn : 536.2347412109375\n",
      "Train_MinReturn : 100.6112289428711\n",
      "Train_AverageEpLen : 139.84722222222223\n",
      "Train_EnvstepsSoFar : 835369\n",
      "TimeSinceStart : 453.4456992149353\n",
      "Training Loss : -0.09518613666296005\n",
      "Baseline Loss : 0.24329431354999542\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 402.5101318359375\n",
      "Eval_StdReturn : 81.80939483642578\n",
      "Eval_MaxReturn : 522.367431640625\n",
      "Eval_MinReturn : 259.1295166015625\n",
      "Eval_AverageEpLen : 142.875\n",
      "Train_AverageReturn : 411.9519958496094\n",
      "Train_StdReturn : 81.4386978149414\n",
      "Train_MaxReturn : 552.849365234375\n",
      "Train_MinReturn : 106.42867279052734\n",
      "Train_AverageEpLen : 145.20289855072463\n",
      "Train_EnvstepsSoFar : 845388\n",
      "TimeSinceStart : 458.90580701828003\n",
      "Training Loss : 1.0990347862243652\n",
      "Baseline Loss : 0.25312379002571106\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10138 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 459.5191345214844\n",
      "Eval_StdReturn : 50.23356246948242\n",
      "Eval_MaxReturn : 557.5140991210938\n",
      "Eval_MinReturn : 375.3458251953125\n",
      "Eval_AverageEpLen : 158.71428571428572\n",
      "Train_AverageReturn : 407.95166015625\n",
      "Train_StdReturn : 81.12433624267578\n",
      "Train_MaxReturn : 513.3615112304688\n",
      "Train_MinReturn : 142.60430908203125\n",
      "Train_AverageEpLen : 144.82857142857142\n",
      "Train_EnvstepsSoFar : 855526\n",
      "TimeSinceStart : 464.4110186100006\n",
      "Training Loss : 2.8045976161956787\n",
      "Baseline Loss : 0.27304625511169434\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10122 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 406.4616394042969\n",
      "Eval_StdReturn : 92.16349029541016\n",
      "Eval_MaxReturn : 516.314453125\n",
      "Eval_MinReturn : 247.14801025390625\n",
      "Eval_AverageEpLen : 146.28571428571428\n",
      "Train_AverageReturn : 410.754638671875\n",
      "Train_StdReturn : 83.16914367675781\n",
      "Train_MaxReturn : 532.429931640625\n",
      "Train_MinReturn : 145.47708129882812\n",
      "Train_AverageEpLen : 144.6\n",
      "Train_EnvstepsSoFar : 865648\n",
      "TimeSinceStart : 469.87383341789246\n",
      "Training Loss : 2.3460471630096436\n",
      "Baseline Loss : 0.25996798276901245\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10145 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 429.6763000488281\n",
      "Eval_StdReturn : 19.45025062561035\n",
      "Eval_MaxReturn : 452.6767272949219\n",
      "Eval_MinReturn : 389.07989501953125\n",
      "Eval_AverageEpLen : 151.28571428571428\n",
      "Train_AverageReturn : 417.9622497558594\n",
      "Train_StdReturn : 63.684967041015625\n",
      "Train_MaxReturn : 605.5519409179688\n",
      "Train_MinReturn : 197.69798278808594\n",
      "Train_AverageEpLen : 149.19117647058823\n",
      "Train_EnvstepsSoFar : 875793\n",
      "TimeSinceStart : 475.4615616798401\n",
      "Training Loss : 2.1837728023529053\n",
      "Baseline Loss : 0.2343028038740158\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10096 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 401.0125732421875\n",
      "Eval_StdReturn : 52.26605224609375\n",
      "Eval_MaxReturn : 473.1946105957031\n",
      "Eval_MinReturn : 321.5288391113281\n",
      "Eval_AverageEpLen : 142.375\n",
      "Train_AverageReturn : 412.4920349121094\n",
      "Train_StdReturn : 73.2517318725586\n",
      "Train_MaxReturn : 554.7151489257812\n",
      "Train_MinReturn : 161.2389373779297\n",
      "Train_AverageEpLen : 148.47058823529412\n",
      "Train_EnvstepsSoFar : 885889\n",
      "TimeSinceStart : 481.016309261322\n",
      "Training Loss : 1.0337796211242676\n",
      "Baseline Loss : 0.22912263870239258\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 423.7413635253906\n",
      "Eval_StdReturn : 34.392059326171875\n",
      "Eval_MaxReturn : 481.644287109375\n",
      "Eval_MinReturn : 373.17877197265625\n",
      "Eval_AverageEpLen : 148.0\n",
      "Train_AverageReturn : 428.92083740234375\n",
      "Train_StdReturn : 42.5848503112793\n",
      "Train_MaxReturn : 594.9900512695312\n",
      "Train_MinReturn : 295.3941955566406\n",
      "Train_AverageEpLen : 150.37313432835822\n",
      "Train_EnvstepsSoFar : 895964\n",
      "TimeSinceStart : 486.4601831436157\n",
      "Training Loss : -5.122942924499512\n",
      "Baseline Loss : 0.21655665338039398\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10031 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 429.0924377441406\n",
      "Eval_StdReturn : 40.82440185546875\n",
      "Eval_MaxReturn : 525.2560424804688\n",
      "Eval_MinReturn : 393.2420654296875\n",
      "Eval_AverageEpLen : 149.85714285714286\n",
      "Train_AverageReturn : 418.084716796875\n",
      "Train_StdReturn : 41.22537612915039\n",
      "Train_MaxReturn : 528.11181640625\n",
      "Train_MinReturn : 292.3846435546875\n",
      "Train_AverageEpLen : 147.51470588235293\n",
      "Train_EnvstepsSoFar : 905995\n",
      "TimeSinceStart : 491.81174182891846\n",
      "Training Loss : -2.2123959064483643\n",
      "Baseline Loss : 0.19902867078781128\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10104 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 394.677490234375\n",
      "Eval_StdReturn : 46.2379264831543\n",
      "Eval_MaxReturn : 457.6450500488281\n",
      "Eval_MinReturn : 317.402099609375\n",
      "Eval_AverageEpLen : 140.75\n",
      "Train_AverageReturn : 417.81951904296875\n",
      "Train_StdReturn : 31.81878662109375\n",
      "Train_MaxReturn : 499.6576843261719\n",
      "Train_MinReturn : 319.2540588378906\n",
      "Train_AverageEpLen : 146.43478260869566\n",
      "Train_EnvstepsSoFar : 916099\n",
      "TimeSinceStart : 497.25617504119873\n",
      "Training Loss : -0.08157913386821747\n",
      "Baseline Loss : 0.17114368081092834\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10109 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 419.06060791015625\n",
      "Eval_StdReturn : 35.828758239746094\n",
      "Eval_MaxReturn : 476.09368896484375\n",
      "Eval_MinReturn : 363.20074462890625\n",
      "Eval_AverageEpLen : 149.57142857142858\n",
      "Train_AverageReturn : 407.0675048828125\n",
      "Train_StdReturn : 43.87040328979492\n",
      "Train_MaxReturn : 538.4317626953125\n",
      "Train_MinReturn : 214.48468017578125\n",
      "Train_AverageEpLen : 146.5072463768116\n",
      "Train_EnvstepsSoFar : 926208\n",
      "TimeSinceStart : 502.6274836063385\n",
      "Training Loss : 3.6834921836853027\n",
      "Baseline Loss : 0.22532260417938232\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10116 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 414.66619873046875\n",
      "Eval_StdReturn : 32.31087875366211\n",
      "Eval_MaxReturn : 481.01312255859375\n",
      "Eval_MinReturn : 378.1816711425781\n",
      "Eval_AverageEpLen : 146.28571428571428\n",
      "Train_AverageReturn : 406.229736328125\n",
      "Train_StdReturn : 36.761295318603516\n",
      "Train_MaxReturn : 481.846923828125\n",
      "Train_MinReturn : 285.8077392578125\n",
      "Train_AverageEpLen : 144.5142857142857\n",
      "Train_EnvstepsSoFar : 936324\n",
      "TimeSinceStart : 508.0417444705963\n",
      "Training Loss : 3.3853108882904053\n",
      "Baseline Loss : 0.1757899969816208\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10030 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 408.3581237792969\n",
      "Eval_StdReturn : 27.415416717529297\n",
      "Eval_MaxReturn : 466.69049072265625\n",
      "Eval_MinReturn : 382.1227722167969\n",
      "Eval_AverageEpLen : 145.71428571428572\n",
      "Train_AverageReturn : 401.7506103515625\n",
      "Train_StdReturn : 38.16592788696289\n",
      "Train_MaxReturn : 550.3622436523438\n",
      "Train_MinReturn : 335.0439453125\n",
      "Train_AverageEpLen : 145.36231884057972\n",
      "Train_EnvstepsSoFar : 946354\n",
      "TimeSinceStart : 513.4147758483887\n",
      "Training Loss : -0.06526562571525574\n",
      "Baseline Loss : 0.21067790687084198\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10129 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 400.51513671875\n",
      "Eval_StdReturn : 18.075464248657227\n",
      "Eval_MaxReturn : 436.54107666015625\n",
      "Eval_MinReturn : 383.7047119140625\n",
      "Eval_AverageEpLen : 145.28571428571428\n",
      "Train_AverageReturn : 403.5981750488281\n",
      "Train_StdReturn : 32.279659271240234\n",
      "Train_MaxReturn : 542.5208129882812\n",
      "Train_MinReturn : 337.14447021484375\n",
      "Train_AverageEpLen : 144.7\n",
      "Train_EnvstepsSoFar : 956483\n",
      "TimeSinceStart : 518.8724505901337\n",
      "Training Loss : -2.1586222648620605\n",
      "Baseline Loss : 0.19417020678520203\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10049 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 418.8146667480469\n",
      "Eval_StdReturn : 68.9194564819336\n",
      "Eval_MaxReturn : 575.3367919921875\n",
      "Eval_MinReturn : 351.5728759765625\n",
      "Eval_AverageEpLen : 152.42857142857142\n",
      "Train_AverageReturn : 399.7824401855469\n",
      "Train_StdReturn : 45.3454475402832\n",
      "Train_MaxReturn : 570.02099609375\n",
      "Train_MinReturn : 250.1335906982422\n",
      "Train_AverageEpLen : 143.55714285714285\n",
      "Train_EnvstepsSoFar : 966532\n",
      "TimeSinceStart : 524.333438873291\n",
      "Training Loss : -2.3875327110290527\n",
      "Baseline Loss : 0.21368078887462616\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 439.4666442871094\n",
      "Eval_StdReturn : 40.037757873535156\n",
      "Eval_MaxReturn : 525.3892822265625\n",
      "Eval_MinReturn : 407.20220947265625\n",
      "Eval_AverageEpLen : 151.0\n",
      "Train_AverageReturn : 415.89398193359375\n",
      "Train_StdReturn : 39.10551452636719\n",
      "Train_MaxReturn : 541.653564453125\n",
      "Train_MinReturn : 320.04071044921875\n",
      "Train_AverageEpLen : 146.94202898550725\n",
      "Train_EnvstepsSoFar : 976671\n",
      "TimeSinceStart : 529.8366115093231\n",
      "Training Loss : -1.4409276247024536\n",
      "Baseline Loss : 0.15802127122879028\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 421.47943115234375\n",
      "Eval_StdReturn : 29.115385055541992\n",
      "Eval_MaxReturn : 463.41015625\n",
      "Eval_MinReturn : 385.47369384765625\n",
      "Eval_AverageEpLen : 145.57142857142858\n",
      "Train_AverageReturn : 414.54351806640625\n",
      "Train_StdReturn : 32.911617279052734\n",
      "Train_MaxReturn : 568.1053466796875\n",
      "Train_MinReturn : 369.06640625\n",
      "Train_AverageEpLen : 147.44117647058823\n",
      "Train_EnvstepsSoFar : 986697\n",
      "TimeSinceStart : 535.3080163002014\n",
      "Training Loss : 0.572526216506958\n",
      "Baseline Loss : 0.1431586593389511\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10096 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 416.64471435546875\n",
      "Eval_StdReturn : 21.228363037109375\n",
      "Eval_MaxReturn : 449.7184143066406\n",
      "Eval_MinReturn : 381.5148010253906\n",
      "Eval_AverageEpLen : 145.85714285714286\n",
      "Train_AverageReturn : 409.2817687988281\n",
      "Train_StdReturn : 37.92887878417969\n",
      "Train_MaxReturn : 526.447998046875\n",
      "Train_MinReturn : 266.5679931640625\n",
      "Train_AverageEpLen : 144.22857142857143\n",
      "Train_EnvstepsSoFar : 996793\n",
      "TimeSinceStart : 540.7952857017517\n",
      "Training Loss : -0.11447108536958694\n",
      "Baseline Loss : 0.15506482124328613\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10118 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 420.21490478515625\n",
      "Eval_StdReturn : 19.813793182373047\n",
      "Eval_MaxReturn : 440.2170715332031\n",
      "Eval_MinReturn : 378.25091552734375\n",
      "Eval_AverageEpLen : 147.85714285714286\n",
      "Train_AverageReturn : 415.5230712890625\n",
      "Train_StdReturn : 32.30350875854492\n",
      "Train_MaxReturn : 568.0026245117188\n",
      "Train_MinReturn : 363.6942138671875\n",
      "Train_AverageEpLen : 146.63768115942028\n",
      "Train_EnvstepsSoFar : 1006911\n",
      "TimeSinceStart : 546.2269732952118\n",
      "Training Loss : -1.2718013525009155\n",
      "Baseline Loss : 0.1377125233411789\n",
      "Initial_DataCollection_AverageReturn : 12.80981159210205\n",
      "Done logging...\n",
      "\n",
      "\n",
      "Running policy gradient experiment with seed 2\n",
      "########################\n",
      "logging outputs to  logs/policy_gradient/Hopper/with_baseline/seed2\n",
      "########################\n",
      "Using CPU for this assignment. There may be some bugs with using GPU that cause test cases to not match. You can uncomment the code below if you want to try using it.\n",
      "Hopper-v2\n",
      "\n",
      "\n",
      "********** Iteration 0 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 82.18453216552734\n",
      "Eval_StdReturn : 15.293522834777832\n",
      "Eval_MaxReturn : 117.85490417480469\n",
      "Eval_MinReturn : 60.87228775024414\n",
      "Eval_AverageEpLen : 50.333333333333336\n",
      "Train_AverageReturn : 17.71956443786621\n",
      "Train_StdReturn : 17.00727653503418\n",
      "Train_MaxReturn : 149.52996826171875\n",
      "Train_MinReturn : 2.81905460357666\n",
      "Train_AverageEpLen : 21.008403361344538\n",
      "Train_EnvstepsSoFar : 10000\n",
      "TimeSinceStart : 5.939263343811035\n",
      "Training Loss : 1.5085480213165283\n",
      "Baseline Loss : 1.1008243560791016\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 1 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10044 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 74.14925384521484\n",
      "Eval_StdReturn : 20.936309814453125\n",
      "Eval_MaxReturn : 144.90196228027344\n",
      "Eval_MinReturn : 48.86653137207031\n",
      "Eval_AverageEpLen : 42.708333333333336\n",
      "Train_AverageReturn : 77.85270690917969\n",
      "Train_StdReturn : 20.610584259033203\n",
      "Train_MaxReturn : 167.17881774902344\n",
      "Train_MinReturn : 5.99744176864624\n",
      "Train_AverageEpLen : 48.28846153846154\n",
      "Train_EnvstepsSoFar : 20044\n",
      "TimeSinceStart : 11.71872854232788\n",
      "Training Loss : -16.15829086303711\n",
      "Baseline Loss : 1.62334406375885\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 2 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 152.78392028808594\n",
      "Eval_StdReturn : 37.5029411315918\n",
      "Eval_MaxReturn : 215.4149627685547\n",
      "Eval_MinReturn : 82.19617462158203\n",
      "Eval_AverageEpLen : 73.64285714285714\n",
      "Train_AverageReturn : 75.56706237792969\n",
      "Train_StdReturn : 19.913536071777344\n",
      "Train_MaxReturn : 153.60121154785156\n",
      "Train_MinReturn : 9.500860214233398\n",
      "Train_AverageEpLen : 43.68995633187773\n",
      "Train_EnvstepsSoFar : 30049\n",
      "TimeSinceStart : 17.413726806640625\n",
      "Training Loss : -9.303325653076172\n",
      "Baseline Loss : 1.1618715524673462\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 3 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10053 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 153.62562561035156\n",
      "Eval_StdReturn : 49.97636032104492\n",
      "Eval_MaxReturn : 217.02499389648438\n",
      "Eval_MinReturn : 73.14693450927734\n",
      "Eval_AverageEpLen : 75.42857142857143\n",
      "Train_AverageReturn : 164.42041015625\n",
      "Train_StdReturn : 52.473628997802734\n",
      "Train_MaxReturn : 238.39341735839844\n",
      "Train_MinReturn : 21.17938995361328\n",
      "Train_AverageEpLen : 76.74045801526718\n",
      "Train_EnvstepsSoFar : 40102\n",
      "TimeSinceStart : 23.123185873031616\n",
      "Training Loss : 8.739670753479004\n",
      "Baseline Loss : 1.0732942819595337\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 4 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10026 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 210.85169982910156\n",
      "Eval_StdReturn : 7.64113187789917\n",
      "Eval_MaxReturn : 222.6871337890625\n",
      "Eval_MinReturn : 199.4065704345703\n",
      "Eval_AverageEpLen : 93.72727272727273\n",
      "Train_AverageReturn : 131.3839111328125\n",
      "Train_StdReturn : 57.22811508178711\n",
      "Train_MaxReturn : 221.66343688964844\n",
      "Train_MinReturn : 23.743770599365234\n",
      "Train_AverageEpLen : 66.84\n",
      "Train_EnvstepsSoFar : 50128\n",
      "TimeSinceStart : 28.808584213256836\n",
      "Training Loss : 9.859657287597656\n",
      "Baseline Loss : 1.0769312381744385\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 5 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10062 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 204.42547607421875\n",
      "Eval_StdReturn : 8.424152374267578\n",
      "Eval_MaxReturn : 214.82614135742188\n",
      "Eval_MinReturn : 190.5640411376953\n",
      "Eval_AverageEpLen : 90.25\n",
      "Train_AverageReturn : 204.90802001953125\n",
      "Train_StdReturn : 19.4199275970459\n",
      "Train_MaxReturn : 226.97019958496094\n",
      "Train_MinReturn : 83.2197494506836\n",
      "Train_AverageEpLen : 91.47272727272727\n",
      "Train_EnvstepsSoFar : 60190\n",
      "TimeSinceStart : 34.42489004135132\n",
      "Training Loss : 7.188703536987305\n",
      "Baseline Loss : 1.0648378133773804\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 6 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 157.2400665283203\n",
      "Eval_StdReturn : 37.13597106933594\n",
      "Eval_MaxReturn : 198.30880737304688\n",
      "Eval_MinReturn : 83.26747131347656\n",
      "Eval_AverageEpLen : 74.35714285714286\n",
      "Train_AverageReturn : 197.34962463378906\n",
      "Train_StdReturn : 20.80284309387207\n",
      "Train_MaxReturn : 226.03179931640625\n",
      "Train_MinReturn : 102.29148864746094\n",
      "Train_AverageEpLen : 87.87719298245614\n",
      "Train_EnvstepsSoFar : 70208\n",
      "TimeSinceStart : 40.118043422698975\n",
      "Training Loss : 3.395707368850708\n",
      "Baseline Loss : 1.0104413032531738\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 7 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10054 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 195.00965881347656\n",
      "Eval_StdReturn : 17.604263305664062\n",
      "Eval_MaxReturn : 213.72254943847656\n",
      "Eval_MinReturn : 155.38343811035156\n",
      "Eval_AverageEpLen : 86.91666666666667\n",
      "Train_AverageReturn : 180.9711456298828\n",
      "Train_StdReturn : 27.188854217529297\n",
      "Train_MaxReturn : 221.7678985595703\n",
      "Train_MinReturn : 99.40617370605469\n",
      "Train_AverageEpLen : 82.40983606557377\n",
      "Train_EnvstepsSoFar : 80262\n",
      "TimeSinceStart : 45.813573598861694\n",
      "Training Loss : 0.21022263169288635\n",
      "Baseline Loss : 0.9668150544166565\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 8 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10079 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 208.70851135253906\n",
      "Eval_StdReturn : 3.287620782852173\n",
      "Eval_MaxReturn : 212.53253173828125\n",
      "Eval_MinReturn : 203.3687286376953\n",
      "Eval_AverageEpLen : 91.63636363636364\n",
      "Train_AverageReturn : 186.04095458984375\n",
      "Train_StdReturn : 24.494277954101562\n",
      "Train_MaxReturn : 217.96131896972656\n",
      "Train_MinReturn : 88.15354919433594\n",
      "Train_AverageEpLen : 83.99166666666666\n",
      "Train_EnvstepsSoFar : 90341\n",
      "TimeSinceStart : 51.514222621917725\n",
      "Training Loss : -1.9618302583694458\n",
      "Baseline Loss : 0.9230360388755798\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 9 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10086 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 201.21258544921875\n",
      "Eval_StdReturn : 8.056194305419922\n",
      "Eval_MaxReturn : 215.2049560546875\n",
      "Eval_MinReturn : 187.1772918701172\n",
      "Eval_AverageEpLen : 89.58333333333333\n",
      "Train_AverageReturn : 203.94644165039062\n",
      "Train_StdReturn : 10.05982780456543\n",
      "Train_MaxReturn : 217.72018432617188\n",
      "Train_MinReturn : 135.16322326660156\n",
      "Train_AverageEpLen : 90.05357142857143\n",
      "Train_EnvstepsSoFar : 100427\n",
      "TimeSinceStart : 57.24236345291138\n",
      "Training Loss : -1.7843642234802246\n",
      "Baseline Loss : 0.8642532825469971\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 10 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10057 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 197.24542236328125\n",
      "Eval_StdReturn : 9.353747367858887\n",
      "Eval_MaxReturn : 209.93128967285156\n",
      "Eval_MinReturn : 175.5609893798828\n",
      "Eval_AverageEpLen : 88.83333333333333\n",
      "Train_AverageReturn : 201.91563415527344\n",
      "Train_StdReturn : 6.409848213195801\n",
      "Train_MaxReturn : 215.81985473632812\n",
      "Train_MinReturn : 185.01510620117188\n",
      "Train_AverageEpLen : 89.79464285714286\n",
      "Train_EnvstepsSoFar : 110484\n",
      "TimeSinceStart : 62.97347831726074\n",
      "Training Loss : 0.1989268660545349\n",
      "Baseline Loss : 0.7972790598869324\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 11 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 192.17860412597656\n",
      "Eval_StdReturn : 8.706751823425293\n",
      "Eval_MaxReturn : 205.69566345214844\n",
      "Eval_MinReturn : 177.34349060058594\n",
      "Eval_AverageEpLen : 87.33333333333333\n",
      "Train_AverageReturn : 199.08033752441406\n",
      "Train_StdReturn : 6.375103950500488\n",
      "Train_MaxReturn : 211.42567443847656\n",
      "Train_MinReturn : 179.40939331054688\n",
      "Train_AverageEpLen : 89.23893805309734\n",
      "Train_EnvstepsSoFar : 120568\n",
      "TimeSinceStart : 68.70998215675354\n",
      "Training Loss : 2.968395471572876\n",
      "Baseline Loss : 0.751265823841095\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 12 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10011 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 188.9606170654297\n",
      "Eval_StdReturn : 7.8326520919799805\n",
      "Eval_MaxReturn : 202.72633361816406\n",
      "Eval_MinReturn : 173.90280151367188\n",
      "Eval_AverageEpLen : 86.5\n",
      "Train_AverageReturn : 193.6114959716797\n",
      "Train_StdReturn : 7.099632263183594\n",
      "Train_MaxReturn : 210.66989135742188\n",
      "Train_MinReturn : 175.4055938720703\n",
      "Train_AverageEpLen : 87.8157894736842\n",
      "Train_EnvstepsSoFar : 130579\n",
      "TimeSinceStart : 74.24328279495239\n",
      "Training Loss : 4.26488733291626\n",
      "Baseline Loss : 0.7099953889846802\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 13 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10015 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 185.7464141845703\n",
      "Eval_StdReturn : 8.374872207641602\n",
      "Eval_MaxReturn : 198.49923706054688\n",
      "Eval_MinReturn : 172.10679626464844\n",
      "Eval_AverageEpLen : 85.91666666666667\n",
      "Train_AverageReturn : 188.45115661621094\n",
      "Train_StdReturn : 8.568253517150879\n",
      "Train_MaxReturn : 207.24607849121094\n",
      "Train_MinReturn : 167.8678436279297\n",
      "Train_AverageEpLen : 86.33620689655173\n",
      "Train_EnvstepsSoFar : 140594\n",
      "TimeSinceStart : 79.78231167793274\n",
      "Training Loss : 2.8161206245422363\n",
      "Baseline Loss : 0.6615880727767944\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 14 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10077 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 172.14390563964844\n",
      "Eval_StdReturn : 4.162222862243652\n",
      "Eval_MaxReturn : 181.25047302246094\n",
      "Eval_MinReturn : 165.53619384765625\n",
      "Eval_AverageEpLen : 82.76923076923077\n",
      "Train_AverageReturn : 182.3431854248047\n",
      "Train_StdReturn : 7.716549873352051\n",
      "Train_MaxReturn : 202.91111755371094\n",
      "Train_MinReturn : 166.95143127441406\n",
      "Train_AverageEpLen : 84.68067226890756\n",
      "Train_EnvstepsSoFar : 150671\n",
      "TimeSinceStart : 85.4808337688446\n",
      "Training Loss : -1.566908597946167\n",
      "Baseline Loss : 0.6265731453895569\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 15 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10018 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.76698303222656\n",
      "Eval_StdReturn : 6.341175079345703\n",
      "Eval_MaxReturn : 186.6175994873047\n",
      "Eval_MinReturn : 167.18035888671875\n",
      "Eval_AverageEpLen : 84.25\n",
      "Train_AverageReturn : 176.45652770996094\n",
      "Train_StdReturn : 7.866489887237549\n",
      "Train_MaxReturn : 196.38619995117188\n",
      "Train_MinReturn : 131.83737182617188\n",
      "Train_AverageEpLen : 83.48333333333333\n",
      "Train_EnvstepsSoFar : 160689\n",
      "TimeSinceStart : 91.06864356994629\n",
      "Training Loss : -5.976497173309326\n",
      "Baseline Loss : 0.6303483843803406\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 16 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 171.9798126220703\n",
      "Eval_StdReturn : 4.087954044342041\n",
      "Eval_MaxReturn : 178.6812286376953\n",
      "Eval_MinReturn : 165.95797729492188\n",
      "Eval_AverageEpLen : 84.58333333333333\n",
      "Train_AverageReturn : 173.6697540283203\n",
      "Train_StdReturn : 6.36221981048584\n",
      "Train_MaxReturn : 193.8416748046875\n",
      "Train_MinReturn : 150.8893280029297\n",
      "Train_AverageEpLen : 83.7\n",
      "Train_EnvstepsSoFar : 170733\n",
      "TimeSinceStart : 96.65524697303772\n",
      "Training Loss : -6.176187038421631\n",
      "Baseline Loss : 0.6070956587791443\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 17 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 170.4396209716797\n",
      "Eval_StdReturn : 4.900771617889404\n",
      "Eval_MaxReturn : 178.53746032714844\n",
      "Eval_MinReturn : 163.3080596923828\n",
      "Eval_AverageEpLen : 85.75\n",
      "Train_AverageReturn : 170.7556610107422\n",
      "Train_StdReturn : 4.455297946929932\n",
      "Train_MaxReturn : 182.86810302734375\n",
      "Train_MinReturn : 153.40487670898438\n",
      "Train_AverageEpLen : 84.66386554621849\n",
      "Train_EnvstepsSoFar : 180808\n",
      "TimeSinceStart : 102.18539023399353\n",
      "Training Loss : -3.0314524173736572\n",
      "Baseline Loss : 0.5284804701805115\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 18 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10049 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 174.40216064453125\n",
      "Eval_StdReturn : 7.1163458824157715\n",
      "Eval_MaxReturn : 186.20651245117188\n",
      "Eval_MinReturn : 160.3936004638672\n",
      "Eval_AverageEpLen : 86.66666666666667\n",
      "Train_AverageReturn : 170.92686462402344\n",
      "Train_StdReturn : 5.6237287521362305\n",
      "Train_MaxReturn : 181.6551513671875\n",
      "Train_MinReturn : 151.1356201171875\n",
      "Train_AverageEpLen : 85.88888888888889\n",
      "Train_EnvstepsSoFar : 190857\n",
      "TimeSinceStart : 107.83300423622131\n",
      "Training Loss : 1.2645235061645508\n",
      "Baseline Loss : 0.4747665226459503\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 19 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10065 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 157.06561279296875\n",
      "Eval_StdReturn : 46.72739028930664\n",
      "Eval_MaxReturn : 200.67384338378906\n",
      "Eval_MinReturn : 66.50203704833984\n",
      "Eval_AverageEpLen : 80.0\n",
      "Train_AverageReturn : 164.53704833984375\n",
      "Train_StdReturn : 29.92817497253418\n",
      "Train_MaxReturn : 198.12164306640625\n",
      "Train_MinReturn : 61.203216552734375\n",
      "Train_AverageEpLen : 83.18181818181819\n",
      "Train_EnvstepsSoFar : 200922\n",
      "TimeSinceStart : 113.44855999946594\n",
      "Training Loss : 1.6192668676376343\n",
      "Baseline Loss : 0.5928921103477478\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 20 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10084 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 183.5327606201172\n",
      "Eval_StdReturn : 12.835591316223145\n",
      "Eval_MaxReturn : 207.30421447753906\n",
      "Eval_MinReturn : 150.3974609375\n",
      "Eval_AverageEpLen : 90.08333333333333\n",
      "Train_AverageReturn : 163.86785888671875\n",
      "Train_StdReturn : 38.19712448120117\n",
      "Train_MaxReturn : 203.80279541015625\n",
      "Train_MinReturn : 59.45514678955078\n",
      "Train_AverageEpLen : 82.65573770491804\n",
      "Train_EnvstepsSoFar : 211006\n",
      "TimeSinceStart : 119.05933976173401\n",
      "Training Loss : -2.2215383052825928\n",
      "Baseline Loss : 0.6896158456802368\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 21 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10007 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 199.86390686035156\n",
      "Eval_StdReturn : 15.744522094726562\n",
      "Eval_MaxReturn : 230.25877380371094\n",
      "Eval_MinReturn : 178.1211700439453\n",
      "Eval_AverageEpLen : 93.0\n",
      "Train_AverageReturn : 184.60324096679688\n",
      "Train_StdReturn : 21.785837173461914\n",
      "Train_MaxReturn : 214.39083862304688\n",
      "Train_MinReturn : 74.34323120117188\n",
      "Train_AverageEpLen : 89.34821428571429\n",
      "Train_EnvstepsSoFar : 221013\n",
      "TimeSinceStart : 124.57623958587646\n",
      "Training Loss : -5.64568567276001\n",
      "Baseline Loss : 0.672956645488739\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 22 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 222.33033752441406\n",
      "Eval_StdReturn : 22.420438766479492\n",
      "Eval_MaxReturn : 256.440673828125\n",
      "Eval_MinReturn : 185.40597534179688\n",
      "Eval_AverageEpLen : 98.9090909090909\n",
      "Train_AverageReturn : 199.8375244140625\n",
      "Train_StdReturn : 14.571826934814453\n",
      "Train_MaxReturn : 241.90206909179688\n",
      "Train_MinReturn : 170.49014282226562\n",
      "Train_AverageEpLen : 92.92592592592592\n",
      "Train_EnvstepsSoFar : 231049\n",
      "TimeSinceStart : 130.10172319412231\n",
      "Training Loss : -9.011009216308594\n",
      "Baseline Loss : 0.7843233346939087\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 23 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10061 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 235.4221649169922\n",
      "Eval_StdReturn : 17.81668472290039\n",
      "Eval_MaxReturn : 262.4197692871094\n",
      "Eval_MinReturn : 197.84552001953125\n",
      "Eval_AverageEpLen : 104.2\n",
      "Train_AverageReturn : 220.8258819580078\n",
      "Train_StdReturn : 18.94278907775879\n",
      "Train_MaxReturn : 261.1947326660156\n",
      "Train_MinReturn : 179.5380401611328\n",
      "Train_AverageEpLen : 98.63725490196079\n",
      "Train_EnvstepsSoFar : 241110\n",
      "TimeSinceStart : 135.6324417591095\n",
      "Training Loss : -9.254341125488281\n",
      "Baseline Loss : 0.8330228328704834\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 24 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10052 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 269.7891845703125\n",
      "Eval_StdReturn : 11.21654987335205\n",
      "Eval_MaxReturn : 283.1630554199219\n",
      "Eval_MinReturn : 247.67642211914062\n",
      "Eval_AverageEpLen : 115.55555555555556\n",
      "Train_AverageReturn : 240.33079528808594\n",
      "Train_StdReturn : 20.42853355407715\n",
      "Train_MaxReturn : 275.955810546875\n",
      "Train_MinReturn : 184.73057556152344\n",
      "Train_AverageEpLen : 105.81052631578947\n",
      "Train_EnvstepsSoFar : 251162\n",
      "TimeSinceStart : 141.20828247070312\n",
      "Training Loss : -7.223033905029297\n",
      "Baseline Loss : 0.8641161918640137\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 25 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10105 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 231.51309204101562\n",
      "Eval_StdReturn : 84.7706298828125\n",
      "Eval_MaxReturn : 321.46002197265625\n",
      "Eval_MinReturn : 89.83926391601562\n",
      "Eval_AverageEpLen : 104.0\n",
      "Train_AverageReturn : 269.0595703125\n",
      "Train_StdReturn : 34.52702331542969\n",
      "Train_MaxReturn : 317.0476989746094\n",
      "Train_MinReturn : 72.98926544189453\n",
      "Train_AverageEpLen : 114.82954545454545\n",
      "Train_EnvstepsSoFar : 261267\n",
      "TimeSinceStart : 146.67427372932434\n",
      "Training Loss : -3.475538492202759\n",
      "Baseline Loss : 0.9669532179832458\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 26 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 198.98326110839844\n",
      "Eval_StdReturn : 74.90270233154297\n",
      "Eval_MaxReturn : 323.86151123046875\n",
      "Eval_MinReturn : 120.59304809570312\n",
      "Eval_AverageEpLen : 99.45454545454545\n",
      "Train_AverageReturn : 255.31143188476562\n",
      "Train_StdReturn : 67.7329330444336\n",
      "Train_MaxReturn : 343.5084228515625\n",
      "Train_MinReturn : 110.1484146118164\n",
      "Train_AverageEpLen : 114.0340909090909\n",
      "Train_EnvstepsSoFar : 271302\n",
      "TimeSinceStart : 152.1762433052063\n",
      "Training Loss : -0.1263302117586136\n",
      "Baseline Loss : 0.9887036085128784\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 27 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10137 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 293.2056884765625\n",
      "Eval_StdReturn : 21.948686599731445\n",
      "Eval_MaxReturn : 327.20574951171875\n",
      "Eval_MinReturn : 259.48486328125\n",
      "Eval_AverageEpLen : 135.125\n",
      "Train_AverageReturn : 231.9475555419922\n",
      "Train_StdReturn : 81.23780822753906\n",
      "Train_MaxReturn : 338.117431640625\n",
      "Train_MinReturn : 106.6515121459961\n",
      "Train_AverageEpLen : 110.18478260869566\n",
      "Train_EnvstepsSoFar : 281439\n",
      "TimeSinceStart : 157.7615418434143\n",
      "Training Loss : 4.732850551605225\n",
      "Baseline Loss : 1.0035734176635742\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 28 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 305.5172119140625\n",
      "Eval_StdReturn : 26.609580993652344\n",
      "Eval_MaxReturn : 357.37542724609375\n",
      "Eval_MinReturn : 261.2245178222656\n",
      "Eval_AverageEpLen : 140.5\n",
      "Train_AverageReturn : 278.9443054199219\n",
      "Train_StdReturn : 60.127864837646484\n",
      "Train_MaxReturn : 382.4856262207031\n",
      "Train_MinReturn : 111.25745391845703\n",
      "Train_AverageEpLen : 130.36363636363637\n",
      "Train_EnvstepsSoFar : 291477\n",
      "TimeSinceStart : 163.33772563934326\n",
      "Training Loss : 6.557013034820557\n",
      "Baseline Loss : 1.0169941186904907\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 29 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10080 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 279.04290771484375\n",
      "Eval_StdReturn : 21.93764305114746\n",
      "Eval_MaxReturn : 332.52386474609375\n",
      "Eval_MinReturn : 256.0163879394531\n",
      "Eval_AverageEpLen : 131.625\n",
      "Train_AverageReturn : 279.6723937988281\n",
      "Train_StdReturn : 41.78458023071289\n",
      "Train_MaxReturn : 377.86346435546875\n",
      "Train_MinReturn : 111.64616394042969\n",
      "Train_AverageEpLen : 130.9090909090909\n",
      "Train_EnvstepsSoFar : 301557\n",
      "TimeSinceStart : 168.86068058013916\n",
      "Training Loss : 7.152908802032471\n",
      "Baseline Loss : 1.1006559133529663\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 30 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10127 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 271.0312805175781\n",
      "Eval_StdReturn : 18.81906509399414\n",
      "Eval_MaxReturn : 312.03436279296875\n",
      "Eval_MinReturn : 245.1793975830078\n",
      "Eval_AverageEpLen : 127.5\n",
      "Train_AverageReturn : 271.3955078125\n",
      "Train_StdReturn : 30.871212005615234\n",
      "Train_MaxReturn : 347.9346923828125\n",
      "Train_MinReturn : 132.1221923828125\n",
      "Train_AverageEpLen : 128.18987341772151\n",
      "Train_EnvstepsSoFar : 311684\n",
      "TimeSinceStart : 174.4577236175537\n",
      "Training Loss : 6.161672115325928\n",
      "Baseline Loss : 1.0735222101211548\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 31 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 258.90142822265625\n",
      "Eval_StdReturn : 9.915170669555664\n",
      "Eval_MaxReturn : 270.38165283203125\n",
      "Eval_MinReturn : 241.17532348632812\n",
      "Eval_AverageEpLen : 120.88888888888889\n",
      "Train_AverageReturn : 270.27178955078125\n",
      "Train_StdReturn : 21.10449981689453\n",
      "Train_MaxReturn : 372.4183654785156\n",
      "Train_MinReturn : 245.39315795898438\n",
      "Train_AverageEpLen : 126.78481012658227\n",
      "Train_EnvstepsSoFar : 321700\n",
      "TimeSinceStart : 179.95738983154297\n",
      "Training Loss : 4.204553127288818\n",
      "Baseline Loss : 0.9710017442703247\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 32 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10102 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 263.0152893066406\n",
      "Eval_StdReturn : 10.24199104309082\n",
      "Eval_MaxReturn : 276.2514343261719\n",
      "Eval_MinReturn : 245.15414428710938\n",
      "Eval_AverageEpLen : 123.44444444444444\n",
      "Train_AverageReturn : 258.8471984863281\n",
      "Train_StdReturn : 23.42534637451172\n",
      "Train_MaxReturn : 367.6906433105469\n",
      "Train_MinReturn : 127.3704833984375\n",
      "Train_AverageEpLen : 121.71084337349397\n",
      "Train_EnvstepsSoFar : 331802\n",
      "TimeSinceStart : 185.54457831382751\n",
      "Training Loss : 2.315234661102295\n",
      "Baseline Loss : 0.859984815120697\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 33 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10046 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 238.08819580078125\n",
      "Eval_StdReturn : 58.1461296081543\n",
      "Eval_MaxReturn : 266.7744445800781\n",
      "Eval_MinReturn : 75.21176147460938\n",
      "Eval_AverageEpLen : 112.44444444444444\n",
      "Train_AverageReturn : 257.83111572265625\n",
      "Train_StdReturn : 12.677128791809082\n",
      "Train_MaxReturn : 293.4490966796875\n",
      "Train_MinReturn : 225.617919921875\n",
      "Train_AverageEpLen : 121.03614457831326\n",
      "Train_EnvstepsSoFar : 341848\n",
      "TimeSinceStart : 191.09304237365723\n",
      "Training Loss : -0.43559640645980835\n",
      "Baseline Loss : 0.7906063795089722\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 34 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10037 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 269.4807434082031\n",
      "Eval_StdReturn : 28.1309757232666\n",
      "Eval_MaxReturn : 344.41552734375\n",
      "Eval_MinReturn : 240.42092895507812\n",
      "Eval_AverageEpLen : 126.66666666666667\n",
      "Train_AverageReturn : 260.3836364746094\n",
      "Train_StdReturn : 14.540481567382812\n",
      "Train_MaxReturn : 308.8544921875\n",
      "Train_MinReturn : 230.7080535888672\n",
      "Train_AverageEpLen : 122.40243902439025\n",
      "Train_EnvstepsSoFar : 351885\n",
      "TimeSinceStart : 196.7068510055542\n",
      "Training Loss : -3.961029052734375\n",
      "Baseline Loss : 0.7833805680274963\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 35 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10058 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 264.55072021484375\n",
      "Eval_StdReturn : 9.06730842590332\n",
      "Eval_MaxReturn : 277.1625061035156\n",
      "Eval_MinReturn : 244.8064727783203\n",
      "Eval_AverageEpLen : 121.77777777777777\n",
      "Train_AverageReturn : 262.2932434082031\n",
      "Train_StdReturn : 21.246408462524414\n",
      "Train_MaxReturn : 328.26763916015625\n",
      "Train_MinReturn : 135.33155822753906\n",
      "Train_AverageEpLen : 122.65853658536585\n",
      "Train_EnvstepsSoFar : 361943\n",
      "TimeSinceStart : 202.2709698677063\n",
      "Training Loss : -6.920950889587402\n",
      "Baseline Loss : 0.7869106531143188\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 36 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10119 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 259.7841491699219\n",
      "Eval_StdReturn : 11.407209396362305\n",
      "Eval_MaxReturn : 278.8638916015625\n",
      "Eval_MinReturn : 238.6094512939453\n",
      "Eval_AverageEpLen : 119.11111111111111\n",
      "Train_AverageReturn : 263.66546630859375\n",
      "Train_StdReturn : 12.63271713256836\n",
      "Train_MaxReturn : 299.3749084472656\n",
      "Train_MinReturn : 239.4359893798828\n",
      "Train_AverageEpLen : 121.91566265060241\n",
      "Train_EnvstepsSoFar : 372062\n",
      "TimeSinceStart : 207.80655455589294\n",
      "Training Loss : -9.54367446899414\n",
      "Baseline Loss : 0.825152575969696\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 37 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10035 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 258.5044250488281\n",
      "Eval_StdReturn : 10.64322566986084\n",
      "Eval_MaxReturn : 277.8717346191406\n",
      "Eval_MinReturn : 246.73110961914062\n",
      "Eval_AverageEpLen : 119.55555555555556\n",
      "Train_AverageReturn : 259.6876220703125\n",
      "Train_StdReturn : 11.313421249389648\n",
      "Train_MaxReturn : 290.8288879394531\n",
      "Train_MinReturn : 236.57644653320312\n",
      "Train_AverageEpLen : 119.46428571428571\n",
      "Train_EnvstepsSoFar : 382097\n",
      "TimeSinceStart : 213.2912678718567\n",
      "Training Loss : -10.251608848571777\n",
      "Baseline Loss : 0.8025552034378052\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 38 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10093 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 252.71441650390625\n",
      "Eval_StdReturn : 15.05944538116455\n",
      "Eval_MaxReturn : 267.95257568359375\n",
      "Eval_MinReturn : 220.82376098632812\n",
      "Eval_AverageEpLen : 115.88888888888889\n",
      "Train_AverageReturn : 252.66944885253906\n",
      "Train_StdReturn : 11.030072212219238\n",
      "Train_MaxReturn : 285.62353515625\n",
      "Train_MinReturn : 221.48684692382812\n",
      "Train_AverageEpLen : 116.01149425287356\n",
      "Train_EnvstepsSoFar : 392190\n",
      "TimeSinceStart : 218.84308767318726\n",
      "Training Loss : -8.068925857543945\n",
      "Baseline Loss : 0.732992947101593\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 39 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10068 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 254.54147338867188\n",
      "Eval_StdReturn : 12.957581520080566\n",
      "Eval_MaxReturn : 272.6776428222656\n",
      "Eval_MinReturn : 226.12881469726562\n",
      "Eval_AverageEpLen : 116.66666666666667\n",
      "Train_AverageReturn : 251.62277221679688\n",
      "Train_StdReturn : 12.204578399658203\n",
      "Train_MaxReturn : 289.1429443359375\n",
      "Train_MinReturn : 221.82666015625\n",
      "Train_AverageEpLen : 115.72413793103448\n",
      "Train_EnvstepsSoFar : 402258\n",
      "TimeSinceStart : 224.46664762496948\n",
      "Training Loss : -3.866123914718628\n",
      "Baseline Loss : 0.6558768153190613\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 40 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10047 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 263.4550476074219\n",
      "Eval_StdReturn : 9.359488487243652\n",
      "Eval_MaxReturn : 276.15093994140625\n",
      "Eval_MinReturn : 251.3443145751953\n",
      "Eval_AverageEpLen : 121.0\n",
      "Train_AverageReturn : 257.18231201171875\n",
      "Train_StdReturn : 11.040149688720703\n",
      "Train_MaxReturn : 284.71356201171875\n",
      "Train_MinReturn : 229.4200897216797\n",
      "Train_AverageEpLen : 118.2\n",
      "Train_EnvstepsSoFar : 412305\n",
      "TimeSinceStart : 230.0169734954834\n",
      "Training Loss : -1.409756064414978\n",
      "Baseline Loss : 0.5999221205711365\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 41 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 257.9266052246094\n",
      "Eval_StdReturn : 9.443048477172852\n",
      "Eval_MaxReturn : 277.2108154296875\n",
      "Eval_MinReturn : 247.32565307617188\n",
      "Eval_AverageEpLen : 118.77777777777777\n",
      "Train_AverageReturn : 258.1439208984375\n",
      "Train_StdReturn : 14.424986839294434\n",
      "Train_MaxReturn : 293.84246826171875\n",
      "Train_MinReturn : 219.92979431152344\n",
      "Train_AverageEpLen : 118.30588235294118\n",
      "Train_EnvstepsSoFar : 422361\n",
      "TimeSinceStart : 235.54472541809082\n",
      "Training Loss : -0.056954480707645416\n",
      "Baseline Loss : 0.544340968132019\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 42 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10016 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 265.53155517578125\n",
      "Eval_StdReturn : 12.620475769042969\n",
      "Eval_MaxReturn : 282.43182373046875\n",
      "Eval_MinReturn : 236.2097930908203\n",
      "Eval_AverageEpLen : 121.33333333333333\n",
      "Train_AverageReturn : 256.2495422363281\n",
      "Train_StdReturn : 24.75198745727539\n",
      "Train_MaxReturn : 306.56195068359375\n",
      "Train_MinReturn : 72.84412384033203\n",
      "Train_AverageEpLen : 117.83529411764705\n",
      "Train_EnvstepsSoFar : 432377\n",
      "TimeSinceStart : 241.0769989490509\n",
      "Training Loss : 0.62327641248703\n",
      "Baseline Loss : 0.5046631693840027\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 43 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10029 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 269.8671569824219\n",
      "Eval_StdReturn : 7.624245643615723\n",
      "Eval_MaxReturn : 280.6348876953125\n",
      "Eval_MinReturn : 254.91424560546875\n",
      "Eval_AverageEpLen : 123.22222222222223\n",
      "Train_AverageReturn : 253.22264099121094\n",
      "Train_StdReturn : 42.2781867980957\n",
      "Train_MaxReturn : 293.23443603515625\n",
      "Train_MinReturn : 65.46772766113281\n",
      "Train_AverageEpLen : 116.61627906976744\n",
      "Train_EnvstepsSoFar : 442406\n",
      "TimeSinceStart : 246.58557605743408\n",
      "Training Loss : 0.13543036580085754\n",
      "Baseline Loss : 0.47586336731910706\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 44 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10091 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 243.3533477783203\n",
      "Eval_StdReturn : 60.65789031982422\n",
      "Eval_MaxReturn : 275.8686218261719\n",
      "Eval_MinReturn : 73.01890563964844\n",
      "Eval_AverageEpLen : 111.44444444444444\n",
      "Train_AverageReturn : 256.53558349609375\n",
      "Train_StdReturn : 36.84548568725586\n",
      "Train_MaxReturn : 294.28143310546875\n",
      "Train_MinReturn : 67.32063293457031\n",
      "Train_AverageEpLen : 117.33720930232558\n",
      "Train_EnvstepsSoFar : 452497\n",
      "TimeSinceStart : 252.0879135131836\n",
      "Training Loss : -0.7346050143241882\n",
      "Baseline Loss : 0.3822312653064728\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 45 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10042 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 261.3183898925781\n",
      "Eval_StdReturn : 8.760740280151367\n",
      "Eval_MaxReturn : 277.2528076171875\n",
      "Eval_MinReturn : 245.5291290283203\n",
      "Eval_AverageEpLen : 120.11111111111111\n",
      "Train_AverageReturn : 246.66912841796875\n",
      "Train_StdReturn : 57.87491989135742\n",
      "Train_MaxReturn : 291.4853515625\n",
      "Train_MinReturn : 58.57823181152344\n",
      "Train_AverageEpLen : 112.8314606741573\n",
      "Train_EnvstepsSoFar : 462539\n",
      "TimeSinceStart : 257.6407935619354\n",
      "Training Loss : -1.9634124040603638\n",
      "Baseline Loss : 0.39316505193710327\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 46 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 248.11810302734375\n",
      "Eval_StdReturn : 59.152442932128906\n",
      "Eval_MaxReturn : 316.8288879394531\n",
      "Eval_MinReturn : 90.41998291015625\n",
      "Eval_AverageEpLen : 113.22222222222223\n",
      "Train_AverageReturn : 259.2558898925781\n",
      "Train_StdReturn : 33.290225982666016\n",
      "Train_MaxReturn : 286.784423828125\n",
      "Train_MinReturn : 60.45497512817383\n",
      "Train_AverageEpLen : 118.30588235294118\n",
      "Train_EnvstepsSoFar : 472595\n",
      "TimeSinceStart : 263.18827414512634\n",
      "Training Loss : -2.6089870929718018\n",
      "Baseline Loss : 0.30713191628456116\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 47 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10000 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 261.7306213378906\n",
      "Eval_StdReturn : 9.52713680267334\n",
      "Eval_MaxReturn : 270.1314697265625\n",
      "Eval_MinReturn : 237.7284698486328\n",
      "Eval_AverageEpLen : 121.22222222222223\n",
      "Train_AverageReturn : 247.45269775390625\n",
      "Train_StdReturn : 56.686134338378906\n",
      "Train_MaxReturn : 300.10723876953125\n",
      "Train_MinReturn : 61.088722229003906\n",
      "Train_AverageEpLen : 113.63636363636364\n",
      "Train_EnvstepsSoFar : 482595\n",
      "TimeSinceStart : 268.7104697227478\n",
      "Training Loss : -1.4917854070663452\n",
      "Baseline Loss : 0.3542790710926056\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 48 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10055 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 265.4898681640625\n",
      "Eval_StdReturn : 10.481334686279297\n",
      "Eval_MaxReturn : 285.8082275390625\n",
      "Eval_MinReturn : 251.7459716796875\n",
      "Eval_AverageEpLen : 122.66666666666667\n",
      "Train_AverageReturn : 264.7157287597656\n",
      "Train_StdReturn : 14.34283447265625\n",
      "Train_MaxReturn : 292.263427734375\n",
      "Train_MinReturn : 185.54452514648438\n",
      "Train_AverageEpLen : 121.144578313253\n",
      "Train_EnvstepsSoFar : 492650\n",
      "TimeSinceStart : 274.2517647743225\n",
      "Training Loss : 0.29315873980522156\n",
      "Baseline Loss : 0.25284335017204285\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 49 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 258.64410400390625\n",
      "Eval_StdReturn : 13.365158081054688\n",
      "Eval_MaxReturn : 282.1157531738281\n",
      "Eval_MinReturn : 238.3646240234375\n",
      "Eval_AverageEpLen : 117.66666666666667\n",
      "Train_AverageReturn : 264.1818542480469\n",
      "Train_StdReturn : 9.615585327148438\n",
      "Train_MaxReturn : 283.86810302734375\n",
      "Train_MinReturn : 241.28060913085938\n",
      "Train_AverageEpLen : 121.3855421686747\n",
      "Train_EnvstepsSoFar : 502725\n",
      "TimeSinceStart : 279.7852237224579\n",
      "Training Loss : 1.6731359958648682\n",
      "Baseline Loss : 0.18745549023151398\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 50 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10051 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 247.39816284179688\n",
      "Eval_StdReturn : 36.71257400512695\n",
      "Eval_MaxReturn : 292.13226318359375\n",
      "Eval_MinReturn : 151.5842742919922\n",
      "Eval_AverageEpLen : 114.44444444444444\n",
      "Train_AverageReturn : 260.7453308105469\n",
      "Train_StdReturn : 11.026439666748047\n",
      "Train_MaxReturn : 297.17755126953125\n",
      "Train_MinReturn : 233.42872619628906\n",
      "Train_AverageEpLen : 119.6547619047619\n",
      "Train_EnvstepsSoFar : 512776\n",
      "TimeSinceStart : 285.32980489730835\n",
      "Training Loss : 2.2568044662475586\n",
      "Baseline Loss : 0.17990902066230774\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 51 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10050 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 261.8314208984375\n",
      "Eval_StdReturn : 4.819611549377441\n",
      "Eval_MaxReturn : 266.5794982910156\n",
      "Eval_MinReturn : 252.89926147460938\n",
      "Eval_AverageEpLen : 119.88888888888889\n",
      "Train_AverageReturn : 256.7676086425781\n",
      "Train_StdReturn : 28.183561325073242\n",
      "Train_MaxReturn : 285.54791259765625\n",
      "Train_MinReturn : 87.62512969970703\n",
      "Train_AverageEpLen : 118.23529411764706\n",
      "Train_EnvstepsSoFar : 522826\n",
      "TimeSinceStart : 290.9571189880371\n",
      "Training Loss : 0.4829278886318207\n",
      "Baseline Loss : 0.19869419932365417\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 52 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10106 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 269.6867980957031\n",
      "Eval_StdReturn : 8.752083778381348\n",
      "Eval_MaxReturn : 282.9931335449219\n",
      "Eval_MinReturn : 258.0948791503906\n",
      "Eval_AverageEpLen : 122.33333333333333\n",
      "Train_AverageReturn : 262.8288879394531\n",
      "Train_StdReturn : 10.696807861328125\n",
      "Train_MaxReturn : 287.39056396484375\n",
      "Train_MinReturn : 234.83221435546875\n",
      "Train_AverageEpLen : 120.30952380952381\n",
      "Train_EnvstepsSoFar : 532932\n",
      "TimeSinceStart : 296.5285634994507\n",
      "Training Loss : -1.2822819948196411\n",
      "Baseline Loss : 0.1488087773323059\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 53 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10072 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 267.8033752441406\n",
      "Eval_StdReturn : 7.778133869171143\n",
      "Eval_MaxReturn : 277.8644104003906\n",
      "Eval_MinReturn : 257.0458068847656\n",
      "Eval_AverageEpLen : 122.11111111111111\n",
      "Train_AverageReturn : 265.6121826171875\n",
      "Train_StdReturn : 27.89229393005371\n",
      "Train_MaxReturn : 294.8184509277344\n",
      "Train_MinReturn : 71.83352661132812\n",
      "Train_AverageEpLen : 121.34939759036145\n",
      "Train_EnvstepsSoFar : 543004\n",
      "TimeSinceStart : 302.15040469169617\n",
      "Training Loss : -1.6651042699813843\n",
      "Baseline Loss : 0.2208239585161209\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 54 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10013 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 214.61355590820312\n",
      "Eval_StdReturn : 76.33204650878906\n",
      "Eval_MaxReturn : 278.5677795410156\n",
      "Eval_MinReturn : 66.73147583007812\n",
      "Eval_AverageEpLen : 101.2\n",
      "Train_AverageReturn : 257.1280212402344\n",
      "Train_StdReturn : 43.4788818359375\n",
      "Train_MaxReturn : 302.224365234375\n",
      "Train_MinReturn : 80.43403625488281\n",
      "Train_AverageEpLen : 117.8\n",
      "Train_EnvstepsSoFar : 553017\n",
      "TimeSinceStart : 307.63903975486755\n",
      "Training Loss : -0.4636305272579193\n",
      "Baseline Loss : 0.2811058759689331\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 55 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 238.78704833984375\n",
      "Eval_StdReturn : 56.10321807861328\n",
      "Eval_MaxReturn : 281.54595947265625\n",
      "Eval_MinReturn : 126.32708740234375\n",
      "Eval_AverageEpLen : 111.77777777777777\n",
      "Train_AverageReturn : 243.87669372558594\n",
      "Train_StdReturn : 56.5401496887207\n",
      "Train_MaxReturn : 297.87286376953125\n",
      "Train_MinReturn : 65.14942932128906\n",
      "Train_AverageEpLen : 112.98876404494382\n",
      "Train_EnvstepsSoFar : 563073\n",
      "TimeSinceStart : 313.1243929862976\n",
      "Training Loss : 0.19516326487064362\n",
      "Baseline Loss : 0.3938950300216675\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 56 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10005 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 252.64076232910156\n",
      "Eval_StdReturn : 13.019490242004395\n",
      "Eval_MaxReturn : 267.4225158691406\n",
      "Eval_MinReturn : 227.09219360351562\n",
      "Eval_AverageEpLen : 116.44444444444444\n",
      "Train_AverageReturn : 207.1139373779297\n",
      "Train_StdReturn : 74.55884552001953\n",
      "Train_MaxReturn : 290.0913391113281\n",
      "Train_MinReturn : 65.2906723022461\n",
      "Train_AverageEpLen : 98.08823529411765\n",
      "Train_EnvstepsSoFar : 573078\n",
      "TimeSinceStart : 318.68839955329895\n",
      "Training Loss : -2.5586390495300293\n",
      "Baseline Loss : 0.5123295783996582\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 57 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10028 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 226.93643188476562\n",
      "Eval_StdReturn : 50.28062057495117\n",
      "Eval_MaxReturn : 264.6573181152344\n",
      "Eval_MinReturn : 79.59867858886719\n",
      "Eval_AverageEpLen : 106.0\n",
      "Train_AverageReturn : 231.0704345703125\n",
      "Train_StdReturn : 53.80416488647461\n",
      "Train_MaxReturn : 282.9315490722656\n",
      "Train_MinReturn : 61.54475402832031\n",
      "Train_AverageEpLen : 107.82795698924731\n",
      "Train_EnvstepsSoFar : 583106\n",
      "TimeSinceStart : 324.25961327552795\n",
      "Training Loss : -3.3366379737854004\n",
      "Baseline Loss : 0.41368424892425537\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 58 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10057 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 234.7336883544922\n",
      "Eval_StdReturn : 37.788902282714844\n",
      "Eval_MaxReturn : 258.0695495605469\n",
      "Eval_MinReturn : 124.9906234741211\n",
      "Eval_AverageEpLen : 109.5\n",
      "Train_AverageReturn : 249.2779083251953\n",
      "Train_StdReturn : 24.191328048706055\n",
      "Train_MaxReturn : 290.5185852050781\n",
      "Train_MinReturn : 135.20108032226562\n",
      "Train_AverageEpLen : 115.59770114942529\n",
      "Train_EnvstepsSoFar : 593163\n",
      "TimeSinceStart : 329.84792137145996\n",
      "Training Loss : -0.3259590268135071\n",
      "Baseline Loss : 0.2490040361881256\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 59 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10060 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 239.42141723632812\n",
      "Eval_StdReturn : 17.75904083251953\n",
      "Eval_MaxReturn : 265.9262390136719\n",
      "Eval_MinReturn : 206.36056518554688\n",
      "Eval_AverageEpLen : 110.2\n",
      "Train_AverageReturn : 250.5933074951172\n",
      "Train_StdReturn : 14.464755058288574\n",
      "Train_MaxReturn : 284.09564208984375\n",
      "Train_MinReturn : 223.1511993408203\n",
      "Train_AverageEpLen : 115.63218390804597\n",
      "Train_EnvstepsSoFar : 603223\n",
      "TimeSinceStart : 335.41572618484497\n",
      "Training Loss : 3.611145257949829\n",
      "Baseline Loss : 0.17346914112567902\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 60 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10055 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 257.4037170410156\n",
      "Eval_StdReturn : 10.203218460083008\n",
      "Eval_MaxReturn : 269.3807678222656\n",
      "Eval_MinReturn : 234.02879333496094\n",
      "Eval_AverageEpLen : 119.55555555555556\n",
      "Train_AverageReturn : 250.5373077392578\n",
      "Train_StdReturn : 16.698213577270508\n",
      "Train_MaxReturn : 283.23577880859375\n",
      "Train_MinReturn : 194.7157745361328\n",
      "Train_AverageEpLen : 115.57471264367815\n",
      "Train_EnvstepsSoFar : 613278\n",
      "TimeSinceStart : 340.97048139572144\n",
      "Training Loss : 4.7983293533325195\n",
      "Baseline Loss : 0.20190054178237915\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 61 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10073 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 257.9105224609375\n",
      "Eval_StdReturn : 15.275543212890625\n",
      "Eval_MaxReturn : 291.0733337402344\n",
      "Eval_MinReturn : 229.46035766601562\n",
      "Eval_AverageEpLen : 119.22222222222223\n",
      "Train_AverageReturn : 251.2238311767578\n",
      "Train_StdReturn : 15.088175773620605\n",
      "Train_MaxReturn : 284.73028564453125\n",
      "Train_MinReturn : 193.1473846435547\n",
      "Train_AverageEpLen : 115.7816091954023\n",
      "Train_EnvstepsSoFar : 623351\n",
      "TimeSinceStart : 346.55370354652405\n",
      "Training Loss : 0.714082658290863\n",
      "Baseline Loss : 0.14659911394119263\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 62 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10046 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 254.073974609375\n",
      "Eval_StdReturn : 6.340135097503662\n",
      "Eval_MaxReturn : 261.4567565917969\n",
      "Eval_MinReturn : 239.3611602783203\n",
      "Eval_AverageEpLen : 117.22222222222223\n",
      "Train_AverageReturn : 252.54916381835938\n",
      "Train_StdReturn : 16.756357192993164\n",
      "Train_MaxReturn : 298.4965515136719\n",
      "Train_MinReturn : 161.3204345703125\n",
      "Train_AverageEpLen : 116.81395348837209\n",
      "Train_EnvstepsSoFar : 633397\n",
      "TimeSinceStart : 352.21047735214233\n",
      "Training Loss : -5.129458427429199\n",
      "Baseline Loss : 0.14617140591144562\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 63 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10023 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 261.6965637207031\n",
      "Eval_StdReturn : 9.444524765014648\n",
      "Eval_MaxReturn : 278.0071716308594\n",
      "Eval_MinReturn : 250.25161743164062\n",
      "Eval_AverageEpLen : 121.55555555555556\n",
      "Train_AverageReturn : 258.716796875\n",
      "Train_StdReturn : 13.899039268493652\n",
      "Train_MaxReturn : 332.99310302734375\n",
      "Train_MinReturn : 234.2318878173828\n",
      "Train_AverageEpLen : 119.32142857142857\n",
      "Train_EnvstepsSoFar : 643420\n",
      "TimeSinceStart : 357.7544515132904\n",
      "Training Loss : -7.493569374084473\n",
      "Baseline Loss : 0.14774084091186523\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 64 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10043 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 246.50306701660156\n",
      "Eval_StdReturn : 36.456565856933594\n",
      "Eval_MaxReturn : 275.9036560058594\n",
      "Eval_MinReturn : 147.52444458007812\n",
      "Eval_AverageEpLen : 118.66666666666667\n",
      "Train_AverageReturn : 258.92059326171875\n",
      "Train_StdReturn : 11.133604049682617\n",
      "Train_MaxReturn : 284.4586486816406\n",
      "Train_MinReturn : 236.53562927246094\n",
      "Train_AverageEpLen : 119.55952380952381\n",
      "Train_EnvstepsSoFar : 653463\n",
      "TimeSinceStart : 363.29138350486755\n",
      "Training Loss : -3.45538592338562\n",
      "Baseline Loss : 0.14536039531230927\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 65 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10019 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 270.1177978515625\n",
      "Eval_StdReturn : 8.855143547058105\n",
      "Eval_MaxReturn : 287.87091064453125\n",
      "Eval_MinReturn : 258.0536193847656\n",
      "Eval_AverageEpLen : 124.11111111111111\n",
      "Train_AverageReturn : 257.17669677734375\n",
      "Train_StdReturn : 15.331512451171875\n",
      "Train_MaxReturn : 302.60809326171875\n",
      "Train_MinReturn : 188.40011596679688\n",
      "Train_AverageEpLen : 119.27380952380952\n",
      "Train_EnvstepsSoFar : 663482\n",
      "TimeSinceStart : 368.77926874160767\n",
      "Training Loss : 2.3040645122528076\n",
      "Baseline Loss : 0.2027551680803299\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 66 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10027 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 261.3995666503906\n",
      "Eval_StdReturn : 11.460530281066895\n",
      "Eval_MaxReturn : 282.2214660644531\n",
      "Eval_MinReturn : 245.1451416015625\n",
      "Eval_AverageEpLen : 121.22222222222223\n",
      "Train_AverageReturn : 253.70428466796875\n",
      "Train_StdReturn : 23.64946174621582\n",
      "Train_MaxReturn : 287.2156677246094\n",
      "Train_MinReturn : 154.2700653076172\n",
      "Train_AverageEpLen : 120.80722891566265\n",
      "Train_EnvstepsSoFar : 673509\n",
      "TimeSinceStart : 374.3390610218048\n",
      "Training Loss : 4.681675434112549\n",
      "Baseline Loss : 0.3140122890472412\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 67 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10101 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 255.2233123779297\n",
      "Eval_StdReturn : 14.06375503540039\n",
      "Eval_MaxReturn : 279.935302734375\n",
      "Eval_MinReturn : 236.07215881347656\n",
      "Eval_AverageEpLen : 117.55555555555556\n",
      "Train_AverageReturn : 260.4356384277344\n",
      "Train_StdReturn : 30.495203018188477\n",
      "Train_MaxReturn : 378.47344970703125\n",
      "Train_MinReturn : 50.25546646118164\n",
      "Train_AverageEpLen : 121.6987951807229\n",
      "Train_EnvstepsSoFar : 683610\n",
      "TimeSinceStart : 379.9388334751129\n",
      "Training Loss : 3.345258951187134\n",
      "Baseline Loss : 0.26262062788009644\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 68 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10116 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 262.5865783691406\n",
      "Eval_StdReturn : 23.645957946777344\n",
      "Eval_MaxReturn : 289.9097595214844\n",
      "Eval_MinReturn : 205.6165771484375\n",
      "Eval_AverageEpLen : 127.375\n",
      "Train_AverageReturn : 261.12579345703125\n",
      "Train_StdReturn : 24.427003860473633\n",
      "Train_MaxReturn : 346.8654479980469\n",
      "Train_MinReturn : 174.23326110839844\n",
      "Train_AverageEpLen : 126.45\n",
      "Train_EnvstepsSoFar : 693726\n",
      "TimeSinceStart : 385.54927158355713\n",
      "Training Loss : 0.6610903739929199\n",
      "Baseline Loss : 0.49638375639915466\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 69 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10075 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 254.692626953125\n",
      "Eval_StdReturn : 36.64009475708008\n",
      "Eval_MaxReturn : 273.50616455078125\n",
      "Eval_MinReturn : 151.4520721435547\n",
      "Eval_AverageEpLen : 120.33333333333333\n",
      "Train_AverageReturn : 267.4434509277344\n",
      "Train_StdReturn : 26.527748107910156\n",
      "Train_MaxReturn : 364.7431640625\n",
      "Train_MinReturn : 180.67999267578125\n",
      "Train_AverageEpLen : 129.16666666666666\n",
      "Train_EnvstepsSoFar : 703801\n",
      "TimeSinceStart : 391.1523218154907\n",
      "Training Loss : -1.9343998432159424\n",
      "Baseline Loss : 0.5401397943496704\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 70 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10059 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 264.8964538574219\n",
      "Eval_StdReturn : 51.602230072021484\n",
      "Eval_MaxReturn : 369.56903076171875\n",
      "Eval_MinReturn : 165.94178771972656\n",
      "Eval_AverageEpLen : 126.875\n",
      "Train_AverageReturn : 263.343017578125\n",
      "Train_StdReturn : 38.97312545776367\n",
      "Train_MaxReturn : 389.7275390625\n",
      "Train_MinReturn : 131.2260284423828\n",
      "Train_AverageEpLen : 127.32911392405063\n",
      "Train_EnvstepsSoFar : 713860\n",
      "TimeSinceStart : 396.7068302631378\n",
      "Training Loss : -0.5549965500831604\n",
      "Baseline Loss : 0.6700008511543274\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 71 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10008 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 246.0577850341797\n",
      "Eval_StdReturn : 59.108062744140625\n",
      "Eval_MaxReturn : 330.81787109375\n",
      "Eval_MinReturn : 126.8900146484375\n",
      "Eval_AverageEpLen : 122.55555555555556\n",
      "Train_AverageReturn : 249.06051635742188\n",
      "Train_StdReturn : 40.117408752441406\n",
      "Train_MaxReturn : 322.7919616699219\n",
      "Train_MinReturn : 135.96351623535156\n",
      "Train_AverageEpLen : 119.14285714285714\n",
      "Train_EnvstepsSoFar : 723868\n",
      "TimeSinceStart : 402.1846282482147\n",
      "Training Loss : 1.0098719596862793\n",
      "Baseline Loss : 0.7260674834251404\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 72 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10063 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 283.28363037109375\n",
      "Eval_StdReturn : 33.56039047241211\n",
      "Eval_MaxReturn : 342.0312194824219\n",
      "Eval_MinReturn : 249.45204162597656\n",
      "Eval_AverageEpLen : 139.0\n",
      "Train_AverageReturn : 244.0475311279297\n",
      "Train_StdReturn : 56.2971305847168\n",
      "Train_MaxReturn : 353.47357177734375\n",
      "Train_MinReturn : 74.33246612548828\n",
      "Train_AverageEpLen : 117.01162790697674\n",
      "Train_EnvstepsSoFar : 733931\n",
      "TimeSinceStart : 407.7763686180115\n",
      "Training Loss : 1.466421365737915\n",
      "Baseline Loss : 0.6829211711883545\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 73 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10091 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 281.9962158203125\n",
      "Eval_StdReturn : 28.565900802612305\n",
      "Eval_MaxReturn : 354.2283020019531\n",
      "Eval_MinReturn : 257.242431640625\n",
      "Eval_AverageEpLen : 145.0\n",
      "Train_AverageReturn : 262.943115234375\n",
      "Train_StdReturn : 34.44766616821289\n",
      "Train_MaxReturn : 379.119873046875\n",
      "Train_MinReturn : 131.56838989257812\n",
      "Train_AverageEpLen : 126.1375\n",
      "Train_EnvstepsSoFar : 744022\n",
      "TimeSinceStart : 413.337441444397\n",
      "Training Loss : -0.6232590079307556\n",
      "Baseline Loss : 0.631576418876648\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 74 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10032 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 261.763671875\n",
      "Eval_StdReturn : 10.254526138305664\n",
      "Eval_MaxReturn : 277.82958984375\n",
      "Eval_MinReturn : 244.0995330810547\n",
      "Eval_AverageEpLen : 121.33333333333333\n",
      "Train_AverageReturn : 269.81646728515625\n",
      "Train_StdReturn : 32.270050048828125\n",
      "Train_MaxReturn : 362.6213684082031\n",
      "Train_MinReturn : 152.3662872314453\n",
      "Train_AverageEpLen : 133.76\n",
      "Train_EnvstepsSoFar : 754054\n",
      "TimeSinceStart : 418.9273352622986\n",
      "Training Loss : -3.2169878482818604\n",
      "Baseline Loss : 0.5474568605422974\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 75 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10117 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 268.45770263671875\n",
      "Eval_StdReturn : 19.332244873046875\n",
      "Eval_MaxReturn : 307.1831359863281\n",
      "Eval_MinReturn : 237.10501098632812\n",
      "Eval_AverageEpLen : 126.25\n",
      "Train_AverageReturn : 270.1448059082031\n",
      "Train_StdReturn : 30.104997634887695\n",
      "Train_MaxReturn : 366.71881103515625\n",
      "Train_MinReturn : 226.80543518066406\n",
      "Train_AverageEpLen : 131.3896103896104\n",
      "Train_EnvstepsSoFar : 764171\n",
      "TimeSinceStart : 424.38939666748047\n",
      "Training Loss : -4.047572612762451\n",
      "Baseline Loss : 0.42397984862327576\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 76 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10110 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 268.41888427734375\n",
      "Eval_StdReturn : 38.22987747192383\n",
      "Eval_MaxReturn : 366.47686767578125\n",
      "Eval_MinReturn : 242.44125366210938\n",
      "Eval_AverageEpLen : 129.875\n",
      "Train_AverageReturn : 261.25244140625\n",
      "Train_StdReturn : 20.657184600830078\n",
      "Train_MaxReturn : 346.1871337890625\n",
      "Train_MinReturn : 178.5587921142578\n",
      "Train_AverageEpLen : 123.29268292682927\n",
      "Train_EnvstepsSoFar : 774281\n",
      "TimeSinceStart : 429.940468788147\n",
      "Training Loss : -3.4307663440704346\n",
      "Baseline Loss : 0.1947498619556427\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 77 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10110 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 267.3211669921875\n",
      "Eval_StdReturn : 24.220827102661133\n",
      "Eval_MaxReturn : 324.90216064453125\n",
      "Eval_MinReturn : 245.6519012451172\n",
      "Eval_AverageEpLen : 131.5\n",
      "Train_AverageReturn : 254.78363037109375\n",
      "Train_StdReturn : 20.10447883605957\n",
      "Train_MaxReturn : 335.2498474121094\n",
      "Train_MinReturn : 174.72637939453125\n",
      "Train_AverageEpLen : 121.80722891566265\n",
      "Train_EnvstepsSoFar : 784391\n",
      "TimeSinceStart : 435.53288197517395\n",
      "Training Loss : -0.8046748042106628\n",
      "Baseline Loss : 0.2521974444389343\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 78 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10041 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 228.27224731445312\n",
      "Eval_StdReturn : 31.58024024963379\n",
      "Eval_MaxReturn : 249.5235137939453\n",
      "Eval_MinReturn : 164.91925048828125\n",
      "Eval_AverageEpLen : 108.7\n",
      "Train_AverageReturn : 249.8826904296875\n",
      "Train_StdReturn : 22.50483512878418\n",
      "Train_MaxReturn : 321.46380615234375\n",
      "Train_MinReturn : 142.63157653808594\n",
      "Train_AverageEpLen : 118.12941176470588\n",
      "Train_EnvstepsSoFar : 794432\n",
      "TimeSinceStart : 441.03367376327515\n",
      "Training Loss : 0.645516037940979\n",
      "Baseline Loss : 0.22854922711849213\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 79 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10020 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 257.7756042480469\n",
      "Eval_StdReturn : 17.478666305541992\n",
      "Eval_MaxReturn : 292.66650390625\n",
      "Eval_MinReturn : 234.84228515625\n",
      "Eval_AverageEpLen : 121.77777777777777\n",
      "Train_AverageReturn : 249.69775390625\n",
      "Train_StdReturn : 22.064064025878906\n",
      "Train_MaxReturn : 342.4981994628906\n",
      "Train_MinReturn : 149.87191772460938\n",
      "Train_AverageEpLen : 117.88235294117646\n",
      "Train_EnvstepsSoFar : 804452\n",
      "TimeSinceStart : 446.60425662994385\n",
      "Training Loss : 1.5186034440994263\n",
      "Baseline Loss : 0.21516846120357513\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 80 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10065 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 248.23806762695312\n",
      "Eval_StdReturn : 11.717440605163574\n",
      "Eval_MaxReturn : 266.69281005859375\n",
      "Eval_MinReturn : 221.849609375\n",
      "Eval_AverageEpLen : 117.0\n",
      "Train_AverageReturn : 243.88192749023438\n",
      "Train_StdReturn : 24.26197052001953\n",
      "Train_MaxReturn : 267.20526123046875\n",
      "Train_MinReturn : 135.66973876953125\n",
      "Train_AverageEpLen : 114.375\n",
      "Train_EnvstepsSoFar : 814517\n",
      "TimeSinceStart : 452.1005265712738\n",
      "Training Loss : 1.9672648906707764\n",
      "Baseline Loss : 0.2304413616657257\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 81 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 249.337646484375\n",
      "Eval_StdReturn : 14.599174499511719\n",
      "Eval_MaxReturn : 278.8636474609375\n",
      "Eval_MinReturn : 227.64785766601562\n",
      "Eval_AverageEpLen : 117.44444444444444\n",
      "Train_AverageReturn : 246.00086975097656\n",
      "Train_StdReturn : 27.388731002807617\n",
      "Train_MaxReturn : 278.6761474609375\n",
      "Train_MinReturn : 89.04647827148438\n",
      "Train_AverageEpLen : 115.35632183908046\n",
      "Train_EnvstepsSoFar : 824553\n",
      "TimeSinceStart : 457.667240858078\n",
      "Training Loss : 0.6322969198226929\n",
      "Baseline Loss : 0.1747264713048935\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 82 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10067 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 254.24685668945312\n",
      "Eval_StdReturn : 22.557870864868164\n",
      "Eval_MaxReturn : 305.3570556640625\n",
      "Eval_MinReturn : 224.2429656982422\n",
      "Eval_AverageEpLen : 119.0\n",
      "Train_AverageReturn : 247.75851440429688\n",
      "Train_StdReturn : 24.8433895111084\n",
      "Train_MaxReturn : 292.31787109375\n",
      "Train_MinReturn : 66.29795837402344\n",
      "Train_AverageEpLen : 115.71264367816092\n",
      "Train_EnvstepsSoFar : 834620\n",
      "TimeSinceStart : 463.137353181839\n",
      "Training Loss : -0.5676485896110535\n",
      "Baseline Loss : 0.12699389457702637\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 83 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10004 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 251.32139587402344\n",
      "Eval_StdReturn : 21.10508155822754\n",
      "Eval_MaxReturn : 283.77337646484375\n",
      "Eval_MinReturn : 208.0115203857422\n",
      "Eval_AverageEpLen : 118.11111111111111\n",
      "Train_AverageReturn : 250.65948486328125\n",
      "Train_StdReturn : 26.68230628967285\n",
      "Train_MaxReturn : 317.42034912109375\n",
      "Train_MinReturn : 68.26142120361328\n",
      "Train_AverageEpLen : 117.69411764705882\n",
      "Train_EnvstepsSoFar : 844624\n",
      "TimeSinceStart : 468.7432701587677\n",
      "Training Loss : -2.233513355255127\n",
      "Baseline Loss : 0.1273079663515091\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 84 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10057 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 256.76287841796875\n",
      "Eval_StdReturn : 18.930652618408203\n",
      "Eval_MaxReturn : 293.8486328125\n",
      "Eval_MinReturn : 225.94537353515625\n",
      "Eval_AverageEpLen : 120.0\n",
      "Train_AverageReturn : 250.65162658691406\n",
      "Train_StdReturn : 34.624515533447266\n",
      "Train_MaxReturn : 327.19439697265625\n",
      "Train_MinReturn : 64.7994155883789\n",
      "Train_AverageEpLen : 118.31764705882352\n",
      "Train_EnvstepsSoFar : 854681\n",
      "TimeSinceStart : 474.3591773509979\n",
      "Training Loss : -2.2931981086730957\n",
      "Baseline Loss : 0.1410568505525589\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 85 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10091 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 192.81399536132812\n",
      "Eval_StdReturn : 90.73408508300781\n",
      "Eval_MaxReturn : 325.06390380859375\n",
      "Eval_MinReturn : 61.294273376464844\n",
      "Eval_AverageEpLen : 100.7\n",
      "Train_AverageReturn : 249.6833953857422\n",
      "Train_StdReturn : 24.311859130859375\n",
      "Train_MaxReturn : 365.09088134765625\n",
      "Train_MinReturn : 210.26548767089844\n",
      "Train_AverageEpLen : 117.33720930232558\n",
      "Train_EnvstepsSoFar : 864772\n",
      "TimeSinceStart : 480.05819940567017\n",
      "Training Loss : -1.6930630207061768\n",
      "Baseline Loss : 0.10969369113445282\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 86 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10095 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 236.86073303222656\n",
      "Eval_StdReturn : 11.220579147338867\n",
      "Eval_MaxReturn : 256.392822265625\n",
      "Eval_MinReturn : 219.41453552246094\n",
      "Eval_AverageEpLen : 111.22222222222223\n",
      "Train_AverageReturn : 241.61224365234375\n",
      "Train_StdReturn : 28.528017044067383\n",
      "Train_MaxReturn : 320.2095642089844\n",
      "Train_MinReturn : 65.4763412475586\n",
      "Train_AverageEpLen : 113.42696629213484\n",
      "Train_EnvstepsSoFar : 874867\n",
      "TimeSinceStart : 485.6365165710449\n",
      "Training Loss : -1.4635460376739502\n",
      "Baseline Loss : 0.14062316715717316\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 87 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10081 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 218.126220703125\n",
      "Eval_StdReturn : 13.970067977905273\n",
      "Eval_MaxReturn : 240.35671997070312\n",
      "Eval_MinReturn : 198.67495727539062\n",
      "Eval_AverageEpLen : 103.9\n",
      "Train_AverageReturn : 229.64810180664062\n",
      "Train_StdReturn : 24.439226150512695\n",
      "Train_MaxReturn : 274.8783874511719\n",
      "Train_MinReturn : 74.15618133544922\n",
      "Train_AverageEpLen : 108.39784946236558\n",
      "Train_EnvstepsSoFar : 884948\n",
      "TimeSinceStart : 491.1836566925049\n",
      "Training Loss : -1.1264686584472656\n",
      "Baseline Loss : 0.17644523084163666\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 88 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10024 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 200.26171875\n",
      "Eval_StdReturn : 42.09864044189453\n",
      "Eval_MaxReturn : 245.59817504882812\n",
      "Eval_MinReturn : 76.32125091552734\n",
      "Eval_AverageEpLen : 95.45454545454545\n",
      "Train_AverageReturn : 217.93991088867188\n",
      "Train_StdReturn : 34.88490676879883\n",
      "Train_MaxReturn : 272.5553894042969\n",
      "Train_MinReturn : 66.66743469238281\n",
      "Train_AverageEpLen : 103.34020618556701\n",
      "Train_EnvstepsSoFar : 894972\n",
      "TimeSinceStart : 496.8013951778412\n",
      "Training Loss : 0.20324185490608215\n",
      "Baseline Loss : 0.25421342253685\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 89 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10054 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 217.82369995117188\n",
      "Eval_StdReturn : 49.090641021728516\n",
      "Eval_MaxReturn : 253.76483154296875\n",
      "Eval_MinReturn : 76.34442138671875\n",
      "Eval_AverageEpLen : 103.1\n",
      "Train_AverageReturn : 220.4576416015625\n",
      "Train_StdReturn : 32.183631896972656\n",
      "Train_MaxReturn : 297.8000793457031\n",
      "Train_MinReturn : 69.62618255615234\n",
      "Train_AverageEpLen : 104.72916666666667\n",
      "Train_EnvstepsSoFar : 905026\n",
      "TimeSinceStart : 502.5065875053406\n",
      "Training Loss : 2.8561532497406006\n",
      "Baseline Loss : 0.23967589437961578\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 90 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10036 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 232.28564453125\n",
      "Eval_StdReturn : 22.453704833984375\n",
      "Eval_MaxReturn : 265.792236328125\n",
      "Eval_MinReturn : 194.77249145507812\n",
      "Eval_AverageEpLen : 109.6\n",
      "Train_AverageReturn : 221.2052459716797\n",
      "Train_StdReturn : 32.57323455810547\n",
      "Train_MaxReturn : 271.2779541015625\n",
      "Train_MinReturn : 67.35358428955078\n",
      "Train_AverageEpLen : 104.54166666666667\n",
      "Train_EnvstepsSoFar : 915062\n",
      "TimeSinceStart : 508.1459610462189\n",
      "Training Loss : 4.589193820953369\n",
      "Baseline Loss : 0.28867289423942566\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 91 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10056 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 242.41497802734375\n",
      "Eval_StdReturn : 16.417160034179688\n",
      "Eval_MaxReturn : 284.1793212890625\n",
      "Eval_MinReturn : 227.33030700683594\n",
      "Eval_AverageEpLen : 112.66666666666667\n",
      "Train_AverageReturn : 227.5350799560547\n",
      "Train_StdReturn : 20.7899169921875\n",
      "Train_MaxReturn : 305.26898193359375\n",
      "Train_MinReturn : 136.55543518066406\n",
      "Train_AverageEpLen : 106.97872340425532\n",
      "Train_EnvstepsSoFar : 925118\n",
      "TimeSinceStart : 513.6694896221161\n",
      "Training Loss : 2.6009700298309326\n",
      "Baseline Loss : 0.20441028475761414\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 92 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10051 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 250.6891326904297\n",
      "Eval_StdReturn : 14.8663969039917\n",
      "Eval_MaxReturn : 279.92138671875\n",
      "Eval_MinReturn : 228.5048828125\n",
      "Eval_AverageEpLen : 115.88888888888889\n",
      "Train_AverageReturn : 242.64639282226562\n",
      "Train_StdReturn : 17.232221603393555\n",
      "Train_MaxReturn : 288.7415771484375\n",
      "Train_MinReturn : 175.75521850585938\n",
      "Train_AverageEpLen : 112.93258426966293\n",
      "Train_EnvstepsSoFar : 935169\n",
      "TimeSinceStart : 519.1938843727112\n",
      "Training Loss : 0.07518377900123596\n",
      "Baseline Loss : 0.18360581994056702\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 93 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10069 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 249.84556579589844\n",
      "Eval_StdReturn : 9.72362995147705\n",
      "Eval_MaxReturn : 267.3974609375\n",
      "Eval_MinReturn : 234.6486358642578\n",
      "Eval_AverageEpLen : 115.88888888888889\n",
      "Train_AverageReturn : 246.25723266601562\n",
      "Train_StdReturn : 13.099526405334473\n",
      "Train_MaxReturn : 282.4602355957031\n",
      "Train_MinReturn : 214.61277770996094\n",
      "Train_AverageEpLen : 114.42045454545455\n",
      "Train_EnvstepsSoFar : 945238\n",
      "TimeSinceStart : 524.7445130348206\n",
      "Training Loss : -3.9542973041534424\n",
      "Baseline Loss : 0.096986785531044\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 94 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10094 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 254.20643615722656\n",
      "Eval_StdReturn : 10.967962265014648\n",
      "Eval_MaxReturn : 272.814208984375\n",
      "Eval_MinReturn : 236.12120056152344\n",
      "Eval_AverageEpLen : 118.0\n",
      "Train_AverageReturn : 253.81268310546875\n",
      "Train_StdReturn : 13.760770797729492\n",
      "Train_MaxReturn : 294.4881286621094\n",
      "Train_MinReturn : 230.29010009765625\n",
      "Train_AverageEpLen : 117.37209302325581\n",
      "Train_EnvstepsSoFar : 955332\n",
      "TimeSinceStart : 530.2531740665436\n",
      "Training Loss : -6.724339008331299\n",
      "Baseline Loss : 0.12984172999858856\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 95 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10043 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 240.0789337158203\n",
      "Eval_StdReturn : 54.404396057128906\n",
      "Eval_MaxReturn : 276.00311279296875\n",
      "Eval_MinReturn : 79.53878021240234\n",
      "Eval_AverageEpLen : 111.2\n",
      "Train_AverageReturn : 255.77308654785156\n",
      "Train_StdReturn : 17.335556030273438\n",
      "Train_MaxReturn : 295.7730712890625\n",
      "Train_MinReturn : 186.07037353515625\n",
      "Train_AverageEpLen : 118.15294117647059\n",
      "Train_EnvstepsSoFar : 965375\n",
      "TimeSinceStart : 535.8090388774872\n",
      "Training Loss : -3.710163116455078\n",
      "Baseline Loss : 0.1951415091753006\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 96 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10078 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 253.0390625\n",
      "Eval_StdReturn : 29.93840789794922\n",
      "Eval_MaxReturn : 283.24163818359375\n",
      "Eval_MinReturn : 178.8322296142578\n",
      "Eval_AverageEpLen : 116.44444444444444\n",
      "Train_AverageReturn : 258.5113525390625\n",
      "Train_StdReturn : 18.72556495666504\n",
      "Train_MaxReturn : 293.32257080078125\n",
      "Train_MinReturn : 150.86007690429688\n",
      "Train_AverageEpLen : 118.56470588235294\n",
      "Train_EnvstepsSoFar : 975453\n",
      "TimeSinceStart : 541.3775815963745\n",
      "Training Loss : 1.3068645000457764\n",
      "Baseline Loss : 0.31112372875213623\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 97 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10038 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 245.17404174804688\n",
      "Eval_StdReturn : 12.931400299072266\n",
      "Eval_MaxReturn : 262.3018493652344\n",
      "Eval_MinReturn : 220.33560180664062\n",
      "Eval_AverageEpLen : 113.66666666666667\n",
      "Train_AverageReturn : 255.00343322753906\n",
      "Train_StdReturn : 37.2032356262207\n",
      "Train_MaxReturn : 306.8125\n",
      "Train_MinReturn : 71.62291717529297\n",
      "Train_AverageEpLen : 116.72093023255815\n",
      "Train_EnvstepsSoFar : 985491\n",
      "TimeSinceStart : 546.9948511123657\n",
      "Training Loss : 5.021212100982666\n",
      "Baseline Loss : 0.4419391453266144\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 98 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10067 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 271.3909606933594\n",
      "Eval_StdReturn : 24.327747344970703\n",
      "Eval_MaxReturn : 315.33367919921875\n",
      "Eval_MinReturn : 241.12359619140625\n",
      "Eval_AverageEpLen : 122.0\n",
      "Train_AverageReturn : 252.9461212158203\n",
      "Train_StdReturn : 39.98681640625\n",
      "Train_MaxReturn : 317.47802734375\n",
      "Train_MinReturn : 132.2305145263672\n",
      "Train_AverageEpLen : 115.71264367816092\n",
      "Train_EnvstepsSoFar : 995558\n",
      "TimeSinceStart : 552.5999531745911\n",
      "Training Loss : 5.18899393081665\n",
      "Baseline Loss : 0.5027075409889221\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** Iteration 99 ************\n",
      "\n",
      "Collecting data to be used for training...\n",
      "At timestep:     10101 / 10000\n",
      "Training agent...\n",
      "\n",
      "Beginning logging procedure...\n",
      "\n",
      "Collecting data for eval...\n",
      "Eval_AverageReturn : 268.97808837890625\n",
      "Eval_StdReturn : 17.2996826171875\n",
      "Eval_MaxReturn : 297.084228515625\n",
      "Eval_MinReturn : 250.9175262451172\n",
      "Eval_AverageEpLen : 122.33333333333333\n",
      "Train_AverageReturn : 250.25299072265625\n",
      "Train_StdReturn : 41.97734069824219\n",
      "Train_MaxReturn : 318.8456726074219\n",
      "Train_MinReturn : 74.6467514038086\n",
      "Train_AverageEpLen : 114.7840909090909\n",
      "Train_EnvstepsSoFar : 1005659\n",
      "TimeSinceStart : 558.1631915569305\n",
      "Training Loss : 2.6372230052948\n",
      "Baseline Loss : 0.4931187629699707\n",
      "Initial_DataCollection_AverageReturn : 17.71956443786621\n",
      "Done logging...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Plot learning curves\n",
    "### Visualize Policy Gradient results on Hopper\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/policy_gradient/Hopper"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 11725), started 0:27:29 ago. (Use '!kill 11725' to kill it.)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-26626f2ea040703d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-26626f2ea040703d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "scrolled": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('hw4': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "e71d9d111dd8bc852f18196ca01d207b62a851d72adbf7f45ab14aa585bef2e8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}